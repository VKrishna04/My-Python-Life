{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1370871-37ed-408f-95d8-8ac481fc8f56",
   "metadata": {},
   "source": [
    "# Foundations of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e856ab4a-1048-4421-ada0-c2c4e663b9e3",
   "metadata": {},
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03c374-c019-4713-8860-13de3f241880",
   "metadata": {},
   "source": [
    "### Lab 1 - (Basic problems - list, dictionary, tuple, set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076258ed-4dda-4d9e-aeab-31d4c9ccae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set after adding element: {1, 2, 3, 4}\n"
     ]
    }
   ],
   "source": [
    "my_set = {1, 2, 3}\n",
    "my_set.add(4)\n",
    "print(\"Set after adding element:\", my_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49d6fb8-351f-43fc-b37a-b80d757317f8",
   "metadata": {},
   "source": [
    "This code creates a set `my_set` containing the elements `{1, 2, 3}`, adds the element `4` to the set using the `add()` method, and then prints the updated set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "571c3d9e-2fde-42fa-a827-f01530d3aa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the list: 4\n"
     ]
    }
   ],
   "source": [
    "my_list = [10, 20, 30, 40]\n",
    "length = len(my_list)\n",
    "print(\"Length of the list:\", length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c40d20-b12c-49cd-933e-fc2b0286ca0a",
   "metadata": {},
   "source": [
    "This code initializes a list `my_list` with elements `[10, 20, 30, 40]`, calculates its length using the `len()` function, and prints the length of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4383c70a-eced-439f-8ea1-c7619dd01bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element at index 2: 15\n"
     ]
    }
   ],
   "source": [
    "my_tuple = (5, 10, 15, 20)\n",
    "element = my_tuple[2]\n",
    "print(\"Element at index 2:\", element)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5676e6-88a6-4056-a6c8-cc5b861d7940",
   "metadata": {},
   "source": [
    "This code creates a tuple `my_tuple` with elements `(5, 10, 15, 20)`, retrieves the element at index `2` (which is `15`), and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8de8e02-74bf-4a17-8833-f292aed0baa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'age' exists in the dictionary.\n"
     ]
    }
   ],
   "source": [
    "my_dict = {'name': 'Alice', 'age': 25, 'city': 'New York'}\n",
    "key = 'age'\n",
    "if key in my_dict:\n",
    "    print(f\"'{key}' exists in the dictionary.\")\n",
    "else:\n",
    "    print(f\"'{key}' does not exist in the dictionary.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301af73-87f4-4bb9-86bd-eed9bc09c914",
   "metadata": {},
   "source": [
    "This code creates a dictionary `my_dict` with keys `'name'`, `'age'`, and `'city'`. It checks if the key `'age'` exists in the dictionary and prints a message indicating whether the key is present or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9af135bb-e8cb-4393-be6e-8bef53f3570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set after removing element: {1, 2, 4}\n"
     ]
    }
   ],
   "source": [
    "my_set = {1, 2, 3, 4}\n",
    "my_set.remove(3)\n",
    "print(\"Set after removing element:\", my_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01ea76f-7a9c-404b-8627-f5dd674eb906",
   "metadata": {},
   "source": [
    "This code creates a set `my_set` with elements `{1, 2, 3, 4}`, removes the element `3` using the `remove()` method, and then prints the updated set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5deabb77-ef01-4c40-abf6-dbc83c1446e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Occurrences of 3: 3\n"
     ]
    }
   ],
   "source": [
    "my_list = [1, 2, 2, 3, 3, 3, 4]\n",
    "count = my_list.count(3)\n",
    "print(\"Occurrences of 3:\", count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d27938-e690-4537-939d-3f3a2e72f83d",
   "metadata": {},
   "source": [
    "This code initializes a list `my_list` with elements `[1, 2, 2, 3, 3, 3, 4]`, counts the occurrences of the element `3` using the `count()` method, and then prints the result (which is `3`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6c9c310-0781-49f3-ad09-f71ef09be2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated tuple: (1, 2, 3, 4, 5, 6)\n"
     ]
    }
   ],
   "source": [
    "tuple1 = (1, 2, 3)\n",
    "tuple2 = (4, 5, 6)\n",
    "concatenated_tuple = tuple1 + tuple2\n",
    "print(\"Concatenated tuple:\", concatenated_tuple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70154b8d-0af2-43df-9c46-835a0248e29b",
   "metadata": {},
   "source": [
    "This code creates two tuples `tuple1` and `tuple2`, concatenates them using the `+` operator, and then prints the resulting concatenated tuple `(1, 2, 3, 4, 5, 6)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbfacfd-6563-47bf-ae76-56e35b148532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common elements: {4, 5}\n"
     ]
    }
   ],
   "source": [
    "list1 = [1, 2, 3, 4, 5]\n",
    "list2 = [4, 5, 6, 7, 8]\n",
    "common_elements = set(list1).intersection(set(list2))\n",
    "print(\"Common elements:\", common_elements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6db4f-aa2c-4e59-b370-c31cfdedd0c4",
   "metadata": {},
   "source": [
    "This code creates two lists, `list1` and `list2`, converts them to sets, finds the common elements between the two sets using the `intersection()` method, and then prints the common elements `{4, 5}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eee31e68-c53b-448b-8b87-0f8ede664e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique numbers: [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 2, 2, 3, 4, 4, 5]\n",
    "unique_numbers = list(set(numbers))\n",
    "print(\"Unique numbers:\", unique_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1d8238-5c18-4e1b-8448-14bac7625397",
   "metadata": {},
   "source": [
    "This code converts the `numbers` list to a set (removing duplicates), then converts it back to a list to get the unique numbers, and prints the result `[1, 2, 3, 4, 5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17f52925-1efb-42f3-aad3-77821a9af469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of elements: {'apple': 3, 'banana': 2, 'orange': 1}\n"
     ]
    }
   ],
   "source": [
    "items = ['apple', 'banana', 'apple', 'orange', 'banana', 'apple']\n",
    "frequency = {}\n",
    "for item in items:\n",
    "    frequency[item] = frequency.get(item, 0) + 1\n",
    "print(\"Frequency of elements:\", frequency)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c941772-c314-465f-ad0d-9f8aa6ee449b",
   "metadata": {},
   "source": [
    "This code iterates over the `items` list, counts the occurrences of each element using a dictionary `frequency`, and then prints the frequency of each element: `{'apple': 3, 'banana': 2, 'orange': 1}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "824b654b-92e0-452b-b1e0-180343d7d535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symmetric difference: {1, 2, 5, 6}\n"
     ]
    }
   ],
   "source": [
    "set1 = {1, 2, 3, 4}\n",
    "set2 = {3, 4, 5, 6}\n",
    "sym_diff = set1.symmetric_difference(set2)\n",
    "print(\"Symmetric difference:\", sym_diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a74ee-ecfa-4428-a967-c78b0044bdba",
   "metadata": {},
   "source": [
    "This code creates two sets, `set1` and `set2`, and finds their symmetric difference (elements that are in either of the sets, but not in both) using the `symmetric_difference()` method. It then prints the result `{1, 2, 5, 6}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68203ef6-851c-4bc5-b441-dc11052d333f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: {'a': 1, 'b': 2, 'c': 3}\n"
     ]
    }
   ],
   "source": [
    "list_of_tuples = [('a', 1), ('b', 2), ('c', 3)]\n",
    "dictionary = dict(list_of_tuples)\n",
    "print(\"Dictionary:\", dictionary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe70626-eb3c-4c73-ae9c-4193c98c6fb7",
   "metadata": {},
   "source": [
    "This code converts a list of tuples `list_of_tuples` into a dictionary using the `dict()` function, where each tuple's first element becomes the key and the second element becomes the value. It then prints the resulting dictionary `{'a': 1, 'b': 2, 'c': 3}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58684207-772d-4add-96fc-f844a02c9015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dictionary: {'a': 1, 'b': 3, 'c': 4}\n"
     ]
    }
   ],
   "source": [
    "dict1 = {'a': 1, 'b': 2}\n",
    "dict2 = {'b': 3, 'c': 4}\n",
    "merged_dict = {**dict1, **dict2}\n",
    "print(\"Merged dictionary:\", merged_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02183da6-7a50-4980-8eba-c0f5d5ea7cac",
   "metadata": {},
   "source": [
    "This code merges `dict1` and `dict2` using the unpacking operator `**`, with values from `dict2` overwriting any matching keys from `dict1`. It then prints the resulting merged dictionary `{'a': 1, 'b': 3, 'c': 4}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf3b659-e778-45bf-9f42-e6d1e4457930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is set1 a subset of set2? True\n"
     ]
    }
   ],
   "source": [
    "set1 = {1, 2, 3}\n",
    "set2 = {1, 2, 3, 4, 5}\n",
    "is_subset = set1.issubset(set2)\n",
    "print(\"Is set1 a subset of set2?\", is_subset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba72d555-35bb-42d1-b05c-4cd23b28035e",
   "metadata": {},
   "source": [
    "This code checks if `set1` is a subset of `set2` using the `issubset()` method. It then prints the result, which will be `True` because all elements of `set1` are present in `set2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d61c5d5-6fef-46a7-8c90-2424da90aca8",
   "metadata": {},
   "source": [
    "# Foundations Of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437fb14e-2b6e-43f5-bd8c-4f869be2d7c9",
   "metadata": {},
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1954bf6b-14f5-4b05-b7d2-1063744c20d1",
   "metadata": {},
   "source": [
    "### Lab 2 (Codes using Numpy [Basic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96b1ba42-7221-4b3c-b217-bccc1c86c105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a=np.array([1,2,3])\n",
    "b=np.array([4,5,6])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347fcb6-aaa2-4795-84ec-88b7a53e368d",
   "metadata": {},
   "source": [
    "Creating two NumPy arrays 'a' and 'b', and printing array 'b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e1abea5-0bb5-4c07-be8c-f28fc757773e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 7 9]\n"
     ]
    }
   ],
   "source": [
    "result = a + b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fb8bdd-b30e-47eb-a341-c31438f84bd9",
   "metadata": {},
   "source": [
    "Adding two arrays 'a' and 'b' element-wise and printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6968bcb0-882a-4a59-8b77-bf69c91b8118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(a)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15aec4a-12d2-46fe-aed3-fa25030b4a16",
   "metadata": {},
   "source": [
    "Calculating and printing the mean (average) of array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fde37b5-fd67-4346-ab8b-103297b06e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "median=np.median(a)\n",
    "print(median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947ba71b-52a7-4e3d-b4f7-ba7756321a27",
   "metadata": {},
   "source": [
    "Calculating and printing the median of array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac8571e6-eaa0-44cb-83d9-33e1033a2ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "sum1=np.sum(a)\n",
    "print(sum1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8724bfa-85c7-48b4-85b9-3abcdde5daea",
   "metadata": {},
   "source": [
    "Calculating and printing the sum of elements in array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46392e38-0b80-443a-9c26-427c529548ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "diff1=np.diff(a)\n",
    "print(diff1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4cc131-1f90-4a78-a6e6-0cdf96f425b4",
   "metadata": {},
   "source": [
    "Calculating and printing the difference between consecutive elements of array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "669b7188-ba1c-4c73-a8bf-9c27dc5d7f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "pro1=np.prod(a)\n",
    "print(pro1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf22aaf-b792-4863-ad36-0b654260610f",
   "metadata": {},
   "source": [
    "Calculating and printing the product of all elements in array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c0c3c9b6-267d-4182-beac-accb60aefff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "bool=np.all(a)\n",
    "print(bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe40df2-7fa3-4b16-88e3-01746ca78d86",
   "metadata": {},
   "source": [
    "Checking if all elements in array 'a' are non-zero (True or False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f9ce562-89f5-4802-839b-923dbe2efc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         1.41421356 1.73205081]\n"
     ]
    }
   ],
   "source": [
    "sqrt_result = np.sqrt(a)\n",
    "print(sqrt_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dd9828-cffc-44cf-b1ed-ae806579d9b0",
   "metadata": {},
   "source": [
    "Calculating and printing the square root of each element in array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a838ef77-a532-4375-95ff-f8dd8a471873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "count_nonzero = np.count_nonzero(a)\n",
    "print(count_nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef60c11-fb96-4436-9228-68d1186bfd01",
   "metadata": {},
   "source": [
    "Counting and printing the number of non-zero elements in array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "321914ae-7a97-4bfa-8576-ae11fa6fa5f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "bool1=np.any(a)\n",
    "print(bool1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd190c-bd50-4d97-bebb-bcccd266d366",
   "metadata": {},
   "source": [
    "Checking if any element in array 'a' is non-zero (True or False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3234abd2-b9e2-4149-80ec-71018d6369f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "variance = np.var(a)\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf8477f-cac5-4b3b-aab0-b9d1fc69ae66",
   "metadata": {},
   "source": [
    "Calculating and printing the variance of array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5fd1327-7d09-43ab-b6d8-9ed148f20c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816496580927726\n"
     ]
    }
   ],
   "source": [
    "std_deviation = np.std(a)\n",
    "print(std_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8b0dc-b3b7-43ad-badf-d57b6304353c",
   "metadata": {},
   "source": [
    "Calculating and printing the standard deviation of array 'a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d7ccbcf-4bc0-4d84-958f-4ef36e5188fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "sort_arr=np.cumprod(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd37c14e-4df8-4fde-8c6d-af2134c395d7",
   "metadata": {},
   "source": [
    "Calculating and printing the cumulative product of elements in array 'a'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fcc2a13-60d9-418f-98a2-c9e3a4a8128a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' hello ' 'world' '1234' 'python3' ' numpy ']\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([\" Hello \", \"WORLD\", \"1234\", \"Python3\", \" NumPy \"])\n",
    "lower_case = np.char.lower(arr)\n",
    "print(lower_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a47c8f4-b676-46a9-8420-0d600731b4e2",
   "metadata": {},
   "source": [
    "Converting all string elements in array 'arr' to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca2e1804-7bfb-4d43-9311-47c03383089c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' HELLO ' 'WORLD' '1234' 'PYTHON3' ' NUMPY ']\n"
     ]
    }
   ],
   "source": [
    "upper_case = np.char.upper(arr)\n",
    "print(upper_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745fade-f42d-4777-9e57-81cbd70b82fd",
   "metadata": {},
   "source": [
    "Converting all string elements in array 'arr' to uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9b1adeb-7c46-400a-853d-3fc67fabf483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello' 'WORLD' '1234' 'Python3' 'NumPy']\n"
     ]
    }
   ],
   "source": [
    "stripped = np.char.strip(arr)\n",
    "print(stripped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7dd379-c581-40ce-b9e7-7b9a38fee3b5",
   "metadata": {},
   "source": [
    " Stripping leading and trailing whitespace from each string in array 'arr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c7330ae-9756-4985-80ff-ba4b95e5f825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False False False]\n"
     ]
    }
   ],
   "source": [
    "is_alpha = np.char.isalpha(arr)\n",
    "print(is_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6513a7-957a-43c7-8e5a-215ebd915735",
   "metadata": {},
   "source": [
    "Checking if each string in array 'arr' contains only alphabetic characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "543fd4ec-61ca-4858-b6d3-ae13d14d9198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False False]\n"
     ]
    }
   ],
   "source": [
    "is_numeric = np.char.isnumeric(arr)\n",
    "print(is_numeric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068d6eb-09d2-4e10-9efa-0586cb90e1e9",
   "metadata": {},
   "source": [
    "Checking if each string in array 'arr' contains only numeric characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5508d18-1f53-4ee3-a22f-08549061f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([\"Hello World\", \"Python Programming\", \"Numpy is great\", \"Python is fun\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ab537d8-3ef0-44f5-bd3f-55c756f9e52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "count_occurrences = np.char.count(arr1, \"Python\")\n",
    "print(count_occurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1384b05d-883c-4a6f-85be-25028525a149",
   "metadata": {},
   "source": [
    "Counting and printing the occurrences of the substring \"Python\" in each element of array 'arr1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d32a418d-9f87-42a2-a525-9b3b41945ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0 -1  0]\n"
     ]
    }
   ],
   "source": [
    "find_substring = np.char.find(arr1, \"Python\")\n",
    "print(find_substring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17379012-d8a4-470e-ab6e-61e72959b414",
   "metadata": {},
   "source": [
    "Finding and printing the index of the first occurrence of the substring \"Python\" in each element of array 'arr1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29465cf7-9464-43bf-90b9-ec409b198fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0 -1  0]\n"
     ]
    }
   ],
   "source": [
    "rfind_substring = np.char.rfind(arr1, \"Python\")\n",
    "print(rfind_substring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d009f0ed-07ee-4783-8376-38d02aac4df6",
   "metadata": {},
   "source": [
    " Finding and printing the index of the last occurrence of the substring \"Python\" in each element of array 'arr1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "41a285c0-eb9d-4f7d-a634-89f957af2fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True False  True]\n"
     ]
    }
   ],
   "source": [
    "starts_with = np.char.startswith(arr1, \"Python\")\n",
    "print(starts_with)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98609be-7481-4a85-aee4-5179f0e1e343",
   "metadata": {},
   "source": [
    "Checking and printing if each element of array 'arr1' starts with the substring \"Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2c2e0f4-f42d-4a2e-be5f-1e53f5746eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "8\n",
      "34\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from datascience import Table\n",
    "from datascience import make_array\n",
    "import numpy as np\n",
    "\n",
    "table = Table().with_columns('no', make_array(8, 34, 5))\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be6ec811-7fcc-471b-9221-daacb051175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Number of petals</th> <th>Name</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>8               </td> <td>lotus    </td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>34              </td> <td>sunflower</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>5               </td> <td>rose     </td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Number of petals | Name\n",
       "8                | lotus\n",
       "34               | sunflower\n",
       "5                | rose"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Table().with_columns(\n",
    "'Number of petals', make_array(8, 34, 5),\n",
    "'Name', make_array('lotus', 'sunflower', 'rose')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53253cf6-b80c-4e89-a7de-a0fcd9a4d83d",
   "metadata": {},
   "source": [
    "Creating a Table object and adding a column 'no' with values 8, 34, and 5, and Name then printing the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a2a60bb-aa73-4c27-bd73-3960a7b57814",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m table \u001b[38;5;241m=\u001b[39m \u001b[43mTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDatasets/sample.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(table)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\datascience\\tables.py:163\u001b[0m, in \u001b[0;36mTable.read_table\u001b[1;34m(cls, filepath_or_buffer, *args, **vargs)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m--> 163\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpandas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mfrom_df(df)\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Program Files\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datasets/sample.csv'"
     ]
    }
   ],
   "source": [
    "table = Table.read_table('Datasets/sample.csv')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa906077-a3e4-4a44-8584-4c7e78aa55c6",
   "metadata": {},
   "source": [
    "Reading and printing the CSV file 'sample.csv' as a Table object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00222089-d752-48e5-8766-1eccb184585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.num_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5bc05f-63fe-4e98-9788-6c498c8daafb",
   "metadata": {},
   "source": [
    "Getting and displaying the number of columns of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b061301f-7b5f-4b7b-8865-d3931bcbd6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.num_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233cb3c2-8cd5-4bc5-8305-947fe8cc7864",
   "metadata": {},
   "source": [
    "Getting and displaying the number of rows of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a58f9e-7294-4740-af46-01d305c65511",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb9e43-bcf5-4ca7-97f1-8fe1f8992bae",
   "metadata": {},
   "source": [
    "Getting and displaying the labels of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a59553e-6c7d-4c61-8d17-e0ad44fbfe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.relabeled('City',\t'City Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc340cfd-054e-4048-b9ab-0c312104f874",
   "metadata": {},
   "source": [
    "Renaming the column 'City' to 'City Name' in the table and printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92fd1db-a18c-4daf-9ec0-b7d0a5ebd188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3845d8-362a-497e-bfcb-2b7e332cf00b",
   "metadata": {},
   "source": [
    "printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d9458d-035c-4af8-96cf-cd24a15addf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table=table.relabeled('City','City Name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822f9421-f58d-4368-ab9f-e26dbec04fe8",
   "metadata": {},
   "source": [
    "Reapplying the renaming of column 'City' to 'City Name' and printing the updated table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2e3410-2d86-42f9-90ca-dc8093bbc02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f10b4ae-b8ae-43b5-8923-e9d3dafd4d40",
   "metadata": {},
   "source": [
    "printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0bbb5-3742-4ad4-a270-47e457c11183",
   "metadata": {},
   "outputs": [],
   "source": [
    " table.column('Survivors')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c29aaf3-17fe-4e60-b948-0bf4091e5ca5",
   "metadata": {},
   "source": [
    "Accessing and printing specific columns by name or index, and retrieving the first item of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21451a06-d2ff-435a-9597-54311596eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    " table.column(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884977ef-d215-48ac-9963-4d48ad940a69",
   "metadata": {},
   "source": [
    "Accessing and printing specific columns by name or index, and retrieving the first item of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cce407-6cde-4be6-add8-20c145cae8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " table.column(4).item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d44de8-5b19-4f94-ba4a-59ab2c0e1c40",
   "metadata": {},
   "source": [
    "Accessing and printing specific columns by name or index, and retrieving the first item of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ecbeb1-b867-4395-9b99-d4155488b8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    " table.select('Longitude',\t'Latitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dc4389-c0a3-4f31-be9f-a895b7be35c1",
   "metadata": {},
   "source": [
    "Accessing and printing specific columns by name or index, and retrieving the first item of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ccc940-c7e2-4b2d-ac3c-2cda6a3d2ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.select(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c2d26-77ac-4172-8afb-52b72c2928e3",
   "metadata": {},
   "source": [
    "Selecting and printing the 'Longitude' and 'Latitude' columns or columns by index 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ed3ef9-384d-464a-97d8-42d218c8d179",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.drop('Longitude',\t'Latitude',\t'Direction')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347b18b3-900a-4d1f-a72c-2a4cdcf64824",
   "metadata": {},
   "source": [
    "Dropping the specified columns ('Longitude', 'Latitude', and 'Direction') from the table and printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff812e5-5ece-4ba9-9ebc-f581adaffa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b230516b-21e9-4b1a-9a0d-0c58e3fa80c5",
   "metadata": {},
   "source": [
    "printing the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a6f14-da75-47c0-91f6-46d9ae8aad2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae07df-c086-4030-be09-3c37ffcc0c97",
   "metadata": {},
   "source": [
    "Displaying the first 3 rows of the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276dd5bd-1d66-4a7b-a219-e3dba34fb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.sort('Longitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cc7e0c-f9f8-4f76-ae16-dbf36d38aa00",
   "metadata": {},
   "source": [
    "Sorting the table based on the 'Longitude' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc897a-ac86-4b4d-9c27-bfb1249a1cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.sort('Longitude', descending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a875ee4-c6fb-4191-8cd1-eabe4ea741ce",
   "metadata": {},
   "source": [
    "Sorting the table based on the 'Longitude' column in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a68b7-7daa-40fd-bc46-961851ff229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import Table\n",
    "from datascience import make_array\n",
    "table = Table.read_table('sample.csv')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6e1dd7-4818-4189-8d4d-b46a77b3789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.take(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0b278-f72c-4498-95bb-b9b74ffd9f2c",
   "metadata": {},
   "source": [
    "Taking and printing the row at index 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df039cf-3ccf-4419-8e5e-db0596335770",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.take(np.arange(3,\t6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548b988-0caf-4150-81bb-ed672ee00e61",
   "metadata": {},
   "source": [
    "Taking and printing rows from index 3 to 5 (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0f9897-cb84-409d-836f-2fcbd3d77359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "table.where('Latitude', are.above(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ab73d-1548-41ae-9e23-224f102faed5",
   "metadata": {},
   "source": [
    "Filtering and printing rows where the 'Latitude' column has values greater than 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c933bfe-8895-431b-9ac1-2a92de08e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.where('Latitude',are.equal_to(54.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97801a5e-6eb0-45b0-9acc-a2bd3ee9fb4a",
   "metadata": {},
   "source": [
    "Filtering and printing rows where the 'Latitude' column equals 54.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5053672-dedf-43fc-915e-7386ad401362",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.where('Latitude',54.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8269160a-c444-4e8e-8541-9bba0f4c87f5",
   "metadata": {},
   "source": [
    "Filtering and printing rows where the 'Latitude' column equals 54.6 (direct comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721c31fd-e0f5-4371-9f9e-da60baeff5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.where('Latitude',\tare.between(54,\t54.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6c473-a955-4deb-b3b5-c1e3d9947b85",
   "metadata": {},
   "source": [
    "Filtering and printing rows where the 'Latitude' column has values between 54 and 54.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191990fa-c4f4-47b8-802c-2d8dadfe6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.where('Direction',\tare.containing('R'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce00a6-d436-4600-8e21-7e34bc8ba0a7",
   "metadata": {},
   "source": [
    "Filtering and printing rows where the 'Direction' column contains the letter 'R'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d5b756-f425-4cb1-a8ff-906c6a8cccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.where('Latitude',\tare.above_or_equal_to(55))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c3fa8-8e48-4c80-a783-e4644b4ea9e1",
   "metadata": {},
   "source": [
    "Filtering and printing rows where the 'Latitude' column has values greater than or equal to 55"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc754b8-541a-43b2-99b7-0a77e0d11e07",
   "metadata": {},
   "source": [
    "# Foundations Of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c17940-b80f-4672-bf04-f03faaeacefe",
   "metadata": {},
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f014d5e-c83a-4eb3-9f4e-786f9ef091d7",
   "metadata": {},
   "source": [
    "### Lab 3 (Pandas, Merging and Concatenating Tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619ea34c-6da8-4937-b2a9-e152ba973048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ser = pd.Series()\n",
    "print(ser)\n",
    "\n",
    "data = ['g', 'e', 'e', 'k', 's']\n",
    "ser = pd.Series(data)\n",
    "print(ser)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bb2b25-360e-4624-9076-a27bcf64b6d7",
   "metadata": {},
   "source": [
    "Creating a Pandas Series from a list of strings and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf526f-de32-457c-ba83-a49f79fba8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb443a80-caaf-4b60-bbbb-712489720a37",
   "metadata": {},
   "source": [
    "Creating an empty Pandas DataFrame and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1232f55-5143-4563-a561-67123993798f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [['g', 1], ['e', 2], ['e', 3], ['k', 4], ['s', 5]]\n",
    "df = pd.DataFrame(data, columns=['Letter', 'Number'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6714e6e6-cad2-4ef7-a806-2d94db3b14de",
   "metadata": {},
   "source": [
    "Creating a Pandas DataFrame from a list of lists, with specified column names, and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef93886-c19e-4985-99e0-eea469f4b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=['amrita','vishwa','vidya','peetham']\n",
    "df=pd.DataFrame(s1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8622fba2-0432-4ae9-90e4-6733739c68ad",
   "metadata": {},
   "source": [
    "Creating a Pandas DataFrame from a list of strings and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea07d26b-c7e9-42ba-bf73-623b8fb578a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name':['Tom','nick','krish'],'Age':[21,19,10]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a46c0-12df-4fea-99ed-fbbba8eda59f",
   "metadata": {},
   "source": [
    "Creating a Pandas DataFrame from a dictionary with 'Name' and 'Age' keys, and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b966d6b7-e0ca-42c5-a1dc-7db894e95b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name':['Tom','nick','krish'],'Age':[21,19,10]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20389d92-7ebf-409a-aa49-b1eabdf3dfa6",
   "metadata": {},
   "source": [
    "Repeating the same DataFrame creation and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641e124d-b035-4309-9291-418c0be71219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'Name':['jai','princi','Gaurav','Anuj'],'Age':[27,24,22,32],'Address':['Delhi','Kanpur','Allahabad','Kannauj'],'Qualification':['MSC','MA','MCA','phd']}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7c93e6-49ba-4b9a-aefe-bf26d4cd5b71",
   "metadata": {},
   "source": [
    "Creating a Pandas DataFrame with multiple columns and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb77b4-eba8-4e55-97a5-1bc7a01a6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['Name','Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f851b5-7004-4297-9f0f-44f5c50c3e6c",
   "metadata": {},
   "source": [
    "Selecting and printing specific columns ('Name' and 'Age') from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e2105-f024-4006-b780-e0ded6c99794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nba.CSV',index_col=\"Name\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e6d5f6-dce3-4f37-b1db-2ccdcd5f3f9d",
   "metadata": {},
   "source": [
    "Reading a CSV file ('nba.CSV') into a Pandas DataFrame, using 'Name' as the index column, and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a399b00-7c71-47e0-bafb-5ea7e3ed5793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb36dbdd-d330-4214-8f66-02e3eb7cb8b0",
   "metadata": {},
   "source": [
    "Printing the first 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8bf02-f0d0-4f77-a4dc-8ebfab072da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8592c1-c61e-4f14-99bc-e7fed4315d70",
   "metadata": {},
   "source": [
    "Printing the last 5 rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf7e4b8-8933-4d39-a8f2-a21266105ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de9d1f2-0460-4a95-9fe4-a756c6d1938d",
   "metadata": {},
   "source": [
    "Displaying information about the DataFrame, including column names, data types, and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12bde04-10e4-447d-9615-82eaa0708347",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccc70f6-647a-4210-ab47-85d952224f03",
   "metadata": {},
   "source": [
    " Generating summary statistics of the numerical columns in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d650f7a-090f-4078-87c1-793958efa4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e611d-c8f3-476b-8717-c77b7b9d7ffc",
   "metadata": {},
   "source": [
    "Printing the shape (number of rows and columns) of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac55a83e-dccf-46cd-9248-0aca790c4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12281643-a3bf-442e-b9f9-6256a5a276f3",
   "metadata": {},
   "source": [
    "Accessing and printing the first row of the DataFrame using integer-location based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe90f9b-c365-4820-a744-5b5b82fcd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc['Avery Bradley'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664fdc9-f3fd-457f-b90e-203c8d7d147d",
   "metadata": {},
   "source": [
    " Accessing and printing the row corresponding to the index label 'Avery Bradley'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc602b73-4ecc-4cac-8086-2f376dd1c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f6baea-d31b-4052-b60a-392b0c5cc114",
   "metadata": {},
   "source": [
    "Sorting the DataFrame by the 'Age' column in ascending order (by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea61fb7-4ee5-4ed7-b105-fa4995eb030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Age',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46e536f-2d93-436e-ade6-7e7a5fcd8e2c",
   "metadata": {},
   "source": [
    "Sorting the DataFrame by the 'Age' column in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c092d-f610-4b75-bc91-cee381024b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Age','Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8936ba0-f41e-4d5f-97d2-560c359756fb",
   "metadata": {},
   "source": [
    "Sorting the DataFrame first by 'Age', then by 'Weight' (ascending by default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7ef732-d384-49f4-bd9a-d725698cb3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=['Age','Weight'],na_position='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86655f38-9e76-449a-9490-b6c2469652b4",
   "metadata": {},
   "source": [
    "Sorting the DataFrame by 'Age' and 'Weight' while placing missing values at the top ('first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bd594f-9245-4de9-9946-f4d44cfe933c",
   "metadata": {},
   "source": [
    "# Foundations Of Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcaa1da-4bf7-4439-a164-e5ca80d726b3",
   "metadata": {},
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6afbfa9-6af1-4cf7-a1f5-6d71fdebe6bf",
   "metadata": {},
   "source": [
    "### Lab 4 (Handling Missing Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d36cd38-9d47-4582-9bd0-966e36f15263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data={'A':[1,2,None,4,5],'B':[None,2,3,4,5],'C':[1,None,3,4,None]}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f929da-6789-4c2c-91db-83957f6c728b",
   "metadata": {},
   "source": [
    "Creating a DataFrame with missing values (None) and printing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e8394-3731-4d48-839e-3a45bc22c2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f083cde2-07e8-464b-948b-23a4e7acf5b8",
   "metadata": {},
   "source": [
    " Checking for missing (null) values in the DataFrame, returns a DataFrame of boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b73050-92c3-425c-b79a-ee2c4c27b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d3a631-f4c0-4166-8b06-51c4869e3046",
   "metadata": {},
   "source": [
    "Checking for non-null values in the DataFrame, returns a DataFrame of boolean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a1bd8-d888-40a6-ba83-2b4782e1632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A'].isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c93162-8641-49a8-8662-6eca92fc1aeb",
   "metadata": {},
   "source": [
    "Checking for null values in column 'A' and returning a boolean Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a3675-6380-4e8e-9f8d-b7ce184de094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2e04cf-b23d-4902-a905-74741eb1e597",
   "metadata": {},
   "source": [
    "Counting the number of missing values in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f03694-e2cb-4f29-8819-d58e8805e023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fab92d-bdfe-42f1-95e5-2cd362718484",
   "metadata": {},
   "source": [
    "Dropping rows (axis=0) with any missing values from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b461cb0-5a54-4037-a7fb-191c52b203e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7120d1-43ad-469e-98f9-15da0a1e00d0",
   "metadata": {},
   "source": [
    " Dropping columns (axis=1) with any missing values from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85eadf-6a9d-47da-b592-303fe0ca1589",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([[1, 2, 3],\n",
    "                    [1, 2, 3],\n",
    "                    [1, 2, 3]])\n",
    "df2.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d5327-3dcd-486c-9c0e-edcccee6506b",
   "metadata": {},
   "source": [
    "Creating a DataFrame and dropping columns with missing values (though no missing values in df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182ddc26-b2ed-4864-81e9-0f1b27b80e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918a9198-efb5-498d-a7ca-630a9eac23eb",
   "metadata": {},
   "source": [
    "Filling missing values in the DataFrame with a constant value (1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbeed0c-06c3-458e-882f-771a0bd09906",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda col:col.fillna(col.mean(), axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a4abf-1443-4321-8fe3-26da101ec247",
   "metadata": {},
   "source": [
    "Filling missing values in each column with the mean of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6432068-9b51-4302-b9b5-6603ff1c628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaef90d-8c69-4609-a853-0da509ac1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac903e4f-9cb9-436a-ad3d-7ba76df2d4b8",
   "metadata": {},
   "source": [
    "Forward filling missing values (propagating the previous valid value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa31f5b-0d6c-49aa-858a-0d6da1ff169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e56719-a901-4aaa-86b6-d30c6e6c7049",
   "metadata": {},
   "source": [
    "Backward filling missing values (propagating the next valid value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d88e351-9186-4955-ad5a-4ab38aa13dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bfill().ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cfa99a-f7da-47be-a49c-a8583aab14b5",
   "metadata": {},
   "source": [
    " Performing both backward and forward filling on the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb235bb-1909-4199-98a2-b023389e2a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(strategy='constant')\n",
    "df_imputed = pd.DataFrame(imp.fit_transform(df), columns = df.columns)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dae4fd6-ebdf-41cf-8729-01970b3824c1",
   "metadata": {},
   "source": [
    "Using SimpleImputer from sklearn to fill missing values with a constant value, then converting it back to a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7ea09-8565-4305-8ec4-52132b810e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imp.fit_transform(df), columns = df.columns)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0daf21f-f279-4a06-89e6-272310f6eabd",
   "metadata": {},
   "source": [
    "Using SimpleImputer from sklearn to fill missing values with the mean value of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb93be1-8825-4984-9b9a-4178ea066c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='median')\n",
    "df_imputed = pd.DataFrame(imp.fit_transform(df), columns = df.columns)\n",
    "df_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721092a2-1ffa-494a-908d-d0b2911bcf26",
   "metadata": {},
   "source": [
    "Using SimpleImputer from sklearn to fill missing values with the median value of each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Au9pBiiHwKyc",
   "metadata": {
    "id": "Au9pBiiHwKyc"
   },
   "source": [
    "## **Foundations of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a61f310-63d6-4041-a3b3-5af13b4a5c94",
   "metadata": {
    "id": "Kqv7qU7YwPw5"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "i5yJ572twU-L",
   "metadata": {
    "id": "i5yJ572twU-L"
   },
   "source": [
    "**Lab 5- (Pearson correlation coefficient & PCA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hMX2qpq0wqzy",
   "metadata": {
    "id": "hMX2qpq0wqzy"
   },
   "source": [
    "**Pearson correlation coefficient**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K1nzofv9vsZy",
   "metadata": {
    "id": "K1nzofv9vsZy"
   },
   "source": [
    "Using numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e625f4e-7eef-4e47-9dd9-60effdd06d1c",
   "metadata": {
    "id": "4e625f4e-7eef-4e47-9dd9-60effdd06d1c",
    "outputId": "64b898d0-94f8-48cd-d06d-73dc650a5d4b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([12,16,20,24,28,32,36])\n",
    "B = np.array([6,9,12,15,18,21,24])\n",
    "\n",
    "mean_A = np.mean(A)\n",
    "mean_B = np.mean(B)\n",
    "print(\"Mean of A:\",mean_A)\n",
    "print(\"Mean of B:\",mean_B)\n",
    "\n",
    "sum1 = np.sum(A-mean_A)\n",
    "sum2 = np.sum(B-mean_B)\n",
    "print(\"A[i]-mean(A):\",sum1)\n",
    "print(\"B[i]-mean(B):\",sum2)\n",
    "\n",
    "sum3 = np.sum((A-mean_A)*(B-mean_B))\n",
    "print(\"(A[i]-mean(A)(B[i]-mean(B)):\",sum3)\n",
    "\n",
    "std_A = np.std(A)\n",
    "std_B = np.std(B)\n",
    "print(\"Standard Deviation of A:\",std_A)\n",
    "print(\"Standard Deviation of B:\",std_B)\n",
    "n = len(A)\n",
    "\n",
    "r = (sum3)/(n*std_A*std_B)\n",
    "print(\"Correlation Coefficient:\",r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rZEJ82jXz8By",
   "metadata": {
    "id": "rZEJ82jXz8By"
   },
   "source": [
    "This section calculates the Pearson correlation coefficient between two arrays, A and B, using the NumPy library. It first calculates the mean and standard deviation of each array, then uses these values to calculate the correlation coefficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BQJ3XoeJvxcr",
   "metadata": {
    "id": "BQJ3XoeJvxcr"
   },
   "source": [
    "Using Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89baace-c366-43a4-93ff-3b44ccb2b259",
   "metadata": {
    "id": "f89baace-c366-43a4-93ff-3b44ccb2b259",
    "outputId": "6e255ad4-5251-47ca-b2ab-d51ef758f011"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'x': [12,16,20,24,28,32,36], 'y': [6,9,12,15,18,21,24]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "correlation = df['x'].corr(df['y'])\n",
    "\n",
    "print(\"Correlation Coefficient:\",correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "asXgyZbQ0CbR",
   "metadata": {
    "id": "asXgyZbQ0CbR"
   },
   "source": [
    "This section calculates the Pearson correlation coefficient between two columns of a Pandas DataFrame, x and y, using the corr() method. This is a more concise way to calculate the correlation coefficient than using NumPy directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nPpWYrJQzMix",
   "metadata": {
    "id": "nPpWYrJQzMix"
   },
   "source": [
    "**Principle Component Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cyoGqbFfzQUz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1155
    },
    "executionInfo": {
     "elapsed": 2234,
     "status": "ok",
     "timestamp": 1731824923474,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "cyoGqbFfzQUz",
    "outputId": "07d59d3a-c594-4d97-e9c8-2990c53d68e1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pca(X, num_components):\n",
    "\n",
    "    mean = np.mean(X, axis=0)\n",
    "    X_centered = X - mean\n",
    "    print(\"Mean of each feature:\\n\", mean)\n",
    "    print(\"Centered Data:\\n\", X_centered)\n",
    "\n",
    "    covariance_matrix = np.cov(X_centered, rowvar=False)\n",
    "    print(\"Covariance Matrix:\\n\", covariance_matrix)\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    print(\"Eigenvalues:\\n\", eigenvalues)\n",
    "    print(\"Eigenvectors:\\n\", eigenvectors)\n",
    "\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    print(\"Sorted Eigenvalues:\\n\", eigenvalues)\n",
    "    print(\"Sorted Eigenvectors:\\n\", eigenvectors)\n",
    "\n",
    "    eigenvectors = eigenvectors[:, :num_components]\n",
    "    print(f\"Top {num_components} Principal Components:\\n\", eigenvectors)\n",
    "\n",
    "    X_reduced = np.dot(X_centered, eigenvectors)\n",
    "    print(\"Reduced Data:\\n\", X_reduced)\n",
    "\n",
    "    return X_reduced\n",
    "\n",
    "\n",
    "X = np.array([\n",
    "    [4, 8, 13, 7],\n",
    "    [11, 4, 5, 14] ]).T\n",
    "\n",
    "print(\"Original Data (Samples as rows):\\n\", X)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], color='blue', label='Original Data', marker='o')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Original Data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "X_reduced = pca(X, num_components=1)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_reduced, np.zeros_like(X_reduced), color='red', label='PCA Result', marker='o')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Zero Line')\n",
    "plt.title('PCA Result')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Original Data (Samples as rows):\\n\", X)\n",
    "print(\"Reduced Data:\\n\", X_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qjqEcsYV0FLg",
   "metadata": {
    "id": "qjqEcsYV0FLg"
   },
   "source": [
    "This section implements PCA to reduce the dimensionality of a dataset. It first centers the data by subtracting the mean of each feature. Then, it calculates the covariance matrix of the centered data and performs eigendecomposition to obtain the eigenvalues and eigenvectors. Finally, it selects the top num_components eigenvectors (principal components) and projects the data onto these components to obtain a lower-dimensional representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "v5PScGYmc3kt",
   "metadata": {
    "id": "v5PScGYmc3kt"
   },
   "source": [
    "# **Foundations Of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foh6Q7k-So3D",
   "metadata": {
    "id": "foh6Q7k-So3D"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wAz-ccOkc8Ha",
   "metadata": {
    "id": "wAz-ccOkc8Ha"
   },
   "source": [
    "Lab 6 (Visualizing Data - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cb2b7d-9127-4ed9-858c-9e3fa20fd242",
   "metadata": {
    "executionInfo": {
     "elapsed": 370,
     "status": "ok",
     "timestamp": 1731826403847,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "91cb2b7d-9127-4ed9-858c-9e3fa20fd242"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C-NpmgX-dPvy",
   "metadata": {
    "id": "C-NpmgX-dPvy"
   },
   "source": [
    "Imports necessary libraries: numpy, pandas, matplotlib.pyplot, and seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb2a63-f15f-4940-b96d-a795ce659608",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731826404248,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "9deb2a63-f15f-4940-b96d-a795ce659608",
    "outputId": "725d2265-c24c-41bc-bef4-8f2599bb55c3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"actors.xlsx\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1KAFlcgxdSui",
   "metadata": {
    "id": "1KAFlcgxdSui"
   },
   "source": [
    "Reads data from an Excel file named \"actors.xlsx\" into a pandas DataFrame called df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125f028-9f97-47fe-bf92-7379a1af2216",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "executionInfo": {
     "elapsed": 535,
     "status": "ok",
     "timestamp": 1731826557702,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "8125f028-9f97-47fe-bf92-7379a1af2216",
    "outputId": "20bdc33e-b0f3-4bac-9ccf-87c8c2d6f23d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(df['Number of Movies'],df['Total Gross'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b-UYkyfkdVOp",
   "metadata": {
    "id": "b-UYkyfkdVOp"
   },
   "source": [
    "Creates a scatter plot of \"Number of Movies\" vs. \"Total Gross\" using the df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639f50c-af3d-41ca-929f-3d2e8f98434e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 657,
     "status": "ok",
     "timestamp": 1731826552960,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "0639f50c-af3d-41ca-929f-3d2e8f98434e",
    "outputId": "123271c0-9e6d-447a-9b1a-e984fb9fe8fb"
   },
   "outputs": [],
   "source": [
    "x = df['Number of Movies']\n",
    "y = df['Total Gross']\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, c='white', edgecolor='green', marker='o')\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Total Gross\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "avbC8RfUdYih",
   "metadata": {
    "id": "avbC8RfUdYih"
   },
   "source": [
    "Creates a customized scatter plot of \"Number of Movies\" vs. \"Total Gross\", with green circles as markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313917c7-e8fd-4f89-aae2-4290ad41354c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "executionInfo": {
     "elapsed": 380,
     "status": "error",
     "timestamp": 1731826548846,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "313917c7-e8fd-4f89-aae2-4290ad41354c",
    "outputId": "864bc21b-79e9-485e-e401-c16d7adbbb0a"
   },
   "outputs": [],
   "source": [
    "x = df['Number of Movies']\n",
    "y = df['Average per Movie']\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, c='white', edgecolor='green', marker='s')\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Average per Movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9zYtyDdiddsd",
   "metadata": {
    "id": "9zYtyDdiddsd"
   },
   "source": [
    "Creates a customized scatter plot of \"Number of Movies\" vs. \"Average per Movie\", with green squares as markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c9aa25-b9eb-4075-ba85-42b41eaf57b2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1585
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731826405750,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "18c9aa25-b9eb-4075-ba85-42b41eaf57b2",
    "outputId": "91e3da98-a009-48bc-9f03-86c14edc6271"
   },
   "outputs": [],
   "source": [
    "outlier = df[df['Number of Movies'] > 10]\n",
    "outlier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6XGd6N94dizx",
   "metadata": {
    "id": "6XGd6N94dizx"
   },
   "source": [
    "Filters the df DataFrame to select rows where \"Number of Movies\" is greater than 10 and stores it in outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cff3a-49c1-409d-9f60-5cf00d01983d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 525,
     "status": "ok",
     "timestamp": 1731826542151,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "aa3cff3a-49c1-409d-9f60-5cf00d01983d",
    "outputId": "69755217-59bd-4b7a-8230-fc794703f72c"
   },
   "outputs": [],
   "source": [
    "x = outlier['Number of Movies']\n",
    "y = outlier['Average per Movie']\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, c='white', edgecolor='green', marker='^')\n",
    "plt.xlabel(\"Number of Movies\")\n",
    "plt.ylabel(\"Average per Movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ydWpp5EdmfR",
   "metadata": {
    "id": "2ydWpp5EdmfR"
   },
   "source": [
    "Creates a scatter plot of \"Number of Movies\" vs. \"Average per Movie\" for the outlier DataFrame, with green triangles as markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f04c69-15ce-434e-bf06-e8835991f07b",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731826405750,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "92f04c69-15ce-434e-bf06-e8835991f07b"
   },
   "outputs": [],
   "source": [
    "#Line Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b88513f-1d73-44b4-b3af-cd594b1e5318",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "executionInfo": {
     "elapsed": 514,
     "status": "ok",
     "timestamp": 1731826537290,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "4b88513f-1d73-44b4-b3af-cd594b1e5318",
    "outputId": "8943f077-7531-4e0a-d5aa-a4b84dfa0738"
   },
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "y = x ** 2\n",
    "w = x * 3\n",
    "z = x * 2\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x,y,'--')\n",
    "plt.plot(w,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wPL_RFnGdpYa",
   "metadata": {
    "id": "wPL_RFnGdpYa"
   },
   "source": [
    "Creates a line plot using numpy arrays, plotting x vs. y with a dashed line and w vs. z with a solid line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f959b30d-cded-4aff-bd70-405dfb8fa67d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "executionInfo": {
     "elapsed": 634,
     "status": "ok",
     "timestamp": 1731826530213,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "f959b30d-cded-4aff-bd70-405dfb8fa67d",
    "outputId": "71abb4c7-cc62-41e9-f5d2-ac40ca46be99"
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-10,10,100)\n",
    "y = np.sin(x)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lrV13n1ddv2j",
   "metadata": {
    "id": "lrV13n1ddv2j"
   },
   "source": [
    "Creates a line plot of the sine function using numpy's linspace and sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dc3d1e-a5b7-461a-a538-8529946f5af4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "executionInfo": {
     "elapsed": 1067,
     "status": "ok",
     "timestamp": 1731826407711,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "f8dc3d1e-a5b7-461a-a538-8529946f5af4",
    "outputId": "3e569ec0-345e-40eb-a27a-9681deb00495"
   },
   "outputs": [],
   "source": [
    "x=np.linspace(-10,10,100)\n",
    "plt.subplot(2,2,1)\n",
    "plt.xlabel('x-value')\n",
    "plt.ylabel('sine')\n",
    "plt.plot(x,np.sin(x))\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.xlabel('x-value')\n",
    "plt.ylabel('cosine')\n",
    "plt.plot(x,np.cos(x))\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.xlabel('x-value')\n",
    "plt.ylabel('tan')\n",
    "plt.plot(x,np.tan(x))\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.xlabel('x-value')\n",
    "plt.ylabel('x ** 2')\n",
    "plt.plot(x ** 2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9x2XxdzHdyWB",
   "metadata": {
    "id": "9x2XxdzHdyWB"
   },
   "source": [
    "Creates a 2x2 subplot grid and plots sine, cosine, tangent, and x squared functions in each subplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd3a5d-d101-4487-a244-f76a96f54979",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1731826521100,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "95cd3a5d-d101-4487-a244-f76a96f54979",
    "outputId": "6f14c128-5a2c-4e90-8735-1a211fee1792"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('movies_by_year.csv')\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(df['Year'], df['Number of Movies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pMxAxiXJd1WS",
   "metadata": {
    "id": "pMxAxiXJd1WS"
   },
   "source": [
    "Reads data from a CSV file named \"movies_by_year.csv\" and creates a line plot of \"Year\" vs. \"Number of Movies\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ff89d-b6e5-4d4b-a929-17c36cd2e00f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731826407711,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c19ff89d-b6e5-4d4b-a929-17c36cd2e00f",
    "outputId": "7da8fefa-9c63-4534-923e-b7bbc75a6269"
   },
   "outputs": [],
   "source": [
    "century_21st = df[df['Year'] >= 2000]\n",
    "century_21st"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y6UhdwZyd4j6",
   "metadata": {
    "id": "Y6UhdwZyd4j6"
   },
   "source": [
    "Filters the df DataFrame for years greater than or equal to 2000 and stores it in century_21st."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183c4e9f-258f-4beb-9783-e105b79100c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1731826512710,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "183c4e9f-258f-4beb-9783-e105b79100c4",
    "outputId": "3aeaf744-c39f-4b2b-8e37-c785182b0423"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(century_21st['Year'], century_21st['Number of Movies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NWMvG42qd64D",
   "metadata": {
    "id": "NWMvG42qd64D"
   },
   "source": [
    "Creates a line plot of \"Year\" vs. \"Number of Movies\" for the century_21st DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f8bb7-2b42-41db-a7bc-81045ca83411",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1731826506700,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "329f8bb7-2b42-41db-a7bc-81045ca83411",
    "outputId": "578df87c-187a-4a61-9dfd-bc2321a21fb9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(century_21st['Year'], century_21st['Total Gross'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UiPdEAw8eCJh",
   "metadata": {
    "id": "UiPdEAw8eCJh"
   },
   "source": [
    "Creates a line plot of \"Year\" vs. \"Total Gross\" for the century_21st DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e160722-3141-4970-a0da-29435136879a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1731826491703,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "4e160722-3141-4970-a0da-29435136879a",
    "outputId": "76c2dd12-8755-4a2d-e209-3a7e8402ea11"
   },
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "y = (2 * x) + 1\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kEeBRkQheEgp",
   "metadata": {
    "id": "kEeBRkQheEgp"
   },
   "source": [
    "Creates a line plot of a linear equation (y = 2x + 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a40a5-e805-4668-85e9-8df4f769d483",
   "metadata": {
    "id": "2e2a40a5-e805-4668-85e9-8df4f769d483"
   },
   "source": [
    "#Bar Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0e97ea-6cc6-4408-823b-462bc8dc6dd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731826408708,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "0b0e97ea-6cc6-4408-823b-462bc8dc6dd2",
    "outputId": "2b335747-bc81-495c-9dd5-25fbc4585fc3"
   },
   "outputs": [],
   "source": [
    "data = {'Flavour':['Chocolate','Straberry','Vanilla'],'Number of Cartons':[16,5,9]}\n",
    "table = pd.DataFrame(data)\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shH30yCveM_d",
   "metadata": {
    "id": "shH30yCveM_d"
   },
   "source": [
    "Creates a pandas DataFrame table with data about ice cream flavors and their quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49444e-303b-49cb-b959-6f9c76778ab0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "executionInfo": {
     "elapsed": 480,
     "status": "ok",
     "timestamp": 1731826430388,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "ae49444e-303b-49cb-b959-6f9c76778ab0",
    "outputId": "7dea4530-66a8-4089-fc6b-f6fe01c3f2f1"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2))\n",
    "plt.bar(table['Flavour'],table['Number of Cartons'])\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Number of Cartons')\n",
    "plt.ylabel('Flavour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eFURdmtxeRCK",
   "metadata": {
    "id": "eFURdmtxeRCK"
   },
   "source": [
    "Creates a vertical bar graph of \"Flavour\" vs. \"Number of Cartons\" with rotated x-axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aef290-7f20-4482-839e-a6d0d1b814e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1731826440059,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c1aef290-7f20-4482-839e-a6d0d1b814e8",
    "outputId": "87c77f94-ccda-4e6b-8919-399385ef4878"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2))\n",
    "plt.barh(table['Flavour'],table['Number of Cartons'])\n",
    "plt.yticks(rotation=270)\n",
    "plt.xlabel('Number of Cartons')\n",
    "plt.ylabel('Flavour')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gQPMLBipeTRa",
   "metadata": {
    "id": "gQPMLBipeTRa"
   },
   "source": [
    "Creates a horizontal bar graph of \"Flavour\" vs. \"Number of Cartons\" with rotated y-axis labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1df50d2-4a1e-467b-86a7-a03c5b22ed68",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1731826409136,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c1df50d2-4a1e-467b-86a7-a03c5b22ed68",
    "outputId": "675f2fa3-8f59-4c84-b516-77100f103c5a"
   },
   "outputs": [],
   "source": [
    "sorted = table.sort_values('Number of Cartons')\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.bar(sorted['Flavour'], sorted['Number of Cartons'])\n",
    "plt.xlabel('Flavour')\n",
    "plt.ylabel('Number of Cartons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fk1AjCW8eVcy",
   "metadata": {
    "id": "Fk1AjCW8eVcy"
   },
   "source": [
    "Sorts the table DataFrame by \"Number of Cartons\" and creates a vertical bar graph using the sorted data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ACk6duItfKw7",
   "metadata": {
    "id": "ACk6duItfKw7"
   },
   "source": [
    "# **Foundations Of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kWlaVMmfSvJi",
   "metadata": {
    "id": "kWlaVMmfSvJi"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DoSMeVpifOew",
   "metadata": {
    "id": "DoSMeVpifOew"
   },
   "source": [
    "Lab 8 (Visualizing Data - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fb5eae-9d5c-4266-a092-faaf64169fac",
   "metadata": {
    "executionInfo": {
     "elapsed": 2231,
     "status": "ok",
     "timestamp": 1731827066881,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "16fb5eae-9d5c-4266-a092-faaf64169fac"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2A8ZMwp7in7k",
   "metadata": {
    "id": "2A8ZMwp7in7k"
   },
   "source": [
    "Imports necessary libraries: pandas, seaborn, and matplotlib.pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0929d131-3d90-4a20-90a9-a238e6c3dd63",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731827066881,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "0929d131-3d90-4a20-90a9-a238e6c3dd63",
    "outputId": "806fb31e-c6be-4c7e-922d-bb68a90c4485"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('top_movies.csv')\n",
    "studios = df[['Title','Studio']]\n",
    "studios_group = studios.groupby('Studio').count()\n",
    "studios_group.rename(columns = {'1':'Count'}, inplace = True)\n",
    "print(studios_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BnR-rOfJirxx",
   "metadata": {
    "id": "BnR-rOfJirxx"
   },
   "source": [
    "Reads data from 'top_movies.csv'.\n",
    "Groups movies by studio and counts the number of movies for each studio.\n",
    "Prints the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0eefbd-909c-49b8-989e-8c24a4d5a56e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 898
    },
    "executionInfo": {
     "elapsed": 980,
     "status": "ok",
     "timestamp": 1731827067858,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "1d0eefbd-909c-49b8-989e-8c24a4d5a56e",
    "outputId": "59ad43d2-3b5f-4ba4-98b7-eae36588b0b2"
   },
   "outputs": [],
   "source": [
    "studios_group_sorted = studios_group.sort_values('Title',ascending = True)\n",
    "print(studios_group_sorted)\n",
    "studios_group_sorted.plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XVxlPkftiuSx",
   "metadata": {
    "id": "XVxlPkftiuSx"
   },
   "source": [
    "Sorts the studio group data and prints the sorted data.\n",
    "Creates a horizontal bar plot of the number of movies per studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb1bc4-a3ef-4273-8679-295b4565e536",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731827067859,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "7bcb1bc4-a3ef-4273-8679-295b4565e536",
    "outputId": "b08aad0c-6fa1-4cc2-e31c-269cdabcd0bf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('top_movies.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OvEkEVZGiyVZ",
   "metadata": {
    "id": "OvEkEVZGiyVZ"
   },
   "source": [
    "Reads data from 'top_movies.csv'.\n",
    "Prints the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdeff20-5bf2-48e0-9aa4-e3836fd57026",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731827067859,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "7bdeff20-5bf2-48e0-9aa4-e3836fd57026",
    "outputId": "ec6f4ff3-c987-429d-d211-afbfdc07d0f8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = np.random.randint(1, 101, size=50)\n",
    "datal = pd.DataFrame(data, columns=['Value'])\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(datal['Value'], bins=20, edgecolor='black')\n",
    "\n",
    "plt.title('Frequency Histogram')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vIRT1uhHi1w5",
   "metadata": {
    "id": "vIRT1uhHi1w5"
   },
   "source": [
    "Generates random data and creates a dataframe.\n",
    "Creates a frequency histogram of the generated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51414c-c3ce-48fe-a8c3-51ca66c90195",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1731827068537,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "8b51414c-c3ce-48fe-a8c3-51ca66c90195",
    "outputId": "ad6dded1-5a9d-4ea5-b455-9e412f54506c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_movies = pd.read_csv('top_movies.csv')\n",
    "num_bins = int(np.sqrt(len(top_movies)))\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.hist(top_movies['Gross'], bins=30, edgecolor='black', color='skyblue')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.title('Distribution of Gross Earnings for Top Movies', fontsize=16)\n",
    "plt.xlabel('Gross Earnings ($)', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7xWAa7O7i6IK",
   "metadata": {
    "id": "7xWAa7O7i6IK"
   },
   "source": [
    "Reads data from 'top_movies.csv'.\n",
    "Creates a histogram to visualize the distribution of gross earnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fef4c68-6b95-474d-a01e-77be7a5cfd2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731827068537,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "5fef4c68-6b95-474d-a01e-77be7a5cfd2d",
    "outputId": "cebdde67-3ff6-465d-da96-43088d7bb0a9"
   },
   "outputs": [],
   "source": [
    "top_movies = pd.read_csv('top_movies.csv')\n",
    "\n",
    "bins = np.arange(300, 2001, 100)\n",
    "top_movies['Gross Bin'] = pd.cut(top_movies['Gross'], bins=bins)\n",
    "bin_counts = top_movies['Gross Bin'].value_counts().sort_index()\n",
    "print(bin_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "x0TV2f-ui99R",
   "metadata": {
    "id": "x0TV2f-ui99R"
   },
   "source": [
    "Reads data from 'top_movies.csv'.\n",
    "Bins the 'Gross' column and counts the number of movies in each bin.\n",
    "Prints the bin counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd88b85-781e-4e80-aa63-12cd6b9f6895",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 750
    },
    "executionInfo": {
     "elapsed": 994,
     "status": "ok",
     "timestamp": 1731827069527,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "ccd88b85-781e-4e80-aa63-12cd6b9f6895",
    "outputId": "7027f921-1b34-468d-aa9f-5ddf5dc6f099"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "top_movies = pd.read_csv('top_movies.csv')\n",
    "\n",
    "year_counts = top_movies['Year'].value_counts().sort_index().reset_index()\n",
    "year_counts.columns = ['Year', 'Count']\n",
    "\n",
    "total_count = year_counts['Count'].sum()\n",
    "year_counts['Percent'] = (year_counts['Count'] / total_count) * 100\n",
    "year_counts['Height'] = year_counts['Percent'] / 100\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.bar(year_counts['Year'], year_counts['Count'], color='skyblue', edgecolor='black')\n",
    "\n",
    "plt.title('Number of Movies per Year (Counts)', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Number of Movies', fontsize=14)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(year_counts[['Year', 'Height']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NCV1hFhajBdR",
   "metadata": {
    "id": "NCV1hFhajBdR"
   },
   "source": [
    "Reads data from 'top_movies.csv'.\n",
    "Calculates the number of movies per year and the percentage.\n",
    "Creates a bar chart of the number of movies per year.\n",
    "Prints a table with year and height (percentage/100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a353f-4f14-4c3a-a75d-86202a5b39a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1731827164324,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "540a353f-4f14-4c3a-a75d-86202a5b39a9",
    "outputId": "958bcd12-dabb-450b-dfa9-8add10758d12"
   },
   "outputs": [],
   "source": [
    "\n",
    "top_movies = pd.read_csv('top_movies.csv')\n",
    "corr_matrix = top_movies[['Gross', 'Gross (Adjusted)']].corr()\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap of Gross Earnings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZGbSvGx1jEbp",
   "metadata": {
    "id": "ZGbSvGx1jEbp"
   },
   "source": [
    "Reads data from 'top_movies.csv'.\n",
    "Creates a correlation heatmap of 'Gross' and 'Gross (Adjusted)'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4380d3-dadb-43a0-b809-3c0c46f001d8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 376
    },
    "executionInfo": {
     "elapsed": 871,
     "status": "ok",
     "timestamp": 1731827283907,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "ac4380d3-dadb-43a0-b809-3c0c46f001d8",
    "outputId": "2e963536-405a-45f4-c0d8-8cd52c678bbf"
   },
   "outputs": [],
   "source": [
    "studio_gross = top_movies.groupby('Studio')['Gross'].sum()\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(studio_gross, labels=studio_gross.index, startangle=140, colors=plt.cm.Paired(range(len(studio_gross))))\n",
    "plt.title('Proportion of Total Gross Earnings by Studio', fontsize=16)\n",
    "plt.axis('equal')\n",
    "plt.axis('equal')\n",
    "plt.xticks(rotate=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WgLuLzuWjHE4",
   "metadata": {
    "id": "WgLuLzuWjHE4"
   },
   "source": [
    "Groups the data by 'Studio' and sums the 'Gross' for each studio.\n",
    "Creates a pie chart to show the proportion of total gross earnings by studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nxwhf457jIzs",
   "metadata": {
    "id": "nxwhf457jIzs"
   },
   "source": [
    "Creates a pie chart showing the distribution of total gross by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f6a4ba-e028-4279-9c5b-6a5f557f2df0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1491
    },
    "executionInfo": {
     "elapsed": 920,
     "status": "ok",
     "timestamp": 1731827219975,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "71f6a4ba-e028-4279-9c5b-6a5f557f2df0",
    "outputId": "68c85647-222d-473c-d919-1d1011fe162a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "plt.boxplot(top_movies['Gross'], vert=False, patch_artist=True,\n",
    "            boxprops=dict(facecolor='skyblue', color='black'),\n",
    "            whiskerprops=dict(color='black'),\n",
    "            medianprops=dict(color='red'))\n",
    "plt.title('Box Plot of Gross Earnings for Top Movies', fontsize=16)\n",
    "plt.xlabel('Gross Earnings ($)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zJ-I_443jLE5",
   "metadata": {
    "id": "zJ-I_443jLE5"
   },
   "source": [
    "Creates a box plot of the 'Gross' earnings for the top movies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rzKmlSBvjs2B",
   "metadata": {
    "id": "rzKmlSBvjs2B"
   },
   "source": [
    "# **Foundation Of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2qnHwVDkS2Bs",
   "metadata": {
    "id": "2qnHwVDkS2Bs"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smXdAYeajxhh",
   "metadata": {
    "id": "smXdAYeajxhh"
   },
   "source": [
    "Lab 8 (Sampling and Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffdc349-24b4-45b1-9587-22e6e900c46a",
   "metadata": {
    "executionInfo": {
     "elapsed": 625,
     "status": "ok",
     "timestamp": 1731827430082,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "dffdc349-24b4-45b1-9587-22e6e900c46a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9mi1uAsdj96D",
   "metadata": {
    "id": "9mi1uAsdj96D"
   },
   "source": [
    "Imports necessary libraries like pandas, numpy, matplotlib, seaborn, and random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6711ddee-028a-4c36-bcff-7c35be34f463",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1731827581729,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "6711ddee-028a-4c36-bcff-7c35be34f463",
    "outputId": "6e0f621b-50e8-45ab-ded0-c3f56cec099b"
   },
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('uk-500.csv')\n",
    "d1.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1O9sj6oVj-xI",
   "metadata": {
    "id": "1O9sj6oVj-xI"
   },
   "source": [
    "Reads the 'uk-500.csv' file into a pandas DataFrame named 'd1' and displays the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33cfa1c-ef35-4d2f-8543-8a3fa7ededbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731827430571,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c33cfa1c-ef35-4d2f-8543-8a3fa7ededbd",
    "outputId": "6e597185-d40f-476a-b6b8-218bec15803a"
   },
   "outputs": [],
   "source": [
    "d1.sample(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rsvZkj0akDwY",
   "metadata": {
    "id": "rsvZkj0akDwY"
   },
   "source": [
    "Randomly samples 3 rows from 'd1' without replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af06bbd-6b9a-4422-8c6a-d1c7023c1259",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1731827589330,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "2af06bbd-6b9a-4422-8c6a-d1c7023c1259",
    "outputId": "a8597e3e-f6e5-427e-f75f-63ec6670c63a"
   },
   "outputs": [],
   "source": [
    "d1.sample(frac=0.1).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ymAmPCuJkGFM",
   "metadata": {
    "id": "ymAmPCuJkGFM"
   },
   "source": [
    "Randomly samples 10% of the rows from 'd1' without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0f4c5-62d9-43f9-b000-2e93cbce81ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "executionInfo": {
     "elapsed": 478,
     "status": "ok",
     "timestamp": 1731827431042,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "41e0f4c5-62d9-43f9-b000-2e93cbce81ab",
    "outputId": "25de6f8d-a9ea-4a61-984a-8761baa44350"
   },
   "outputs": [],
   "source": [
    "d1.sample(n=3, replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XghN50EAkLXB",
   "metadata": {
    "id": "XghN50EAkLXB"
   },
   "source": [
    "Randomly samples 3 rows from 'd1' with replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bb4916-1fc2-4b82-ae58-467257c3d943",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731827431042,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c4bb4916-1fc2-4b82-ae58-467257c3d943",
    "outputId": "a26ecca1-c350-49a1-9a85-e70d10281fef"
   },
   "outputs": [],
   "source": [
    "d1.sample(n=3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lwscwpJakP7E",
   "metadata": {
    "id": "lwscwpJakP7E"
   },
   "source": [
    "Randomly samples 3 rows from 'd1' without replacement, using a specific random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1cd22-7024-4a69-8d33-a8530e3bb231",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1731827598046,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "eee1cd22-7024-4a69-8d33-a8530e3bb231",
    "outputId": "4f06e152-669b-47dd-b24d-dfe0ab3596ab"
   },
   "outputs": [],
   "source": [
    "d1.sample(frac=0.10, replace=True, random_state=5).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pTNOPna4kY1o",
   "metadata": {
    "id": "pTNOPna4kY1o"
   },
   "source": [
    "Randomly samples 10% of the rows from 'd1' with replacement, using a specific random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def5aedd-f1a9-4d05-b539-693dc922f83b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 399
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731827431042,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "def5aedd-f1a9-4d05-b539-693dc922f83b",
    "outputId": "cf02f57e-56c5-48f9-96eb-9a3fe1934124"
   },
   "outputs": [],
   "source": [
    "d1.sample(n=5, replace=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZBh1SOtOkbko",
   "metadata": {
    "id": "ZBh1SOtOkbko"
   },
   "source": [
    "Randomly samples 5 rows from 'd1' with replacement, using a specific random state for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a8603-c5df-4f4e-b93e-7f1056d2bb6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731827431042,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c13a8603-c5df-4f4e-b93e-7f1056d2bb6a",
    "outputId": "72e868f4-b5f6-4ffe-cdce-0c27c7f5ec49"
   },
   "outputs": [],
   "source": [
    "d2 = pd.read_csv('StudentsPerformance.csv')\n",
    "d2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NblV2uZckfy1",
   "metadata": {
    "id": "NblV2uZckfy1"
   },
   "source": [
    "Reads the 'StudentsPerformance.csv' file into a pandas DataFrame named 'd2' and displays the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b301308-8deb-459a-90b9-3f78a6e6087f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "executionInfo": {
     "elapsed": 1136,
     "status": "ok",
     "timestamp": 1731827456953,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "6b301308-8deb-459a-90b9-3f78a6e6087f",
    "outputId": "9a18178d-2c48-495c-cf18-6eb7857d1b0f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.histplot(d2['race/ethnicity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3H3JA42wkh_h",
   "metadata": {
    "id": "3H3JA42wkh_h"
   },
   "source": [
    "Creates a histogram of the 'race/ethnicity' column in 'd2' using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5042ca5f-07df-40bc-884c-687e0b3b2e89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "executionInfo": {
     "elapsed": 390,
     "status": "ok",
     "timestamp": 1731827608554,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "5042ca5f-07df-40bc-884c-687e0b3b2e89",
    "outputId": "6686fa16-e293-42dd-addd-2dc231c88de7"
   },
   "outputs": [],
   "source": [
    "d2.groupby('race/ethnicity', group_keys=False).apply(lambda x:x.sample(min(len(x),3))).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ODPmzpW3kkyo",
   "metadata": {
    "id": "ODPmzpW3kkyo"
   },
   "source": [
    "Groups 'd2' by 'race/ethnicity' and samples a maximum of 3 rows from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efda15-677c-42c3-9bd4-835b911a3d08",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731827431776,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "52efda15-677c-42c3-9bd4-835b911a3d08",
    "outputId": "88625547-2373-42e0-a477-d9b42e6a00ba"
   },
   "outputs": [],
   "source": [
    "d2.groupby('gender', group_keys=False).apply(lambda x:x.sample(min(len(x),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tEGM5YOuknGJ",
   "metadata": {
    "id": "tEGM5YOuknGJ"
   },
   "source": [
    " Groups 'd2' by 'race/ethnicity' and samples a maximum of 3 rows from each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57596337-9a16-441f-a512-875a0860fcd8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1731827614579,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "57596337-9a16-441f-a512-875a0860fcd8",
    "outputId": "5f3e61b4-74cd-41cc-dd22-b6e885b973c3"
   },
   "outputs": [],
   "source": [
    "step_size = 6\n",
    "d2.iloc[::step_size].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8JKblalzkrqi",
   "metadata": {
    "id": "8JKblalzkrqi"
   },
   "source": [
    "Selects every 6th row from 'd2' using slicing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea3304-46ae-4e3f-a476-d83f1c786cf0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731827431776,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c0ea3304-46ae-4e3f-a476-d83f1c786cf0",
    "outputId": "a19b1294-d03a-489f-ebfe-24db55236094"
   },
   "outputs": [],
   "source": [
    "reading_range = np.amax(d2['reading score'])-np.amin(d2['reading score'])\n",
    "reading_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Radd5lGdkvmY",
   "metadata": {
    "id": "Radd5lGdkvmY"
   },
   "source": [
    "Calculates the class interval for 'reading score'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b3d95-164f-44bd-97f8-4ce7c7355a63",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731827431776,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "023b3d95-164f-44bd-97f8-4ce7c7355a63"
   },
   "outputs": [],
   "source": [
    "num_of_classes=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f682ac7-f78c-4817-95c6-4cc513357b98",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731827431776,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "2f682ac7-f78c-4817-95c6-4cc513357b98",
    "outputId": "f9c29f3e-2d31-437c-b4a7-0ab453cd8b7d"
   },
   "outputs": [],
   "source": [
    "class_interval = reading_range/num_of_classes\n",
    "class_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bPg7yRX-kysx",
   "metadata": {
    "id": "bPg7yRX-kysx"
   },
   "source": [
    "Calculates the mean of 'math score' in 'd2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090c28e-bb24-4dc2-a528-f8e9909501e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 376,
     "status": "ok",
     "timestamp": 1731827628619,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "4090c28e-bb24-4dc2-a528-f8e9909501e2",
    "outputId": "26442d5c-0f3b-49c1-d356-72f266cdba17"
   },
   "outputs": [],
   "source": [
    "d2['reading score'].value_counts().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af293bea-18cd-4f66-a168-83250c77c45f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1731827636034,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "af293bea-18cd-4f66-a168-83250c77c45f",
    "outputId": "edcbfcb6-6836-47b2-80e5-b4b2b765f74f"
   },
   "outputs": [],
   "source": [
    "d2['reading score'].value_counts().cumsum().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11079e01-5e4c-4a88-b1a3-ea55b9841e10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1731827432205,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "11079e01-5e4c-4a88-b1a3-ea55b9841e10",
    "outputId": "bb454a07-b004-4b61-f63f-7a979e77f00d"
   },
   "outputs": [],
   "source": [
    "d2['math score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lc5VCoZplX28",
   "metadata": {
    "id": "Lc5VCoZplX28"
   },
   "source": [
    "Calculates the mean of 'math score' in 'd2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214f4d90-e61e-4370-9d48-ae2513608683",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1731827432205,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "214f4d90-e61e-4370-9d48-ae2513608683",
    "outputId": "0b96d2df-7750-4b47-dfd9-e80e838c93b8"
   },
   "outputs": [],
   "source": [
    "d2.mean(axis=0, skipna=True, numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cSN5fDxVlVmp",
   "metadata": {
    "id": "cSN5fDxVlVmp"
   },
   "source": [
    "Calculates the mean of all numeric columns in 'd2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bce31c-51cf-4784-85ee-82089863c8fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1731827432205,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "a3bce31c-51cf-4784-85ee-82089863c8fa",
    "outputId": "8a07f439-fa70-4dce-f270-122937ab3d20"
   },
   "outputs": [],
   "source": [
    "d2['reading score'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QzW99W-mlRro",
   "metadata": {
    "id": "QzW99W-mlRro"
   },
   "source": [
    "Calculates the median of 'reading score' in 'd2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b28b862-09f9-4e82-8006-905e3e53ee9b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1731827432205,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "7b28b862-09f9-4e82-8006-905e3e53ee9b",
    "outputId": "0f6771ef-3965-4dc0-e618-86add57bdbd6"
   },
   "outputs": [],
   "source": [
    "d2['reading score'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lky-CRBMlPQG",
   "metadata": {
    "id": "lky-CRBMlPQG"
   },
   "source": [
    "Calculates the mode of 'reading score' in 'd2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a345f-08ab-446f-87cd-17215b77e926",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1731827432205,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "b52a345f-08ab-446f-87cd-17215b77e926",
    "outputId": "6180f701-5fb6-4d2f-c980-b112a6633a9f"
   },
   "outputs": [],
   "source": [
    "d2.quantile(.2, axis = 0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rlKkvjNulM_p",
   "metadata": {
    "id": "rlKkvjNulM_p"
   },
   "source": [
    "Calculates the 20th percentile of all numeric columns in 'd2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f37e6-fdc9-4a15-b09e-d776fb4c18c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1731827432206,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "610f37e6-fdc9-4a15-b09e-d776fb4c18c2",
    "outputId": "3ef29939-76a4-48d6-810f-8d0f99586f39"
   },
   "outputs": [],
   "source": [
    "d2.quantile([.1, .3, .63, .95], axis = 0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OxdcY4lulJwB",
   "metadata": {
    "id": "OxdcY4lulJwB"
   },
   "source": [
    " Calculates the 10th, 30th, 63rd, and 95th percentiles of all numeric columns in 'd2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939c257b-34dc-4616-a08b-21af154c4faa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1731827432206,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "939c257b-34dc-4616-a08b-21af154c4faa",
    "outputId": "c18a3ea2-da47-41e3-e0e2-ff2fad317d64"
   },
   "outputs": [],
   "source": [
    "d2.quantile([.25, .50, .75], axis = 0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QCKssdZflGXR",
   "metadata": {
    "id": "QCKssdZflGXR"
   },
   "source": [
    "Calculates the 25th, 50th, and 75th percentiles (quartiles) of all numeric columns in 'd2'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cffb1e-bd80-4be1-9813-58e80e67ebc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "executionInfo": {
     "elapsed": 610,
     "status": "ok",
     "timestamp": 1731827646454,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "81cffb1e-bd80-4be1-9813-58e80e67ebc6",
    "outputId": "a9666a18-ec96-4476-b43f-5d150dec57aa"
   },
   "outputs": [],
   "source": [
    "d3 = pd.read_csv('nba.csv')\n",
    "d3.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YSCBMb3vlERi",
   "metadata": {
    "id": "YSCBMb3vlERi"
   },
   "source": [
    "Reads the 'nba.csv' file into a pandas DataFrame named 'd3' and displays the first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da320db4-e17e-4b51-a92f-8a88d0a2f5df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1731827432206,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "da320db4-e17e-4b51-a92f-8a88d0a2f5df",
    "outputId": "ad164d74-b572-4f62-a8e7-2d2f3fa378af"
   },
   "outputs": [],
   "source": [
    "d3.skew(axis=0, skipna=True, numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RsZOFyyRlB98",
   "metadata": {
    "id": "RsZOFyyRlB98"
   },
   "source": [
    "Calculates the skewness of all numeric columns in 'd3'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e9da6-64c1-4d0f-bafc-e896c6229cac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "executionInfo": {
     "elapsed": 544,
     "status": "ok",
     "timestamp": 1731827432733,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "ee0e9da6-64c1-4d0f-bafc-e896c6229cac",
    "outputId": "b1e3962b-dec5-4b27-8d8d-f55c0ac83852"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "d3['Salary'].sort_values().hist().plot(use_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5V6-6Svyk_KY",
   "metadata": {
    "id": "5V6-6Svyk_KY"
   },
   "source": [
    "Creates a histogram of the 'Salary' column in 'd3' after sorting the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb20e6-91b4-4168-8cea-42e8a03564f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1731827471536,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "4dbb20e6-91b4-4168-8cea-42e8a03564f7",
    "outputId": "81087181-ca3f-49c3-b66f-82814c268789"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.boxplot(d3['Salary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aP4sT-_Dk9YA",
   "metadata": {
    "id": "aP4sT-_Dk9YA"
   },
   "source": [
    "Creates a box plot of the 'Salary' column in 'd3' using seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d4390b-d9be-47b6-9065-125164540791",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731827432734,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "53d4390b-d9be-47b6-9065-125164540791",
    "outputId": "afad30a3-a416-4fac-8e05-368b3e7b4ca1"
   },
   "outputs": [],
   "source": [
    "d3.kurtosis(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yRbO28-sk7ep",
   "metadata": {
    "id": "yRbO28-sk7ep"
   },
   "source": [
    "Calculates the kurtosis of all numeric columns in 'd3'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOSD_I3mKhUH"
   },
   "source": [
    "## **Foundations of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yftr8DvXKj4d"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4f9ll6qEKmXR"
   },
   "source": [
    "**Lab 9 - (Probability Distributions)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 418,
     "status": "ok",
     "timestamp": 1731831385666,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "lbylvpGkKciu"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhWWeX8XLXx1"
   },
   "source": [
    "Imports the numpy library and assigns it the alias np."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_r87IxSLMrw"
   },
   "source": [
    "#Binomial\n",
    "Suppose there are twelve multiple choice questions in an English class quiz. Each question has five possible answers, and only one of them is correct. Find the probability of having (a) Exactly 4 ans correct (b) four or less correct answers if a student attempts to answer every question at random.\n",
    "Solution\n",
    "\tSince only one out of five possible answers is correct, the probability of answering a question correctly by random is 1/5=0.2.\n",
    "\tWe can find the probability of having exactly 4 correct answers by random attempts as follows.\n",
    "(4, size=12, prob=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r9R-OOkvKciy",
    "outputId": "23a11c8b-ef53-410d-fce9-75443ed2cdd9"
   },
   "outputs": [],
   "source": [
    "sum(np.random.binomial(12, 0.2, 20000) == 4)/20000. # Exactly four answers correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_NL68b2Leck"
   },
   "source": [
    "Calculates the probability of getting exactly 4 questions correct out of 12 using a simulation with 20000 trials. It uses the binomial function from numpy.random and calculates the proportion of trials where the result is 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGy8W9iQKciz",
    "outputId": "f555c5ce-0056-480e-abf6-9c06379f4785"
   },
   "outputs": [],
   "source": [
    "sum(np.random.binomial(12, 0.2, 20000) <= 4)/20000. # four or less correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruje_fc2LiWv"
   },
   "source": [
    " Calculates the probability of getting 4 or less questions correct using a similar simulation approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6qlNIp-Llfu"
   },
   "source": [
    "A real world example. A company drills 9 wild-cat oil exploration wells, each with an estimated probability of success of 0.1. All nine wells fail. What is the probability of that happening?\n",
    "Let’s do 20,000 trials of the model, and count the number that generate zero positive results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMT5BL9bKci0",
    "outputId": "44ef1d43-b95e-4fec-ecee-c5985aa47d85"
   },
   "outputs": [],
   "source": [
    "sum(np.random.binomial(9, 0.1, 20000) == 0)/20000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4I4AWwtnLt3f"
   },
   "source": [
    "Calculates the probability of all 9 wells failing using a simulation with 20000 trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYVGUAW7Lvrf"
   },
   "source": [
    "#Poisson\n",
    "If there are twelve cars crossing a bridge per minute on average, find the probability of having seventeen or more cars crossing the bridge in a particular minute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qM1xTwVKKci1",
    "outputId": "8344cb70-1772-465a-8a17-db13b0228b5c"
   },
   "outputs": [],
   "source": [
    "sum(np.random.poisson(12, 10000) >=17)/10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4SB-yW-SL0Zw"
   },
   "source": [
    "Calculates the probability of having 17 or more cars crossing the bridge using a simulation with 10000 trials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXQfrif-L2dH"
   },
   "source": [
    "#Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F4IAP1gPKci4",
    "outputId": "30cdd6a9-b0f5-43bd-9f56-8d2fdf584b74"
   },
   "outputs": [],
   "source": [
    "sum(np.random.uniform(0,20,1000) >5)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQmqOM9NKci4",
    "outputId": "890244e9-b587-424e-b242-162920ce60b0"
   },
   "outputs": [],
   "source": [
    "sum(np.random.uniform(0,20,1000) <10)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YGp_LIaXKci5",
    "outputId": "fee16298-2f24-483e-b2f1-acbee91f1ec5"
   },
   "outputs": [],
   "source": [
    "(sum(np.random.uniform(0,20,1000) >5)/1000) - (sum(np.random.uniform(0,20,1000) <10)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ttfgnt7_Kci5"
   },
   "outputs": [],
   "source": [
    "s = np.random.uniform(-1,0,1000)\n",
    "#s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBl8AJ6fKci5",
    "outputId": "b0e65f81-6d51-4335-cb47-be6feea4d54c"
   },
   "outputs": [],
   "source": [
    "np.all(s >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7EiRR-25Kci6",
    "outputId": "ddb68739-164b-4620-c39f-0203da1579dc"
   },
   "outputs": [],
   "source": [
    "np.all(s < 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWaLWPXKL7Hg"
   },
   "source": [
    "The above cells explore the Uniform distribution, generating random numbers between 0 and 20, and calculating probabilities based on conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LQGNIdBL-S2"
   },
   "source": [
    "# Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uatepg8dKci7",
    "outputId": "5e2e4f79-acba-443c-f6a2-0ce8830002bb"
   },
   "outputs": [],
   "source": [
    "mu, sigma = 10, 2 # mean and standard deviation\n",
    "sum(np.random.normal(mu, sigma, 1000) >13)/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9QnAqR-MEFm"
   },
   "source": [
    "Calculates the probability of a value being greater than 13 in a normal distribution with mean 10 and standard deviation 2 using a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmxMSoubKci7"
   },
   "outputs": [],
   "source": [
    " s = np.random.normal(mu, sigma, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_Bp6G4GKci8",
    "outputId": "5b277906-1ea6-4cee-e0d9-882ae5768b98"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "count, bins, ignored = plt.hist(s, 30, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
    "np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
    "linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2felbI5CMG6L"
   },
   "source": [
    "These cells generate random numbers from the normal distribution, plot a histogram, and overlay the theoretical normal distribution curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1F-zrwE0MIvP"
   },
   "source": [
    "#Exponential\n",
    "lamda is 1.4 min time between detections in a Geiger counter. Probability of detecting within 0.6 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1731831390614,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "SMAV_5jAKci9",
    "outputId": "a8fb3225-457f-4d64-d799-f12b10f53068"
   },
   "outputs": [],
   "source": [
    "sum(np.random.exponential(scale=1/4, size=1000) < 0.5) / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gl0j_7M5Kci-",
    "outputId": "cbd8621d-b783-40eb-c573-925e98d7b1fe"
   },
   "outputs": [],
   "source": [
    "1/1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT5W_9UtKci-"
   },
   "outputs": [],
   "source": [
    "#np.random.exponential(scale=1.4, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Znp9s54vKci_",
    "outputId": "2004f67f-bc4f-4e68-9d30-1f84d5facfd4"
   },
   "outputs": [],
   "source": [
    "sum(np.random.exponential(scale=1.4, size=10000) <0.5)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pCbHIsa5Kci_",
    "outputId": "9328642c-04c4-4250-f2f6-58a622548a57"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "x = -(0.5/1.4)\n",
    "1-math.exp( x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOkYeVDRKci_",
    "outputId": "64afc78f-3651-4701-9964-ac4ad3fd0612"
   },
   "outputs": [],
   "source": [
    "sum(np.random.exponential(scale=12, size=10000) <8)/10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGP5bUwmKcjC",
    "outputId": "d505d1fc-b07b-460b-9502-03753e34bfd2"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "x = -(8/12)\n",
    "1-math.exp( x )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jh9X-8RZMgnX"
   },
   "source": [
    "The above cells explore the Exponential distribution, calculating probabilities and comparing them with theoretical values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SlkO2Mgpw0-b",
   "metadata": {
    "id": "SlkO2Mgpw0-b"
   },
   "source": [
    "# **Foundations of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SB9R8r2Mw7Mx",
   "metadata": {
    "id": "SB9R8r2Mw7Mx"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gsJ6sxiBxIQS",
   "metadata": {
    "id": "gsJ6sxiBxIQS"
   },
   "source": [
    "**Lab 10 (Hypothesis Testing)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2atty9G8d4pY",
   "metadata": {
    "id": "2atty9G8d4pY"
   },
   "source": [
    "# **Accessing Models**\n",
    "In data science, a “model” is a set of assumptions about data. Often, models include assumptions about chance processes used to generate data.\n",
    "\n",
    "Sometimes, data scientists have to decide whether or not their models are good. In this section we will discuss two examples of making such decisions. In later sections we will use the methods developed here as the building blocks of a general framework for testing hypotheses.\n",
    "\n",
    "In 1965, the U.S. Supreme Court case *Swain v. Alabama* addressed whether an all-white jury in Talladega County, Alabama, was formed randomly or was the result of racial exclusion. Robert Swain, a Black man convicted of raping a white woman, appealed his death sentence, pointing to the absence of Black jurors on his trial jury, despite 26% of the eligible jurors in the county being Black. The Supreme Court, however, ruled against him, stating that the racial disparity on the jury panel could have been a result of random selection rather than intentional exclusion. To test if this could indeed be attributed to chance, a simulation model can be applied to evaluate the likelihood of obtaining a similar outcome in a random selection. By simulating the selection of 100 jurors from a population where 26% are Black, we can compare the actual jury composition with the outcomes predicted by the random selection model. If the number of Black jurors in the simulated samples aligns poorly with the observed panel, this would suggest that the jury selection was likely not random, supporting Swain's claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634ad12-fd04-409f-b33d-1e4c9543c549",
   "metadata": {
    "id": "5634ad12-fd04-409f-b33d-1e4c9543c549"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adff1733-547a-484f-9110-985ffadbf686",
   "metadata": {
    "id": "adff1733-547a-484f-9110-985ffadbf686"
   },
   "source": [
    "# U.S. Supreme Court, 1965: Swain vs. Alabama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_zIqI2dKhJYW",
   "metadata": {
    "id": "_zIqI2dKhJYW"
   },
   "source": [
    "**The sample_proportions** function will take two arguments:\n",
    "\n",
    "the sample size\n",
    "\n",
    "the distribution of the categories in the population, as a list or array of proportions that add up to 1\n",
    "\n",
    "As the function uses a numpy ‘method’ an array will be returned containing the distribution of the categories in a random sample of the given size taken from the population. This is an array consisting of the sample proportions in all the different categories.\n",
    "\n",
    "To see how to use this, remember that according to our model, the panel is selected at random from a population of men among whom 26% were black and 74% were not. Thus the distribution of the two categories can be represented as the list [0.26, 0.74], which we have assigned to the name eligible_population. Now let’s sample at random 100 times from this distribution, and see what proportions of the two categories we get in our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf94700-9b04-491d-bb29-90c5c73e23e2",
   "metadata": {
    "id": "caf94700-9b04-491d-bb29-90c5c73e23e2"
   },
   "outputs": [],
   "source": [
    "def sample_proportions(sample_size, probabilities):\n",
    "    return np.random.multinomial(sample_size, probabilities) / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536b688-58cd-4852-9bf5-15c6bb5b2447",
   "metadata": {
    "id": "5536b688-58cd-4852-9bf5-15c6bb5b2447",
    "outputId": "f36a2942-2fe7-4c32-c093-3cb324a70a2a"
   },
   "outputs": [],
   "source": [
    "eligible_population = [0.26, 0.74]\n",
    "sample_proportions(100, eligible_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a12712-1c9f-4115-b3ea-0f0606dee3e7",
   "metadata": {
    "id": "c5a12712-1c9f-4115-b3ea-0f0606dee3e7",
    "outputId": "fce04e6d-704e-435d-ff4c-00526f8b1715"
   },
   "outputs": [],
   "source": [
    "(100 * sample_proportions(100, eligible_population)).item(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MBE2adSMg0cU",
   "metadata": {
    "id": "MBE2adSMg0cU"
   },
   "source": [
    "**Running the Simulation**\n",
    "\n",
    "To get a sense of the variability without running the cell over and over, let’s generate 10,000 simulated values of the count.\n",
    "\n",
    "The code follows the same steps that we have used in every simulation. First, we define a function to simulate one value of the count, using the code we wrote above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93dde45-8d61-45b0-9d49-ea85dc10b3f5",
   "metadata": {
    "id": "c93dde45-8d61-45b0-9d49-ea85dc10b3f5"
   },
   "outputs": [],
   "source": [
    "def one_simulated_count():\n",
    "    return (100 * sample_proportions(100, eligible_population)).item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e596404-08ae-4435-815b-56a3941806ad",
   "metadata": {
    "id": "8e596404-08ae-4435-815b-56a3941806ad"
   },
   "outputs": [],
   "source": [
    "counts = np.array([])\n",
    "\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    counts = np.append(counts, one_simulated_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adFGQRGjgcHd",
   "metadata": {
    "id": "adFGQRGjgcHd"
   },
   "source": [
    "**The Prediction**\n",
    "\n",
    "To interpret the results of our simulation, we start as usual by visualizing the results by an empirical histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e77564-9c0f-4c9d-af69-12b9d2e370e0",
   "metadata": {
    "id": "f4e77564-9c0f-4c9d-af69-12b9d2e370e0"
   },
   "outputs": [],
   "source": [
    "def hist_with_bins(df, bins, plot_title, x_axis_label, y_axis_label):\n",
    "    source = df\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.hist(source, bins=bins, density=True, alpha=0.8, ec='white')\n",
    "    y_vals = ax1.get_yticks()\n",
    "    y_label = y_axis_label\n",
    "    x_label = x_axis_label\n",
    "    ax1.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title('%s' % plot_title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d3b68-29ec-494c-86f6-065ba443c0d8",
   "metadata": {
    "id": "875d3b68-29ec-494c-86f6-065ba443c0d8",
    "outputId": "bdb958b9-177a-4dde-9e15-b999851d733b"
   },
   "outputs": [],
   "source": [
    "random_sample_counts = pd.DataFrame({'Count in a Random Sample':counts})\n",
    "hist_with_bins(random_sample_counts, np.arange(5.5, 46.6, 1),\n",
    "               'Random Sampling', 'Count in Random Sample', 'Percent per Unit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NrcwK4OqhY2a",
   "metadata": {
    "id": "NrcwK4OqhY2a"
   },
   "source": [
    "**Comparing the Prediction and the Data**\n",
    "\n",
    "Though the simulated counts are quite varied, very few of them came out to be eight or less. The value eight is far out in the left hand tail of the histogram. It’s the red dot on the horizontal axis of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12dda2a-e210-42b1-94a5-d3c9977ac023",
   "metadata": {
    "id": "e12dda2a-e210-42b1-94a5-d3c9977ac023",
    "outputId": "a14297f4-43aa-4da5-fb48-bde4fabc54fb"
   },
   "outputs": [],
   "source": [
    "bins = np.arange(5.5, 46.6, 1)\n",
    "unit = ''\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(random_sample_counts, bins=bins, density=True, alpha=0.8, ec='white', zorder=5)\n",
    "ax.scatter(8,0,color='red', s=30, zorder=10).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Count in Random Sample'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59ae2d-e6ee-4818-8e95-a82fc214af5b",
   "metadata": {
    "id": "1d59ae2d-e6ee-4818-8e95-a82fc214af5b"
   },
   "source": [
    "# Mendel’s Pea Flowers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wpumU1DZiTUM",
   "metadata": {
    "id": "wpumU1DZiTUM"
   },
   "source": [
    "The method of assessing models through simulation is general and can apply in various contexts, including jury selection and genetics. For example, in *Swain v. Alabama*, a simulation showed that selecting 100 jurors at random from a population with 26% Black members is unlikely to yield only 8 Black jurors, suggesting the jury was not randomly selected. Similarly, Gregor Mendel, in his experiments with pea plants, hypothesized a model where purple-flowering plants would occur with a probability of 75%. To test this model, we can simulate plant samples and measure the distance between the observed proportion of purple flowers and the expected 75%. Large deviations from 75% would indicate the model may not fit the observed data. This approach, which involves comparing actual data with the results of model-based simulations, allows us to test the validity of assumptions across various scientific and legal settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13ee346-bced-4449-b219-63698e3dc5a1",
   "metadata": {
    "id": "e13ee346-bced-4449-b219-63698e3dc5a1"
   },
   "outputs": [],
   "source": [
    "def distance_from_75(p):\n",
    "    return abs(100*p - 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd772443-d464-444c-8260-1c4f23641393",
   "metadata": {
    "id": "cd772443-d464-444c-8260-1c4f23641393"
   },
   "outputs": [],
   "source": [
    "model_proportions = [0.75, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e64bf0-7a45-438e-a546-0ad8fb6c3b39",
   "metadata": {
    "id": "68e64bf0-7a45-438e-a546-0ad8fb6c3b39",
    "outputId": "1ba422ad-a9cf-4a93-ab2b-e4ae420a037a"
   },
   "outputs": [],
   "source": [
    "proportion_purple_in_sample = sample_proportions(929, model_proportions).item(0)\n",
    "distance_from_75(proportion_purple_in_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3LEJ-VGJicq-",
   "metadata": {
    "id": "3LEJ-VGJicq-"
   },
   "source": [
    "**Running the Simulation**\n",
    "\n",
    "To get a sense of how variable the distance could be, we have to simulate it many more times.\n",
    "\n",
    "We will generate 10,000 values of the distance. As before, we will first use the code we developed above to define a function that returns one simulated value Mendel’s hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca647b-f549-4494-b718-8122e3e3655c",
   "metadata": {
    "id": "c0ca647b-f549-4494-b718-8122e3e3655c"
   },
   "outputs": [],
   "source": [
    "def one_simulated_distance():\n",
    "    proportion_purple_in_sample = sample_proportions(929, model_proportions).item(0)\n",
    "    return distance_from_75(proportion_purple_in_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ynFZPwalikO5",
   "metadata": {
    "id": "ynFZPwalikO5"
   },
   "source": [
    "Next, we will use a for loop to create 10,000 such simulated distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f80fe0-c6bd-494c-8774-b05823cab220",
   "metadata": {
    "id": "29f80fe0-c6bd-494c-8774-b05823cab220"
   },
   "outputs": [],
   "source": [
    "distances = np.array([])\n",
    "\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    distances = np.append(distances, one_simulated_distance())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WvEuDauzioik",
   "metadata": {
    "id": "WvEuDauzioik"
   },
   "source": [
    "**The Prediction**\n",
    "\n",
    "The empirical histogram of the simulated values shows the distribution of the distance as predicted by Mendel’s model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74a3278-6c93-44ee-bd03-81b3eefe955e",
   "metadata": {
    "id": "c74a3278-6c93-44ee-bd03-81b3eefe955e",
    "outputId": "307e0bb3-7bda-483e-9a16-785a4f0bc956"
   },
   "outputs": [],
   "source": [
    "sample_distance = pd.DataFrame({'Distance between Sample % and 75%':distances})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(sample_distance, density=True, alpha=0.8, ec='white', zorder=5)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Distance between Sample % and 75%'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EUskBnGqiwg0",
   "metadata": {
    "id": "EUskBnGqiwg0"
   },
   "source": [
    "Look on the horizontal axis to see the typical values of the distance, as predicted by the model. They are rather small. For example, a high proportion of the distances are in the range 0 to 1, meaning that for a high proportion of the samples, the percent of purple-flowering plants is within 1% of 75%, that is, the sample percent is in the range 74% to 76%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HyPbQ6Dti02M",
   "metadata": {
    "id": "HyPbQ6Dti02M"
   },
   "source": [
    "**Comparing the Prediction and the Data**\n",
    "\n",
    "To assess the model, we have to compare this prediction with the data. Mendel recorded the number of purple and white flowering plants. Among the 929 plants that he grew, 705 were purple flowering. That’s just about 75.89%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796441b-797b-4dc3-ba05-cad8e0b47f25",
   "metadata": {
    "id": "5796441b-797b-4dc3-ba05-cad8e0b47f25",
    "outputId": "30d1f90b-2422-44ae-adde-899795383723"
   },
   "outputs": [],
   "source": [
    "705 / 929"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dd3206-4c63-4d10-a1ce-69586e981919",
   "metadata": {
    "id": "97dd3206-4c63-4d10-a1ce-69586e981919",
    "outputId": "f347214b-df75-406b-da56-2e985222930b"
   },
   "outputs": [],
   "source": [
    "observed_statistic = distance_from_75(705/929)\n",
    "observed_statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L29q-Fz5jB9c",
   "metadata": {
    "id": "L29q-Fz5jB9c"
   },
   "source": [
    "The cell below redraws the histogram with the observed value plotted on the horizontal axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9fdc70-3acb-4ffd-9cec-3f2d30ad362f",
   "metadata": {
    "id": "bb9fdc70-3acb-4ffd-9cec-3f2d30ad362f",
    "outputId": "8c9db941-86df-4661-f767-7324029f43aa"
   },
   "outputs": [],
   "source": [
    "distance_0_75 = pd.DataFrame({'Distance between Sample % and 75%':distances})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(distance_0_75, density=True, alpha=0.8, ec='white', zorder=5)\n",
    "ax.scatter(observed_statistic, 0, color='red', s=30, zorder=10).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Distance between Sample % and 75%'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Mi2Q4A_6jiq0",
   "metadata": {
    "id": "Mi2Q4A_6jiq0"
   },
   "source": [
    "# **2. Multiple Categories**\n",
    "\n",
    "We have developed a way of assessing models about chance processes that generate data in two categories. The method extends to models involving data in multiple categories. The process of assessment is the same as before, the only difference being that we have to come up with a new statistic to simulate.\n",
    "\n",
    "Let’s do this in an example that addresses the same kind of question that was raised in the case of Robert Swain’s jury panel. This time, the data are more recent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d742803-9218-41de-a01a-72c9d6c574b2",
   "metadata": {
    "id": "2d742803-9218-41de-a01a-72c9d6c574b2"
   },
   "source": [
    "# Jury Selection in Alameda County"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZIrr0iB6kCUx",
   "metadata": {
    "id": "ZIrr0iB6kCUx"
   },
   "source": [
    "In 2010, the ACLU of Northern California released a report on jury selection in Alameda County, focusing on the ethnic composition of jury panels and highlighting potential disparities. According to California law, jury panels are meant to be random samples that represent the community’s demographic makeup. However, in an analysis of 11 felony trial jury panels from 2009 to 2010, the ACLU found discrepancies in representation among ethnic groups. They reviewed data from 1,453 individuals who reported for jury service and compared the ethnic distribution in this group with that of all eligible jurors in Alameda County. The report questioned whether these jury panels truly represented a cross-section of the community and proposed reforms to ensure greater diversity among prospective jurors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfae35-0d69-4cba-bf76-bf2d2dfdf9cb",
   "metadata": {
    "id": "bfdfae35-0d69-4cba-bf76-bf2d2dfdf9cb",
    "outputId": "d507977f-aa59-45ef-e946-e831acb660cd"
   },
   "outputs": [],
   "source": [
    "jury = pd.DataFrame(\n",
    "    {'Ethnicity':np.array(['Asian', 'Black', 'Latino', 'White', 'Other']),\n",
    "    'Eligible':np.array([0.15, 0.18, 0.12, 0.54, 0.01]),\n",
    "    'Panels':np.array([0.26, 0.08, 0.08, 0.54, 0.04])}\n",
    ")\n",
    "\n",
    "jury"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "V_VfozMUkJ3c",
   "metadata": {
    "id": "V_VfozMUkJ3c"
   },
   "source": [
    "Some ethnicities are overrepresented and some are underrepresented on the jury panels in the study. A bar chart is helpful for visualizing the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b372f-99ba-40b5-bcbe-b4c88160fe6c",
   "metadata": {
    "id": "a86b372f-99ba-40b5-bcbe-b4c88160fe6c",
    "outputId": "7b8a6e34-6003-4545-a541-028453c880b1"
   },
   "outputs": [],
   "source": [
    "jury = jury.sort_values(by=['Ethnicity'], ascending=False)\n",
    "jury.plot.barh('Ethnicity', width=0.8, figsize=(8,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AJvqJTsnkXTI",
   "metadata": {
    "id": "AJvqJTsnkXTI"
   },
   "source": [
    "**Comparison with Panels Selected at Random**\n",
    "\n",
    "What if we select a random sample of 1,453 people from the population of eligible jurors? Will the distribution of their ethnicities look like the distribution of the panels above?\n",
    "\n",
    "We can answer these questions by using sample_proportions and augmenting the jury table with a column of the proportions in our sample.\n",
    "\n",
    "Technical note. Random samples of prospective jurors would be selected without replacement. However, when the size of a sample is small relative to the size of the population, sampling without replacement resembles sampling with replacement; the proportions in the population don’t change much between draws. The population of eligible jurors in Alameda County is over a million, and compared to that, a sample size of about 1500 is quite small. We will therefore sample with replacement.\n",
    "\n",
    "In the cell below, we sample at random 1453 times from the distribution of eligible jurors, and display the distribution of the random sample along with the distributions of the eligible jurors and the panel in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be146ced-bcf9-4363-a371-17ccf0263eb5",
   "metadata": {
    "id": "be146ced-bcf9-4363-a371-17ccf0263eb5"
   },
   "outputs": [],
   "source": [
    "def sample_proportions(sample_size, probabilities):\n",
    "    return np.random.multinomial(sample_size, probabilities) / sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935f16cf-7257-42ae-bc7e-a45118ad30de",
   "metadata": {
    "id": "935f16cf-7257-42ae-bc7e-a45118ad30de",
    "outputId": "68542f31-9354-424c-d530-2741fe8b3511"
   },
   "outputs": [],
   "source": [
    "jury1 = jury.copy()\n",
    "\n",
    "eligible_population = jury1['Eligible']\n",
    "sample_distribution = sample_proportions(1453, eligible_population)\n",
    "\n",
    "panels_and_sample = jury1\n",
    "panels_and_sample['Random Sample'] = sample_distribution\n",
    "panels_and_sample = panels_and_sample.sort_values(['Ethnicity'], ascending=True)\n",
    "panels_and_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d56d72-74a8-4f27-b679-f263b6ee172f",
   "metadata": {
    "id": "35d56d72-74a8-4f27-b679-f263b6ee172f",
    "outputId": "229ffda6-6033-4b29-83f8-9f6df30b2e26"
   },
   "outputs": [],
   "source": [
    "panels_and_sample.plot.barh('Ethnicity', width=0.8, figsize=(10,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sKhxY3lukk7k",
   "metadata": {
    "id": "sKhxY3lukk7k"
   },
   "source": [
    "The bar chart shows that the distribution of the random sample resembles the eligible population but the distribution of the panels does not.\n",
    "\n",
    "To assess whether this observation is particular to one random sample or more general, we can simulate multiple panels under the model of random selection and see what the simulations predict. But we won’t be able to look at thousands of bar charts like the one above. We need a statistic that will help us assess whether or not the model or random selection is supported by the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AQPQV7cMktUH",
   "metadata": {
    "id": "AQPQV7cMktUH"
   },
   "source": [
    "**A New Statistic: The Distance between Two Distributions**\n",
    "\n",
    "We know how to measure how different two numbers are – if the numbers are x\n",
    " and y\n",
    ", the distance between them is |x−y|\n",
    ". Now we have to quantify the distance between two distributions. For example, we have to measure the distance between the blue and gold distributions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd7d353-89b8-46ba-9373-c11451b24b25",
   "metadata": {
    "id": "efd7d353-89b8-46ba-9373-c11451b24b25",
    "outputId": "12f362b2-2b3e-4a66-cd96-37ab181fd9d5"
   },
   "outputs": [],
   "source": [
    "jury.plot.barh('Ethnicity', width=0.8, figsize=(8,4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HHzuCs-uk1V2",
   "metadata": {
    "id": "HHzuCs-uk1V2"
   },
   "source": [
    "For this we will compute a quantity called the total variation distance between two distributions. The calculation is as an extension of the calculation of the distance between two numbers.\n",
    "\n",
    "To compute the total variation distance, we first take the difference between the two proportions in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1923da-9703-42bb-b908-21a533d94681",
   "metadata": {
    "id": "5d1923da-9703-42bb-b908-21a533d94681",
    "outputId": "6a7ce199-d74d-4dd1-ee52-7b6a983c3bca"
   },
   "outputs": [],
   "source": [
    "jury_with_diffs = jury.sort_values(by=['Ethnicity']).copy()\n",
    "jury_with_diffs['Difference'] = jury['Panels'] - jury['Eligible']\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pQwdd7K7k8J2",
   "metadata": {
    "id": "pQwdd7K7k8J2"
   },
   "source": [
    "Take a look at the column Difference and notice that the sum of its entries is 0: the positive entries add up to 0.14, exactly canceling the total of the negative entries which is -0.14.\n",
    "\n",
    "This is numerical evidence of the fact that in the bar chart, the red bars exceed the blue bars by exactly as much as the blue bars exceed the red. The proportions in each of the two columns Panels and Eligible add up to 1, and so the give-and-take between their entries must add up to 0.\n",
    "\n",
    "To avoid the cancellation, we drop the negative signs and then add all the entries. But this gives us two times the total of the positive entries (equivalently, two times the total of the negative entries, with the sign removed). So we divide the sum by 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f191632-bbff-497e-8682-c0cf154a3d1b",
   "metadata": {
    "id": "2f191632-bbff-497e-8682-c0cf154a3d1b",
    "outputId": "ed6cef66-9426-477c-dbe4-75bc5c31c0c0"
   },
   "outputs": [],
   "source": [
    "jury_with_diffs['Absolute Difference'] =  np.abs(jury_with_diffs['Difference'])\n",
    "jury_with_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8dcb2-bfe6-4eb2-8919-734e1b5b4151",
   "metadata": {
    "id": "a6d8dcb2-bfe6-4eb2-8919-734e1b5b4151",
    "outputId": "4bf00062-671d-4fb2-ab79-a692c29887b3"
   },
   "outputs": [],
   "source": [
    "jury_with_diffs['Absolute Difference'].sum() / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fEUy5XN7lJ2W",
   "metadata": {
    "id": "fEUy5XN7lJ2W"
   },
   "source": [
    "This quantity 0.14 is the total variation distance (TVD) between the distribution of ethnicities in the eligible juror population and the distribution in the panels.\n",
    "\n",
    "We could have obtained the same result by just adding the positive differences. But our method of including all the absolute differences eliminates the need to keep track of which differences are positive and which are not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CdrxDW66lQx8",
   "metadata": {
    "id": "CdrxDW66lQx8"
   },
   "source": [
    "**Simulating One Value of the Statistic**\n",
    "\n",
    "We will use the total variation distance between distributions as the statistic to simulate. It will help us decide whether the model of random selection is good, because large values of the distance will be evidence against the model.\n",
    "\n",
    "Keep in mind that the observed value of our statistic is 0.14, calculated above.\n",
    "\n",
    "Since we are going to be computing total variation distance repeatedly, we will write a function to compute it.\n",
    "\n",
    "The function total_variation_distance returns the TVD between distributions in two arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa4f8b8-3ab8-4cf7-a599-ee29d856adf8",
   "metadata": {
    "id": "6fa4f8b8-3ab8-4cf7-a599-ee29d856adf8"
   },
   "outputs": [],
   "source": [
    "def total_variation_distance(distribution_1, distribution_2):\n",
    "    return sum(np.abs(distribution_1 - distribution_2)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hFlzyBszlaaI",
   "metadata": {
    "id": "hFlzyBszlaaI"
   },
   "source": [
    "This function will help us calculate our statistic in each repetition of the simulation. But first, let’s check that it gives the right answer when we use it to compute the distance between the blue (eligible) and gold (panels) distributions above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84dc4fa-70a0-4feb-8d1b-67af4dcdae6b",
   "metadata": {
    "id": "e84dc4fa-70a0-4feb-8d1b-67af4dcdae6b",
    "outputId": "87dc1c11-c708-43aa-9270-4122ed9a2ca1"
   },
   "outputs": [],
   "source": [
    "total_variation_distance(jury['Panels'], jury['Eligible'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3H1XOAb6li6K",
   "metadata": {
    "id": "3H1XOAb6li6K"
   },
   "source": [
    "This agrees with the value that we computed directly without using the function.\n",
    "\n",
    "In the cell below we use the function to compute the TVD between the distributions of the eligible jurors and one random sample. This is the code for simulating one value of our statistic. Recall that eligible_population is the array containing the distribution of the eligible jurors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37dac10-bcb5-4346-941f-45ccf7005b25",
   "metadata": {
    "id": "c37dac10-bcb5-4346-941f-45ccf7005b25",
    "outputId": "10815118-426f-4003-ba68-2b88f0a69749"
   },
   "outputs": [],
   "source": [
    "sample_distribution = sample_proportions(1453, eligible_population)\n",
    "total_variation_distance(sample_distribution, eligible_population)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oi2IY7emlwyG",
   "metadata": {
    "id": "oi2IY7emlwyG"
   },
   "source": [
    "Notice that the distance is quite a bit smaller than 0.14, the distance between the distribution of the panels and the eligible jurors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lC78WIeWlygU",
   "metadata": {
    "id": "lC78WIeWlygU"
   },
   "source": [
    "**Predicting the Statistic Under the Model of Random Selection**\n",
    "\n",
    "The total variation distance between the distributions of the random sample and the eligible jurors is the statistic that we are using to measure the distance between the two distributions. By repeating the process of sampling, we can see how much the statistic varies across different random samples.\n",
    "\n",
    "The code below simulates the statistic based on a large number of replications of the random sampling process, following our usual sequence of steps for simulation. We first define a function that returns one simulated value of the total variation distance under the hypothesis of random selection. Then we use our function in a for loop to create an array tvds consisting of 5,000 such distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fffb67-1611-42e0-8c6b-75096570bc36",
   "metadata": {
    "id": "c0fffb67-1611-42e0-8c6b-75096570bc36"
   },
   "outputs": [],
   "source": [
    "def one_simulated_tvd():\n",
    "    sample_distribution = sample_proportions(1453, eligible_population)\n",
    "    return total_variation_distance(sample_distribution, eligible_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243266af-cc2a-4714-964a-7c16cf713175",
   "metadata": {
    "id": "243266af-cc2a-4714-964a-7c16cf713175"
   },
   "outputs": [],
   "source": [
    "tvds = np.array([])\n",
    "\n",
    "repetitions = 5000\n",
    "for i in np.arange(repetitions):\n",
    "    tvds = np.append(tvds, one_simulated_tvd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rFvMmxJrl_5D",
   "metadata": {
    "id": "rFvMmxJrl_5D"
   },
   "source": [
    "The empirical histogram of the simulated distances shows that drawing 1453 jurors at random from the pool of eligible candidates results in a distribution that rarely deviates from the eligible jurors’ race distribution by more than about 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad5bd03-8dd3-482b-afba-e1f4eaf9d537",
   "metadata": {
    "id": "1ad5bd03-8dd3-482b-afba-e1f4eaf9d537",
    "outputId": "fb9d4be5-e864-4823-eaa7-242de092308d"
   },
   "outputs": [],
   "source": [
    "TVD = pd.DataFrame({'TVD':tvds})\n",
    "unit = ''\n",
    "fig, ax1 = plt.subplots()\n",
    "ax1.hist(TVD, bins=np.arange(0, 0.2, 0.005), density=True, alpha=0.8, ec='white')\n",
    "y_vals = ax1.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'TVD'\n",
    "ax1.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yFRVr_dUmcHn",
   "metadata": {
    "id": "yFRVr_dUmcHn"
   },
   "source": [
    "# **3. Decisions and Uncertainty**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VgehFoJNmfOI",
   "metadata": {
    "id": "VgehFoJNmfOI"
   },
   "source": [
    "Statistical hypothesis testing helps make decisions when data could be explained by chance or a meaningful effect. Outcomes are not always clear-cut, so statistical conventions and judgment are used to determine whether observed data align with the null hypothesis. Visualizations and test statistics provide evidence, but some decisions still require careful interpretation.\n",
    "\n",
    "**Step 1: The Hypotheses**\n",
    "Formulate two hypotheses: a null hypothesis, which assumes the data is due to random chance, and an alternative hypothesis, which suggests that other factors affect the data. The null hypothesis provides a model to simulate data.\n",
    "\n",
    "**Step 2: The Test Statistic**\n",
    "Select a statistic that will indicate which hypothesis is more likely. For example, the distance between the observed data and an expected value can serve as a test statistic; large distances suggest the data may not fit the null hypothesis.\n",
    "\n",
    "**Step 3: Distribution of the Test Statistic Under the Null Hypothesis**\n",
    "Simulate the test statistic repeatedly under the assumptions of the null hypothesis to understand its possible values. The resulting distribution gives context to the observed value and helps determine the likelihood of observing such data by chance.\n",
    "\n",
    "**Step 4: Conclusion of the Test**\n",
    "Compare the observed test statistic to the simulated distribution. If it’s consistent, the data supports the null hypothesis. If not, the null hypothesis is rejected in favor of the alternative, suggesting other factors influenced the data.\n",
    "\n",
    "Here is an example where the decision requires judgment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42ad794-e5a6-4568-9620-d2b67bb1d02d",
   "metadata": {
    "id": "e42ad794-e5a6-4568-9620-d2b67bb1d02d"
   },
   "source": [
    "# The GSI’s Defense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AFxCQ9TvnMyg",
   "metadata": {
    "id": "AFxCQ9TvnMyg"
   },
   "source": [
    "In a Berkeley Statistics class of 350 students, Section 3 students noticed their midterm scores were lower on average than the rest of the class, leading them to question their GSI's teaching. However, the GSI suggested this could simply be due to random variation. To investigate, we set up hypotheses: the **null hypothesis** assumes Section 3’s average score could occur by chance if a random group of students were selected, while the **alternative hypothesis** suggests Section 3’s average is unusually low. Testing this hypothesis involves comparing Section 3's average to simulated averages from random samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Dc29lK0KnjsZ",
   "metadata": {
    "id": "Dc29lK0KnjsZ"
   },
   "source": [
    "The table scores contains the section number and midterm score for each student in the class. The midterm scores were integers in the range 0 through 25; 0 means that the student didn’t take the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5522afb0-0925-429b-9a78-7e88d801aa17",
   "metadata": {
    "id": "5522afb0-0925-429b-9a78-7e88d801aa17",
    "outputId": "1ea85c3c-0b9f-4e01-d529-e28de4125ac6"
   },
   "outputs": [],
   "source": [
    "scores = pd.read_csv('scores_by_section.csv')\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inDFviEAnsJ9",
   "metadata": {
    "id": "inDFviEAnsJ9"
   },
   "source": [
    "To find the average or mean score in each section, we will use groupby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0c08d4-5250-4031-b17c-01eb56709fa4",
   "metadata": {
    "id": "cb0c08d4-5250-4031-b17c-01eb56709fa4",
    "outputId": "a650ffe7-4f53-45a3-e33a-fc21a188d926"
   },
   "outputs": [],
   "source": [
    "section_averages = scores.groupby(['Section']).mean()\n",
    "section_averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hG8N-e68nwcb",
   "metadata": {
    "id": "hG8N-e68nwcb"
   },
   "source": [
    "The average score of Section 3 is 13.667, which does look low compared to the other section averages. But is it lower than the average of a section of the same size selected at random from the class?\n",
    "\n",
    "To answer this, we can select a section at random from the class and find its average. To select a section at random to we need to know how big Section 3 is, which we can by once again using group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed8d92d-d12d-4d40-8230-4f1f5c060c72",
   "metadata": {
    "id": "0ed8d92d-d12d-4d40-8230-4f1f5c060c72",
    "outputId": "ae0c6237-42a6-4094-8c52-75b3ee00b429"
   },
   "outputs": [],
   "source": [
    "scores.groupby('Section').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iJvTo_Hrn2xV",
   "metadata": {
    "id": "iJvTo_Hrn2xV"
   },
   "source": [
    "Section 3 had 27 students.\n",
    "\n",
    "Now we can figure out how to create one simulated value of our test statistic, the random sample average.\n",
    "\n",
    "First we have to select 27 scores at random without replacement. Since the data are already in a table, we will use the Table method sample.\n",
    "\n",
    "Remember that by default, sample draws with replacement. The optional argument with_replacement = False produces a random sample drawn without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4bcfcc-159e-45e1-b81f-7be9df7e3424",
   "metadata": {
    "id": "9b4bcfcc-159e-45e1-b81f-7be9df7e3424"
   },
   "outputs": [],
   "source": [
    "scores_only = scores.drop(columns=['Section'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6cd277-2b06-4798-8e98-6019ffb98486",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 936,
     "status": "error",
     "timestamp": 1731834300285,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "ab6cd277-2b06-4798-8e98-6019ffb98486",
    "outputId": "9495376b-31b4-4b33-bec9-72b5eaf038c5"
   },
   "outputs": [],
   "source": [
    "random_sample = scores_only.sample(27, replace=False)\n",
    "random_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418ac82-4bed-4de8-9a8b-1ea3bb50738d",
   "metadata": {
    "id": "8418ac82-4bed-4de8-9a8b-1ea3bb50738d",
    "outputId": "77ba07bd-5968-4fd1-c578-4f5cf5ba0e87"
   },
   "outputs": [],
   "source": [
    "np.average(random_sample['Midterm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zDl1IQn6oAwK",
   "metadata": {
    "id": "zDl1IQn6oAwK"
   },
   "source": [
    "That’s the average of 27 randomly selected scores.\n",
    "\n",
    "The cell below collects the code necessary for generating this random average.\n",
    "\n",
    "Now we can simulate the random sample average by repeating the calculation multple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52624d0-7352-414d-8774-16b3a26a8c44",
   "metadata": {
    "id": "a52624d0-7352-414d-8774-16b3a26a8c44"
   },
   "outputs": [],
   "source": [
    "def random_sample_average():\n",
    "    random_sample = scores_only.sample(27, replace=False)\n",
    "    return np.average(random_sample['Midterm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc3d1b-c308-4c2a-b6e7-cb6f335c6f29",
   "metadata": {
    "id": "f6cc3d1b-c308-4c2a-b6e7-cb6f335c6f29",
    "outputId": "ed6e3923-018c-4837-d748-a4cfe68e9c75"
   },
   "outputs": [],
   "source": [
    "sample_averages = np.array([])\n",
    "\n",
    "repetitions = 10000\n",
    "for i in np.arange(repetitions):\n",
    "    sample_averages = np.append(sample_averages, random_sample_average())\n",
    "\n",
    "sample_averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "okNddPxkoL89",
   "metadata": {
    "id": "okNddPxkoL89"
   },
   "source": [
    "Here is the histogram of the simulated averages. It shows the distribution of what the Section 3 average might have been, if Section 3 had been selected at random from the class.\n",
    "\n",
    "The observed Section 3 average score of 13.667 is shown as a red dot on the horizontal axis. You can ignore the last line of code; it just draws the dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56056b7f-3232-4021-8757-5a023383e7a0",
   "metadata": {
    "id": "56056b7f-3232-4021-8757-5a023383e7a0",
    "outputId": "1440c60e-54f9-4fdf-9c11-95867e6d53fc"
   },
   "outputs": [],
   "source": [
    "averages_tbl = pd.DataFrame({'Sample Average':sample_averages})\n",
    "observed_statistic = 13.667\n",
    "unit = ''\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(averages_tbl, bins=20,density=True, alpha=0.8, ec='white', zorder=5)\n",
    "ax.scatter(observed_statistic, 0, color='red', s=30, zorder=10).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Sample Average'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aececd2d-e48f-42e0-adf2-879f669596de",
   "metadata": {
    "id": "aececd2d-e48f-42e0-adf2-879f669596de"
   },
   "source": [
    "# **4. Error Probabilities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "O_4WApYzoWxE",
   "metadata": {
    "id": "O_4WApYzoWxE"
   },
   "source": [
    "In the process by which we decide which of two hypotheses is better supported by our data, the final step involves a judgment about the consistency of the data and the null hypothesis. While this step results in a good decision a vast majority of the time, it can sometimes lead us astray. The reason is chance variation. For example, even when the null hypothesis is true, chance variation might cause the sample to look quite different from what the null hypothesis predicts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_uqL4f6pozxj",
   "metadata": {
    "id": "_uqL4f6pozxj"
   },
   "source": [
    "# **Wrong Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-zErQCVwo1n4",
   "metadata": {
    "id": "-zErQCVwo1n4"
   },
   "source": [
    "**The Chance of an Error :**\n",
    "Suppose you want to test whether a coin is fair or not. Then the hypotheses are:\n",
    "\n",
    "**Null:** The coin is fair. That is, the results are like draws made at random with replacement from Heads, Tails.\n",
    "\n",
    "**Alternative:** The coin is not fair.\n",
    "\n",
    "Suppose you are going to test this hypothesis based on 2000 tosses of the coin. You would expect a fair coin to land heads 1000 times out of 2000, so a reasonable test statistic to use is\n",
    "\n",
    "test statistic = ∣ number of heads−1000 ∣\n",
    "\n",
    "Small values of this statistic favor the null hypothesis, and large values favor the alternative.\n",
    "\n",
    "We have simulated this statistic under the null hypothesis many times, and drawn its empirical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005a9f8-cf9c-4751-b200-f4d75ae86275",
   "metadata": {
    "id": "0005a9f8-cf9c-4751-b200-f4d75ae86275",
    "outputId": "a438d51a-fba6-4b43-e81c-3c31c6c6b6be"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "statistics = np.random.binomial(100, 0.3, 1000)\n",
    "\n",
    "results = pd.DataFrame({'|Number of Heads - 1000|': statistics})\n",
    "unit = ''\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(results['|Number of Heads - 1000|'], bins=np.arange(0, 81, 5), density=True, alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot([40, 40], [0, 3.5], color='gold', lw=2, zorder=10)\n",
    "\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = '|Number of Heads - 1000|'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('Distribution of Number of Heads')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muVu0YKKpTnn",
   "metadata": {
    "id": "muVu0YKKpTnn"
   },
   "source": [
    "The area to the right of 45 (where the gold line is) is about 5%. Large values of the test statistic favor the alternative. So if the test statistic comes out to be 45 or more, the test will conclude that the coin is unfair.\n",
    "\n",
    "However, as the figure shows, a fair coin can produce test statistics with values 45 or more. In fact it does so with chance about 5%.\n",
    "\n",
    "So if the coin is fair and our test uses a 5% cutoff for deciding whether it is fair or not, then there is about a 5% chance that the test will wrongly conclude that the coin is unfair.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TNd7Ia3QYIja",
   "metadata": {
    "id": "TNd7Ia3QYIja"
   },
   "source": [
    "# **Foundations Of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WEYGegIdYNJJ",
   "metadata": {
    "id": "WEYGegIdYNJJ"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1SYWTWmzYQJi",
   "metadata": {
    "id": "1SYWTWmzYQJi"
   },
   "source": [
    "**Lab 11 (Comparing Two Samples)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be921591-07c1-4bd4-8388-b1a461006684",
   "metadata": {
    "id": "be921591-07c1-4bd4-8388-b1a461006684"
   },
   "source": [
    "# **A/B Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643fe678-8a13-4ac0-801d-c22aff03eeab",
   "metadata": {
    "id": "643fe678-8a13-4ac0-801d-c22aff03eeab"
   },
   "source": [
    "In modern data analytics, deciding whether two numerical samples come from the same underlying distribution is called A/B testing. The name refers to the labels of the two samples, A and B.\n",
    "\n",
    "We will develop the method in the context of an example. The data come from a sample of newborns in a large hospital system. We will treat it as if it were a simple random sample though the sampling was done in multiple stages. Stat Labs by Deborah Nolan and Terry Speed has details about a larger dataset from which this set is drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da134b-8524-45a9-8632-6b0a56f32ec0",
   "metadata": {
    "id": "81da134b-8524-45a9-8632-6b0a56f32ec0"
   },
   "source": [
    "# Smokers and Nonsmokers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25ba429-581e-495d-9dcf-e73216a0c364",
   "metadata": {
    "id": "e25ba429-581e-495d-9dcf-e73216a0c364"
   },
   "source": [
    "The table births contains the following variables for 1,174 mother-baby pairs: the baby’s birth weight in ounces, the number of gestational days, the mother’s age in completed years, the mother’s height in inches, pregnancy weight in pounds, and whether or not the mother smoked during pregnancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2c7613-d989-4790-90e7-70981bc9f99a",
   "metadata": {
    "id": "5c2c7613-d989-4790-90e7-70981bc9f99a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da10cd8-b1aa-465b-bd76-e34005457fcf",
   "metadata": {
    "id": "5da10cd8-b1aa-465b-bd76-e34005457fcf",
    "outputId": "d2190c40-8349-463c-85d4-3c671f170ddb"
   },
   "outputs": [],
   "source": [
    "births = pd.read_csv('baby.csv')\n",
    "births.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dcca4b-a87d-4d1e-842d-c52563942a8c",
   "metadata": {
    "id": "b0dcca4b-a87d-4d1e-842d-c52563942a8c"
   },
   "source": [
    "One of the aims of the study was to see whether maternal smoking was associated with birth weight. Let’s see what we can say about the two variables.\n",
    "We’ll start by selecting just Birth Weight and Maternal Smoker. There are 715 non-smokers among the women in the sample, and 459 smokers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19644c21-771b-4cc5-970a-72c41875646c",
   "metadata": {
    "id": "19644c21-771b-4cc5-970a-72c41875646c"
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight = births[['Maternal Smoker', 'Birth Weight']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea81c0b-9518-40d9-872c-6ba793dd0d5c",
   "metadata": {
    "id": "5ea81c0b-9518-40d9-872c-6ba793dd0d5c",
    "outputId": "05f13271-ecfc-462e-a6b5-8adada087313"
   },
   "outputs": [],
   "source": [
    "smoking_birthweight1 = smoking_and_birthweight.groupby([\"Maternal Smoker\"]).agg(\n",
    "    count=pd.NamedAgg(column=\"Maternal Smoker\", aggfunc=\"count\")\n",
    ")\n",
    "smoking_birthweight1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa842bd-4629-430c-857c-65c629b2ae88",
   "metadata": {
    "id": "4fa842bd-4629-430c-857c-65c629b2ae88"
   },
   "outputs": [],
   "source": [
    "smoker = births[births['Maternal Smoker'] == False]\n",
    "non_smoker = births[births['Maternal Smoker'] == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a78e4d2-bd8a-4577-952d-63d152c38c7c",
   "metadata": {
    "id": "4a78e4d2-bd8a-4577-952d-63d152c38c7c"
   },
   "source": [
    "Let’s look at the distribution of the birth weights of the babies of the non-smoking mothers compared to those of the smoking mothers. To generate two overlaid histograms, we will use hist with the optional group argument which is a column label or index. The rows of the table are first grouped by this column and then a histogram is drawn for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cfdcfa-3f99-415c-95c5-80863c088a2d",
   "metadata": {
    "id": "07cfdcfa-3f99-415c-95c5-80863c088a2d",
    "outputId": "f6dfdbf7-bead-41bf-cf4e-81b280ed978b"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(smoker['Birth Weight'], density=True,\n",
    "        label='Maternal Smoker = True',\n",
    "        color='blue',\n",
    "        alpha=0.8,\n",
    "        ec='white',\n",
    "        zorder=5)\n",
    "ax.hist(non_smoker['Birth Weight'], density=True,\n",
    "        label='Maternal Smoker = ',\n",
    "        color='gold',\n",
    "        alpha=0.8,\n",
    "        ec='white',\n",
    "        zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = ''\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('')\n",
    "ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69477cda-408a-4d80-b379-35296b314bc1",
   "metadata": {
    "id": "69477cda-408a-4d80-b379-35296b314bc1"
   },
   "source": [
    "The distribution of the weights of the babies born to mothers who smoked appears to be based slightly to the left of the distribution corresponding to non-smoking mothers. The weights of the babies of the mothers who smoked seem lower on average than the weights of the babies of the non-smokers.\n",
    "\n",
    "**The Hypotheses**\n",
    "We can try to answer this question by a test of hypotheses. The chance model that we will test says that there is no underlying difference in the popuations; the distributions in the samples are different just due to chance.\n",
    "\n",
    "Formally, this is the null hypothesis. We are going to have to figure out how to simulate a useful statistic under this hypothesis. But as a start, let’s just state the two natural hypotheses.\n",
    "\n",
    "**Null hypothesis:** In the population, the distribution of birth weights of babies is the same for mothers who don’t smoke as for mothers who do. The difference in the sample is due to chance.\n",
    "\n",
    "**Alternative hypothesis:** In the population, the babies of the mothers who smoke have a lower birth weight, on average, than the babies of the non-smokers.\n",
    "\n",
    "**Test Statistic :**\n",
    "The alternative hypothesis compares the average birth weights of the two groups and says that the average for the mothers who smoke is smaller. Therefore it is reasonable for us to use the difference between the two group means as our statistic.\n",
    "\n",
    "We will do the subtraction in the order “average weight of the smoking group −\n",
    " average weight of the non-smoking group”. Small values (that is, large negative values) of this statistic will favor the alternative hypothesis.\n",
    "\n",
    "The observed value of the test statistic is about −9.27\n",
    " ounces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d84559-97ce-4c41-8f31-eda8481ddee6",
   "metadata": {
    "id": "85d84559-97ce-4c41-8f31-eda8481ddee6",
    "outputId": "938fca81-de19-45cd-d6b5-e7687c0e668a"
   },
   "outputs": [],
   "source": [
    "means_table = smoking_and_birthweight.groupby('Maternal Smoker').mean()\n",
    "means_table = means_table.reset_index()\n",
    "means_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489672c9-6fd9-4b4f-ab13-39e5f7f9066d",
   "metadata": {
    "id": "489672c9-6fd9-4b4f-ab13-39e5f7f9066d",
    "outputId": "d946475e-5008-452b-9473-7cf8b52cf32f"
   },
   "outputs": [],
   "source": [
    "means = means_table['Birth Weight']\n",
    "observed_difference = means[1] - means[0]\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b527ed41-c5fd-4b5b-9c62-7e3f6bf4298c",
   "metadata": {
    "id": "b527ed41-c5fd-4b5b-9c62-7e3f6bf4298c"
   },
   "source": [
    "We are going compute such differences repeatedly in our simulations below, so we will define a function to do the job. The function takes three arguments:\n",
    "the name of the table of data\n",
    "the label of the column that contains the numerical variable whose average is of interest\n",
    "the label of the column that contains the Boolean variable for grouping\n",
    "It returns the difference between the means of the True group and the False group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069a475f-533f-4ae0-ab15-12268deeb0ca",
   "metadata": {
    "id": "069a475f-533f-4ae0-ab15-12268deeb0ca"
   },
   "outputs": [],
   "source": [
    "def difference_of_means(table, label, group_label):\n",
    "    reduced = table[[label, group_label]]\n",
    "    means_table = reduced.groupby(group_label).mean()\n",
    "    means = means_table[label]\n",
    "    return means[1] - means[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73eac2f-62eb-49c8-8731-fbd654fd22a3",
   "metadata": {
    "id": "b73eac2f-62eb-49c8-8731-fbd654fd22a3",
    "outputId": "3cb8245d-7d48-4d7c-b2cf-7bf35bacea34"
   },
   "outputs": [],
   "source": [
    "difference_of_means(births, 'Birth Weight', 'Maternal Smoker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06aeb3cb-a2e2-4d6e-9d16-0028b4b8db1b",
   "metadata": {
    "id": "06aeb3cb-a2e2-4d6e-9d16-0028b4b8db1b"
   },
   "source": [
    "That’s the same as the value of observed_difference calculated earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf6dd7-885d-4579-af10-8b22cd5ace0b",
   "metadata": {
    "id": "5caf6dd7-885d-4579-af10-8b22cd5ace0b"
   },
   "source": [
    "**Predicting the Statistic Under the Null Hypothesis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6453c-71b1-4939-a508-4f1a3fd0a95d",
   "metadata": {
    "id": "79e6453c-71b1-4939-a508-4f1a3fd0a95d",
    "outputId": "a5a9e1d6-b0d8-4235-87e6-6a321a87231a"
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f60c693-2d55-4fe3-ae40-da683cc8ad63",
   "metadata": {
    "id": "9f60c693-2d55-4fe3-ae40-da683cc8ad63"
   },
   "source": [
    "There are 1,174 rows in the table. To shuffle all the labels, we will draw a random sample of 1,174 rows without replacement. Then the sample will include all the rows of the table, in random order.\n",
    "\n",
    "We can use the Table method sample with the optional with_replacement=False argument. We don’t have to specify a sample size, because by default, sample draws as many times as there are rows in the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce52a84-e721-44ba-a3ed-0f6cf63869c5",
   "metadata": {
    "id": "7ce52a84-e721-44ba-a3ed-0f6cf63869c5"
   },
   "outputs": [],
   "source": [
    "smoking_and_birthweight2 = smoking_and_birthweight.copy()\n",
    "shuffled_labels = smoking_and_birthweight2.sample(len(smoking_and_birthweight2), replace = False)\n",
    "shuffled_labels = np.array(shuffled_labels['Maternal Smoker'])\n",
    "smoking_and_birthweight2['Shuffled Label'] = shuffled_labels\n",
    "original_and_shuffled = smoking_and_birthweight2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8020de-5b54-4414-bda9-5339d96776a6",
   "metadata": {
    "id": "4a8020de-5b54-4414-bda9-5339d96776a6",
    "outputId": "cba0e8cc-5bbf-4e6c-8c41-457b9442be2d"
   },
   "outputs": [],
   "source": [
    "original_and_shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82397baf-4261-4f67-8998-5a87fdeab476",
   "metadata": {
    "id": "82397baf-4261-4f67-8998-5a87fdeab476"
   },
   "source": [
    "Each baby’s mother now has a random smoker/non-smoker label in the column Shuffled Label, while her original label is in Maternal Smoker. If the null hypothesis is true, all the random re-arrangements of the labels should be equally likely.\n",
    "\n",
    "Let’s see how different the average weights are in the two randomly labeled groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421adbc8-00bc-45b0-90b9-e663209354df",
   "metadata": {
    "id": "421adbc8-00bc-45b0-90b9-e663209354df",
    "outputId": "5df8e168-7b8e-45c4-a5c9-28611b5b2b3e"
   },
   "outputs": [],
   "source": [
    "shuffled_only = original_and_shuffled.drop(columns=['Maternal Smoker'])\n",
    "shuffled_group_means = shuffled_only.groupby('Shuffled Label').mean()\n",
    "shuffled = shuffled_group_means.reset_index()\n",
    "shuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e3a6bf-fb83-4e6e-b5b3-8352c3e02f5f",
   "metadata": {
    "id": "c0e3a6bf-fb83-4e6e-b5b3-8352c3e02f5f"
   },
   "source": [
    "The averages of the two randomly selected groups are quite a bit closer than the averages of the two original groups. We can use our function difference_of_means to find the two differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b686dd-4b1e-4d12-a45e-d04102089d55",
   "metadata": {
    "id": "a9b686dd-4b1e-4d12-a45e-d04102089d55",
    "outputId": "69d830b5-15c8-490a-d4f5-3ae4db5d3f71"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "difference_of_means(original_and_shuffled, 'Birth Weight', 'Shuffled Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71564dd0-93ff-4b03-bdae-f06356438089",
   "metadata": {
    "id": "71564dd0-93ff-4b03-bdae-f06356438089",
    "outputId": "3beeb375-5fb8-4c43-f3d7-3ba5a4876a0b"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "difference_of_means(original_and_shuffled, 'Birth Weight', 'Maternal Smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef1f62f-c56c-478d-93c8-f8f0bcf36d0c",
   "metadata": {
    "id": "fef1f62f-c56c-478d-93c8-f8f0bcf36d0c"
   },
   "outputs": [],
   "source": [
    "def one_simulated_difference(table, label, group_label):\n",
    "    births1 = table.copy()\n",
    "    shuffled_labels = births1.sample(len(births1), replace = False)\n",
    "    shuffled_labels = np.array(shuffled_labels[group_label])\n",
    "    births1['Shuffled Label'] = shuffled_labels\n",
    "    original_and_shuffled = births1\n",
    "    shuffled_only = original_and_shuffled.drop(columns=['Maternal Smoker'])\n",
    "    shuffled_group_means = shuffled_only.groupby('Shuffled Label').mean()\n",
    "    table1 = shuffled_group_means.reset_index()\n",
    "    return difference_of_means(table1, label, 'Shuffled Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b50518-0e67-4b55-b81e-8fe15892cff6",
   "metadata": {
    "id": "f8b50518-0e67-4b55-b81e-8fe15892cff6",
    "outputId": "a2896287-a98d-4753-901e-dada80e6780c"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "one_simulated_difference(births, 'Birth Weight', 'Maternal Smoker')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49371899-78a3-44ae-a595-57c15160abd9",
   "metadata": {
    "id": "49371899-78a3-44ae-a595-57c15160abd9"
   },
   "source": [
    "**Permutation Test**\n",
    "\n",
    "Tests based on random permutations of the data are called permutation tests. We are performing one in this example. In the cell below, we will simulate our test statistic – the difference between the averages of the two groups – many times and collect the differences in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c4cea5-400a-4a7d-9270-f4f6df85fff9",
   "metadata": {
    "id": "f9c4cea5-400a-4a7d-9270-f4f6df85fff9",
    "outputId": "8c4e413e-b319-4eaf-aa23-57507e87de40"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "differences = []\n",
    "\n",
    "repetitions = 5000\n",
    "for i in range(repetitions):\n",
    "    new_difference = one_simulated_difference(births, 'Birth Weight', 'Maternal Smoker')\n",
    "    differences.append(new_difference)\n",
    "\n",
    "differences = np.array(differences)\n",
    "differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc9ea50-0dee-4501-ae6b-90ffb55e708e",
   "metadata": {
    "id": "ccc9ea50-0dee-4501-ae6b-90ffb55e708e"
   },
   "source": [
    "**Conclusion of the Test**\n",
    "\n",
    "The histogram below shows the distribution of these 5,000 values. It is the empirical distribution of the test statistic simulated under the null hypothesis. This is a prediction about the test statistic, based on the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc520d-6931-4f44-a578-b286d8b67a9a",
   "metadata": {
    "id": "dfcc520d-6931-4f44-a578-b286d8b67a9a",
    "outputId": "cf0ecd25-b3ce-413f-c6bf-f3c2e3664711"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "test_conclusion = pd.DataFrame({'Difference Between Group Means':differences})\n",
    "print('Observed Difference:', observed_difference)\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(test_conclusion, density=True, color='blue', alpha=0.8, ec='white')\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Diference Between Group Means'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('Prediction Under the Null Hypothesis');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8777fea-02a5-45b7-93c6-a1e84f4e0946",
   "metadata": {
    "id": "f8777fea-02a5-45b7-93c6-a1e84f4e0946",
    "outputId": "4d5db2b3-cd20-4275-82bc-01d0cd87eff8"
   },
   "outputs": [],
   "source": [
    "empirical_P = np.count_nonzero(differences <= observed_difference) / repetitions\n",
    "empirical_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55820731-8256-45e9-976d-cf857e9379c7",
   "metadata": {
    "id": "55820731-8256-45e9-976d-cf857e9379c7"
   },
   "source": [
    "The empirical P-value is 0, meaning that none of the 5,000 permuted samples resulted in a difference of -9.27 or lower. This is only an approximation. The exact chance of getting a difference in that range is not 0 but it is vanishingly small."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807cc032-5d86-4457-9f51-3cd6cdae9f82",
   "metadata": {
    "id": "807cc032-5d86-4457-9f51-3cd6cdae9f82"
   },
   "source": [
    "**Another Permutation Test**\n",
    "\n",
    "We can use the same method to compare other attributes of the smokers and the non-smokers, such as their ages. Histograms of the ages of the two groups show that in the sample, the mothers who smoked tended to be younger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7824eaa-4b8f-42d2-ba9e-88661ad6d3b4",
   "metadata": {
    "id": "e7824eaa-4b8f-42d2-ba9e-88661ad6d3b4",
    "outputId": "5e9f3a18-e8c5-4570-9369-5d09f93a31e0"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "smoking_and_age = births[['Maternal Smoker', 'Maternal Age']]\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(smoker['Maternal Age'], density=True, label='Maternal Smoker = True', color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.hist(non_smoker['Maternal Age'], density=True, label='Maternal Smoker = False', color='gold', alpha=0.8, ec='white', zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = ''\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('')\n",
    "ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3785489d-65f3-4d91-8e29-10940d6e956b",
   "metadata": {
    "id": "3785489d-65f3-4d91-8e29-10940d6e956b"
   },
   "source": [
    "The observed difference between the average ages is about −0.8\n",
    " years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45351007-1e02-4f0a-9b18-af0fbd3b7b14",
   "metadata": {
    "id": "45351007-1e02-4f0a-9b18-af0fbd3b7b14",
    "outputId": "0ddac505-aca3-4a7d-cf18-a22ed5177b88"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "observed_age_difference = difference_of_means(births, 'Maternal Age', 'Maternal Smoker')\n",
    "observed_age_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89476b38-00be-49d0-aece-f99372044809",
   "metadata": {
    "id": "89476b38-00be-49d0-aece-f99372044809"
   },
   "source": [
    "Remember that the difference is calculated as the mean age of the smokers minus the mean age of the non-smokers. The negative sign shows that the smokers are younger on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c9074c-11cc-43b9-9e75-0abc7863e99a",
   "metadata": {
    "id": "b7c9074c-11cc-43b9-9e75-0abc7863e99a"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "age_differences = np.array([])\n",
    "\n",
    "repetitions = 5000\n",
    "for i in np.arange(repetitions):\n",
    "    new_difference = one_simulated_difference(births, 'Maternal Age', 'Maternal Smoker')\n",
    "    age_differences = np.append(age_differences, new_difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e351e0-2a09-4d3a-9166-36715e8c9aa8",
   "metadata": {
    "id": "72e351e0-2a09-4d3a-9166-36715e8c9aa8"
   },
   "source": [
    "The observed difference is in the tail of the empirical distribution of the differences simulated under the null hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63f9a1-5c54-4f90-ac7b-ab30ca280961",
   "metadata": {
    "id": "4b63f9a1-5c54-4f90-ac7b-ab30ca280961",
    "outputId": "2da2920c-da37-41a9-c4a3-e77a2241ad1d"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "mean_differences = pd.DataFrame({'Difference Between Group Means':age_differences})\n",
    "unit = ''\n",
    "print('Observed Difference:', observed_age_difference)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(mean_differences, density=True, alpha=0.8, ec='white', zorder=5)\n",
    "ax.scatter(observed_age_difference, 0, color='red', s=30, zorder=10).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Difference Between Group Means'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('Prediction Under the Null Hypothesis');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52e9e1f-a0e7-4e5b-ad0a-36ecc1b514f7",
   "metadata": {
    "id": "d52e9e1f-a0e7-4e5b-ad0a-36ecc1b514f7"
   },
   "source": [
    "The empirical P-value of the test is the proportion of simulated differences that were equal to or less than the observed difference. This is because low values of the difference favor the alternative hypothesis that the smokers were younger on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48513f4c-47d5-4a27-a8f3-28e73bd9988f",
   "metadata": {
    "id": "48513f4c-47d5-4a27-a8f3-28e73bd9988f"
   },
   "source": [
    "empirical_P = np.count_nonzero(age_differences <= observed_age_difference) / 5000\n",
    "empirical_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5e0d85-46ec-4e29-8617-ff88aab4dd03",
   "metadata": {
    "id": "8a5e0d85-46ec-4e29-8617-ff88aab4dd03"
   },
   "source": [
    "The empirical P-value is around 1% and therefore the result is statistically significant. The test supports the hypothesis that the smokers were younger on average."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446255c-34ee-4395-8a82-14e4f0972f04",
   "metadata": {
    "id": "f446255c-34ee-4395-8a82-14e4f0972f04"
   },
   "source": [
    "# **2.Deflategate**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64022cb7-94de-45ef-ae69-701fb82a1f43",
   "metadata": {
    "id": "64022cb7-94de-45ef-ae69-701fb82a1f43"
   },
   "source": [
    "Here are the data. Each row corresponds to one football. Pressure is measured in psi. The Patriots ball that had been intercepted by the Colts was not inspected at half-time. Nor were most of the Colts’ balls – the officials simply ran out of time and had to relinquish the balls for the start of second half play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6561eb0-f675-4430-9ea2-967ca22076ef",
   "metadata": {
    "id": "a6561eb0-f675-4430-9ea2-967ca22076ef",
    "outputId": "d652d665-7907-4ffd-9f29-4ea81b5b0abd"
   },
   "outputs": [],
   "source": [
    "football = pd.read_csv('deflategate.csv')\n",
    "football.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cdcad6-5186-4c14-9719-fa65c34fa2c4",
   "metadata": {
    "id": "63cdcad6-5186-4c14-9719-fa65c34fa2c4"
   },
   "source": [
    "For each of the 15 balls that were inspected, the two officials got different results. It is not uncommon that repeated measurements on the same object yield different results, especially when the measurements are performed by different people. So we will assign to each the ball the average of the two measurements made on that ball."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c38d789-c38e-423b-b49a-f38704eed338",
   "metadata": {
    "id": "3c38d789-c38e-423b-b49a-f38704eed338",
    "outputId": "8f5da267-1e2e-447b-befb-073eebecb683"
   },
   "outputs": [],
   "source": [
    "football_1 = football.copy()\n",
    "football_1['Combined'] = (football_1['Blakeman']+football_1['Prioleau'])/2\n",
    "football_combined = football_1.drop(columns=['Blakeman','Prioleau'])\n",
    "football_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeff53d-b358-4a89-ae9a-3ae58fb8047f",
   "metadata": {
    "id": "baeff53d-b358-4a89-ae9a-3ae58fb8047f",
    "outputId": "06fa8fba-5392-4673-8b3d-ec3f28c2837a"
   },
   "outputs": [],
   "source": [
    "np.ones(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e65a0-98fb-489c-a6de-d8cae5dee104",
   "metadata": {
    "id": "f83e65a0-98fb-489c-a6de-d8cae5dee104",
    "outputId": "a1650218-b1ad-4f70-b1ec-c5df425ad503"
   },
   "outputs": [],
   "source": [
    "patriots_start = 12.5 * np.ones(11)\n",
    "colts_start = 13 * np.ones(4)\n",
    "start = np.append(patriots_start, colts_start)\n",
    "start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47cd35-2d11-4cb9-9039-41942e6ab1f2",
   "metadata": {
    "id": "aa47cd35-2d11-4cb9-9039-41942e6ab1f2"
   },
   "source": [
    "The drop in pressure for each football is the difference between the starting pressure and the combined pressure measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdd427-8169-451b-8751-ebcd123c7f11",
   "metadata": {
    "id": "30cdd427-8169-451b-8751-ebcd123c7f11",
    "outputId": "d2713676-db03-45e1-999c-41c005f02110"
   },
   "outputs": [],
   "source": [
    "drop = start - football_combined['Combined']\n",
    "football_combined['Pressure Drop'] = drop\n",
    "football_combined.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f1a8b-e77d-40a4-96ae-94de54b731f6",
   "metadata": {
    "id": "c68f1a8b-e77d-40a4-96ae-94de54b731f6"
   },
   "source": [
    "It looks as though the Patriots’ drops were larger than the Colts’. Let’s look at the average drop in each of the two groups. We no longer need the combined scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837d3c2-3bce-41f7-be22-d5553851b186",
   "metadata": {
    "id": "a837d3c2-3bce-41f7-be22-d5553851b186",
    "outputId": "4cc4091f-4330-4005-8b5d-f0be0da93169"
   },
   "outputs": [],
   "source": [
    "football_combined1 = football_combined.copy()\n",
    "football_combined_average = football_combined1.drop(columns=['Combined'])\n",
    "football_combined_average = football_combined_average.groupby(by=['Team']).mean()\n",
    "football_combined_average = football_combined_average.reset_index()\n",
    "football_combined_average = football_combined_average.rename(columns={'Pressure Drop':'Pressure Drop average'})\n",
    "football_combined_average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fafc7ef-86d1-4a24-8f0f-f8f174950c8d",
   "metadata": {
    "id": "8fafc7ef-86d1-4a24-8f0f-f8f174950c8d"
   },
   "source": [
    "The average drop for the Patriots was about 1.2 psi compared to about 0.47 psi for the Colts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbe38ce-80fa-4ec6-a9ac-70a73a94bf4b",
   "metadata": {
    "id": "fdbe38ce-80fa-4ec6-a9ac-70a73a94bf4b"
   },
   "source": [
    "**The Hypotheses**\n",
    "How does chance come in here? Nothing was being selected at random. But we can make a chance model by hypothesizing that the 11 Patriots’ drops look like a random sample of 11 out of all the 15 drops, with the Colts’ drops being the remaining four. That’s a completely specified chance model under which we can simulate data. So it’s the null hypothesis.\n",
    "For the alternative, we can take the position that the Patriots’ drops are too large, on average, to resemble a random sample drawn from all the drops.\n",
    "\n",
    "**Test Statistic**\n",
    "A natural statistic is the difference between the two average drops, which we will compute as “average drop for Patriots - average drop for Colts”. Large values of this statistic will favor the alternative hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e069fc-4de0-43f9-aba7-db7734d09227",
   "metadata": {
    "id": "89e069fc-4de0-43f9-aba7-db7734d09227",
    "outputId": "874d3232-ac64-4d10-e357-d9c6144047c0"
   },
   "outputs": [],
   "source": [
    "observed_means = football_combined_average['Pressure Drop average']\n",
    "observed_difference = observed_means.iloc[1] - observed_means.iloc[0]\n",
    "observed_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a175a9c-821b-4757-968e-f7276180d8e1",
   "metadata": {
    "id": "1a175a9c-821b-4757-968e-f7276180d8e1"
   },
   "source": [
    "This positive difference reflects the fact that the average drop in pressure of the Patriots’ footballs was greater than that of the Colts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba118a-6ad5-4744-9e39-c8b707739fa3",
   "metadata": {
    "id": "faba118a-6ad5-4744-9e39-c8b707739fa3"
   },
   "outputs": [],
   "source": [
    "def difference_of_means(table, label, group_label):\n",
    "    reduced = table[[label, group_label]]\n",
    "    means_table = reduced.groupby(group_label).mean()\n",
    "    means = means_table[label]\n",
    "    return means[1] - means[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9408d2e-1dbb-42ca-b8d4-32b49834cb09",
   "metadata": {
    "id": "d9408d2e-1dbb-42ca-b8d4-32b49834cb09"
   },
   "source": [
    "We have defined this function in an earlier section. The definition is repeated here for ease of reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877aa75e-552a-4c4a-a0ba-afbd03257ed9",
   "metadata": {
    "id": "877aa75e-552a-4c4a-a0ba-afbd03257ed9",
    "outputId": "b7516a1d-cf93-41db-b06e-3b32f9b2f335"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "difference_of_means(football_combined, 'Pressure Drop', 'Team')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfc886a-1775-44a4-bf24-e9f5cf3a53a1",
   "metadata": {
    "id": "5bfc886a-1775-44a4-bf24-e9f5cf3a53a1"
   },
   "source": [
    "**Predicting the Statistic Under the Null Hypothesis**\n",
    "\n",
    "If the null hypothesis were true, then it shouldn’t matter which footballs are labeled Patriots and which are labeled Colts. The distributions of the two sets of drops would be the same. We can simulate this by randomly shuffling the team labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0875feb-12e8-4a89-b08d-29b51aadbf14",
   "metadata": {
    "id": "a0875feb-12e8-4a89-b08d-29b51aadbf14",
    "outputId": "55b42632-8522-460e-e447-5cc6cbe93e29"
   },
   "outputs": [],
   "source": [
    "shuffled_labels3 = football_combined.copy()\n",
    "shuffled_labels4 = shuffled_labels3\n",
    "shuffled_labels5 = shuffled_labels4.sample(len(shuffled_labels3), replace = False)\n",
    "shuffled_labels6 = np.array(shuffled_labels5['Team'])\n",
    "shuffled_labels3['Shuffled Label'] = shuffled_labels6\n",
    "original_and_shuffled = shuffled_labels3.drop(columns=['Combined'])\n",
    "original_and_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099e4b80-1fc9-440a-9bf8-cbd59c45c67e",
   "metadata": {
    "id": "099e4b80-1fc9-440a-9bf8-cbd59c45c67e",
    "outputId": "dacede44-9fb0-4745-c262-da594fa64912"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "difference_of_means(original_and_shuffled, 'Pressure Drop', 'Shuffled Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c02f2e-bddf-44ec-a081-cbd1d4c7c7de",
   "metadata": {
    "id": "35c02f2e-bddf-44ec-a081-cbd1d4c7c7de",
    "outputId": "bfe36269-5839-4951-bd62-3d7ceb306abd"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "difference_of_means(original_and_shuffled, 'Pressure Drop', 'Team')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d200bc-ba4f-4116-b22c-cb5f6b76fd1f",
   "metadata": {
    "id": "08d200bc-ba4f-4116-b22c-cb5f6b76fd1f"
   },
   "source": [
    "The two teams’ average drop values are closer when the team labels are randomly assigned to the footballs than they were for the two groups actually used in the game.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594d2a8-627b-4c5b-a5f4-a7203013d1c7",
   "metadata": {
    "id": "6594d2a8-627b-4c5b-a5f4-a7203013d1c7"
   },
   "source": [
    "**Permutation Test**\n",
    "\n",
    "It’s time for a step that is now familiar. We will do repeated simulations of the test statistic under the null hypothesis, by repeatedly permuting the footballs and assigning random sets to the two teams.\n",
    "Once again, we will use the function one_simulated_difference defined in an earlier section as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a22de5-a34b-41c7-8c3f-4cdfd91e35ba",
   "metadata": {
    "id": "32a22de5-a34b-41c7-8c3f-4cdfd91e35ba"
   },
   "outputs": [],
   "source": [
    "def one_simulated_difference(table, label, group_label):\n",
    "    table_copy = table.copy()\n",
    "    shuffled_labels = table_copy.sample(len(table_copy), replace = False)\n",
    "    shuffled_labels = np.array(shuffled_labels[group_label])\n",
    "    table_copy['Shuffled Label'] = shuffled_labels\n",
    "    original_and_shuffled = table_copy.drop(columns=['Combined'])\n",
    "    shuffled_group_means = original_and_shuffled.groupby('Shuffled Label').mean()\n",
    "    table1 = shuffled_group_means.reset_index()\n",
    "    return difference_of_means(table1, label, 'Shuffled Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155eb781-bcd5-404c-9845-b3db094df990",
   "metadata": {
    "id": "155eb781-bcd5-404c-9845-b3db094df990",
    "outputId": "21027063-c6a0-4ddf-e6a4-14169e088690"
   },
   "outputs": [],
   "source": [
    "non_numeric = football_combined[pd.to_numeric(football_combined['Pressure Drop'], errors='coerce').isna()]\n",
    "print(\"\\nRows with non-numeric values in 'Pressure Drop':\")\n",
    "print(non_numeric[['Team', 'Pressure Drop']])\n",
    "football_combined['Pressure Drop'] = pd.to_numeric(football_combined['Pressure Drop'], errors='coerce')\n",
    "football_combined['Pressure Drop'].fillna(football_combined['Pressure Drop'].mean(), inplace=True)\n",
    "print(\"\\nData types after cleaning:\")\n",
    "print(football_combined.dtypes)\n",
    "football_combined_average = football_combined.groupby(by=['Team']).mean().reset_index()\n",
    "football_combined_average = football_combined_average.rename(columns={'Pressure Drop': 'Pressure Drop average'})\n",
    "print(\"\\nFootball Combined Average DataFrame:\")\n",
    "print(football_combined_average)\n",
    "repetitions = 1000\n",
    "differences = np.empty(repetitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f04503-6277-438c-8273-47ed1edc44d9",
   "metadata": {
    "id": "79f04503-6277-438c-8273-47ed1edc44d9",
    "outputId": "b5533303-6e1e-4869-da99-57243a4f7eaa"
   },
   "outputs": [],
   "source": [
    "empirical_P = np.count_nonzero(differences >= observed_difference) / 10000\n",
    "empirical_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267d74e-eded-4154-9942-2521f936d2ee",
   "metadata": {
    "id": "d267d74e-eded-4154-9942-2521f936d2ee"
   },
   "source": [
    "That’s a pretty small P-value. To visualize this, here is the empirical distribution of the test statistic under the null hypothesis, with the observed statistic marked on the horizontal axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b782a973-c8bf-4273-9f33-277ceaa1bcd1",
   "metadata": {
    "id": "b782a973-c8bf-4273-9f33-277ceaa1bcd1"
   },
   "source": [
    "if len(differences) > 0:\n",
    "    test_conclusion = pd.DataFrame({'Difference Between Group Averages':differences})\n",
    "    print('Empirical P-value:', empirical_P)\n",
    "    unit = ''\n",
    "    fig, ax = plt.subplots(figsize=(2,2))\n",
    "    ax.hist(test_conclusion, density=True, color='blue', alpha=0.8, ec='white')\n",
    "    y_vals = ax.get_yticks()\n",
    "    y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "    x_label = 'Diference Between Group Averages'\n",
    "    ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title('Prediction Under the Null Hypothesis');\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No values in 'differences' array to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f30f31-e943-4c7f-b6cb-4c2d0e664955",
   "metadata": {
    "id": "90f30f31-e943-4c7f-b6cb-4c2d0e664955"
   },
   "source": [
    "# **3.Causality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1c06ba-e249-49f3-9ea8-564421e9d756",
   "metadata": {
    "id": "6e1c06ba-e249-49f3-9ea8-564421e9d756"
   },
   "source": [
    "Our methods for comparing two samples have a powerful use in the analysis of randomized controlled experiments. Since the treatment and control groups are assigned randomly in such experiements, differences in their outcomes can be compared to what would happen just due to chance if the treatment had no effect at all. If the observed differences are more marked than what we would predict as purely due to chance, we will have evidence of causation. Because of the unbiased assignment of individuals to the treatment and control groups, differences in the outcomes of the two groups can be ascribed to the treatment.\n",
    "\n",
    "The key to the analysis of randomized controlled experiments is understanding exactly how chance enters the picture. This helps us set up clear null and alternative hypotheses. Once that’s done, we can simply use the methods of the previous sections to complete the analysis.\n",
    "\n",
    "Let’s see how to do this in an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11cfc0a-0842-4123-8438-01b5d6dd450e",
   "metadata": {
    "id": "c11cfc0a-0842-4123-8438-01b5d6dd450e",
    "outputId": "00be3695-6a6d-4a0c-cb48-ce20527cc922"
   },
   "outputs": [],
   "source": [
    "bta = pd.read_csv('bta.csv')\n",
    "bta.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7d01bd-c5e1-4579-bfd6-7d6e4c64b99b",
   "metadata": {
    "id": "fa7d01bd-c5e1-4579-bfd6-7d6e4c64b99b"
   },
   "source": [
    "Remember that counting is the same as adding zeros and ones. The sum of 1’s in the control group is the number of control group patients who had pain relief. So the average of the number of 1’s is the proportion of control group patients who had pain relief."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d247556-41bd-4e66-95c5-7761c6e321e7",
   "metadata": {
    "id": "7d247556-41bd-4e66-95c5-7761c6e321e7",
    "outputId": "d15627eb-f73d-4431-9766-13991a999e49"
   },
   "outputs": [],
   "source": [
    "bta_group = bta.groupby('Group').mean()\n",
    "bta_group.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381bf21a-8bac-475e-95a8-9e4987ea1ecf",
   "metadata": {
    "id": "381bf21a-8bac-475e-95a8-9e4987ea1ecf"
   },
   "source": [
    "The table observed_outcomes collects the information about every patient’s potential outcomes, leaving the unobserved half of each “ticket” blank. (It’s just another way of thinking about the bta table, carrying the same information.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c535876-db23-4335-b1ca-4ba6d6038eb6",
   "metadata": {
    "id": "7c535876-db23-4335-b1ca-4ba6d6038eb6",
    "outputId": "97aaef07-5fd2-44b8-b6e2-0869b2801b34"
   },
   "outputs": [],
   "source": [
    "observed_outcomes = pd.read_csv(\"observed_outcomes.csv\")\n",
    "observed_outcomes.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a25d7b-0307-4973-9f88-0ec1b401c297",
   "metadata": {
    "id": "c6a25d7b-0307-4973-9f88-0ec1b401c297"
   },
   "source": [
    "**The Hypotheses**\n",
    "\n",
    "This hypothesis test evaluates whether a treatment (botulinum toxin A) has an effect compared to a control (saline). Under the **null hypothesis**, there’s no difference between the treatment and control outcomes, meaning any observed differences are due to chance. The **alternative hypothesis** suggests the treatment has a distinct effect. To test this, we simulate by randomly permuting the outcomes between treatment and control groups and comparing the resulting distributions, just as in A/B testing.\n",
    "\n",
    "**The Test Statistic :**\n",
    "If the two group proportions are very different from each other, we will lean towards the alternative hypothesis that the two underlying distributions are different. So our test statistic will be the distance between the two group proportions, that is, the absolute value of the difference between them.\n",
    "\n",
    "Large values of the test statistic will favor the alternative hypothesis over the null.\n",
    "\n",
    "Since the two group proportions were 0.6 and 0.125, the observed value of the test statistic is   ∣0.6−0.125∣ = 0.475\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27763c95-faa3-45ad-8d62-bb13e1fb54d7",
   "metadata": {
    "id": "27763c95-faa3-45ad-8d62-bb13e1fb54d7",
    "outputId": "56f39711-4900-46e3-85ca-284af9133d89"
   },
   "outputs": [],
   "source": [
    "bta_group = bta.groupby('Group').mean()\n",
    "bta_group = bta_group.reset_index()\n",
    "bta_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103bbc53-7cad-4f22-98d4-a0317afada1c",
   "metadata": {
    "id": "103bbc53-7cad-4f22-98d4-a0317afada1c",
    "outputId": "10721f94-51db-4274-ad8d-ed6956fa832a"
   },
   "outputs": [],
   "source": [
    "observed_proportions = bta_group['Result']\n",
    "observed_distance = abs(observed_proportions.iloc[0] - observed_proportions.iloc[1])\n",
    "observed_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1f7c17-be33-4010-b5ab-e555c711d9d7",
   "metadata": {
    "id": "bf1f7c17-be33-4010-b5ab-e555c711d9d7"
   },
   "source": [
    "As we have done before, we will define a function that takes the following arguments:\n",
    "the name of the table of data\n",
    "the column label of the numerical variable\n",
    "the column label of the group labels\n",
    "and returns the absolute difference between the two group proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a25f5-b04e-4432-ae06-0d556676fc92",
   "metadata": {
    "id": "927a25f5-b04e-4432-ae06-0d556676fc92"
   },
   "outputs": [],
   "source": [
    "def distance(table, label, group_label):\n",
    "    reduced = table[[label, group_label]]\n",
    "    proportions = reduced.groupby(group_label).mean()\n",
    "    distance = proportions[label]\n",
    "    return abs(distance.iloc[1] - distance.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966fefd-aa54-4487-a719-055ac54d532d",
   "metadata": {
    "id": "3966fefd-aa54-4487-a719-055ac54d532d",
    "outputId": "925ab16b-39e9-45d1-f221-46a41f709fbd"
   },
   "outputs": [],
   "source": [
    "distance(bta_group, 'Result', 'Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61651376-3010-4b35-87e5-447f0ad4ceaa",
   "metadata": {
    "id": "61651376-3010-4b35-87e5-447f0ad4ceaa"
   },
   "source": [
    "**Predicting the Statistic Under the Null Hypothesis :**\n",
    "We can simulate results under the null hypothesis, to see how our test statistic should come out if the null hypothesis is true.\n",
    "\n",
    "**Generating One Value of the Statistic :**\n",
    "The simulation follows exactly the same process we used in the previous section. We start by randomly permuting the all group labels and then attaching the shuffled labels to the 0/1 results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77915edb-dc6c-4426-aad4-31b7ee005896",
   "metadata": {
    "id": "77915edb-dc6c-4426-aad4-31b7ee005896",
    "outputId": "76cd5530-3c96-4b88-f9ec-90cdde9625e9"
   },
   "outputs": [],
   "source": [
    "shuffled_labels3 = bta.copy()\n",
    "shuffled_labels4 = shuffled_labels3\n",
    "shuffled_labels5 = shuffled_labels4.sample(len(shuffled_labels3), replace = False)\n",
    "shuffled_labels6 = np.array(shuffled_labels5['Group'])\n",
    "shuffled_labels3['Shuffled Label'] = shuffled_labels6\n",
    "bta_with_shuffled_labels = shuffled_labels3\n",
    "bta_with_shuffled_labels.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f824f5-3591-46b4-9414-a95494fbd599",
   "metadata": {
    "id": "29f824f5-3591-46b4-9414-a95494fbd599"
   },
   "source": [
    "We can now find the distance between the two proportions after the group labels have been shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caed28f-9390-4b45-b773-08a849bf7393",
   "metadata": {
    "id": "3caed28f-9390-4b45-b773-08a849bf7393",
    "outputId": "3e8b7cc8-fe2f-47ee-998b-432bbd60c7d2"
   },
   "outputs": [],
   "source": [
    "distance(bta_with_shuffled_labels, 'Result', 'Shuffled Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb89a04b-c11f-4004-9331-b1402be5c087",
   "metadata": {
    "id": "cb89a04b-c11f-4004-9331-b1402be5c087"
   },
   "source": [
    "This is quite different from the distance between the two original proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536ba1d-7b83-4faf-98db-399dc3550b39",
   "metadata": {
    "id": "1536ba1d-7b83-4faf-98db-399dc3550b39",
    "outputId": "46437500-2d06-42c4-e2ff-d08700bd2d87"
   },
   "outputs": [],
   "source": [
    "distance(bta_with_shuffled_labels, 'Result', 'Group')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90727e75-b5cb-4a30-ab42-1f7164400c88",
   "metadata": {
    "id": "90727e75-b5cb-4a30-ab42-1f7164400c88"
   },
   "source": [
    "**Permutation Test :**\n",
    "If we shuffled the labels again, how different would the new distance be? To answer this, we will define a function that simulates one simulated value of the distance under the hypothesis of random draws from the same underlying distribution. And then we will collect 20,000 such simulated values in an array.\n",
    "\n",
    "You can see that we are doing exactly what we did in our previous examples of the permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5a6d0-3be5-4269-ae9e-9e0559f9adba",
   "metadata": {
    "id": "e8e5a6d0-3be5-4269-ae9e-9e0559f9adba"
   },
   "outputs": [],
   "source": [
    "def one_simulated_distance(table, label, group_label):\n",
    "    table_copy = table.copy()\n",
    "\n",
    "    shuffled_labels = table_copy[group_label].sample(frac=1).reset_index(drop=True)\n",
    "    table_copy['Shuffled Label'] = shuffled_labels\n",
    "\n",
    "    table_copy[label] = pd.to_numeric(table_copy[label], errors='coerce')\n",
    "\n",
    "    table_copy = table_copy.dropna(subset=[label])\n",
    "    shuffled_group_means = table_copy.groupby('Shuffled Label')[label].mean()\n",
    "    table1 = shuffled_group_means.reset_index()\n",
    "\n",
    "    return distance(table1, label, 'Shuffled Label')\n",
    "\n",
    "distances = np.array([])\n",
    "repetitions = 20000\n",
    "for i in np.arange(repetitions):\n",
    "    new_distance = one_simulated_distance(bta, 'Result', 'Group')\n",
    "    distances = np.append(distances, new_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19449ab1-aa6d-49d9-a174-eb3c09fb3222",
   "metadata": {
    "id": "19449ab1-aa6d-49d9-a174-eb3c09fb3222"
   },
   "source": [
    "**Conclusion of the Test :**\n",
    "The array distances contains 20,000 values of our test statistic simulated under the null hypothesis.\n",
    "\n",
    "To find the P-value of the test, remember that large values of the test statistic favor the alternative hypothesis. So the empirical P-value is the proportion of simulated statistics that were equal to or larger than the observed statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9080aec-c393-4b71-a866-aeb955f726f2",
   "metadata": {
    "id": "e9080aec-c393-4b71-a866-aeb955f726f2",
    "outputId": "5c554893-3b34-47f5-df6a-c20e2113d532"
   },
   "outputs": [],
   "source": [
    "empirical_P = np.count_nonzero(distances >= observed_distance) / repetitions\n",
    "empirical_P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30b76ef-fe54-43aa-a2c3-9070b703c9b5",
   "metadata": {
    "id": "d30b76ef-fe54-43aa-a2c3-9070b703c9b5"
   },
   "source": [
    "his is a small P-value. The observed statistic, shown as the red dot below, is in the tail of the empirical histogram of the test statistic generated under the null hypothesis.\n",
    "The result is statistically significant. The test favors the alternative hypothesis over the null. The evidence supports the hypothesis that the treatment is doing something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0aa96-d162-4d4d-b028-aaedb3206664",
   "metadata": {
    "id": "59d0aa96-d162-4d4d-b028-aaedb3206664",
    "outputId": "645c08b3-ef53-4103-d365-9158bc7736e2"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "test_conclusion = pd.DataFrame({'Distance':distances})\n",
    "print('Observed Distance', observed_distance)\n",
    "print('Empirical P-value:', round(empirical_P, 4) *100, '%')\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(test_conclusion, bins = np.arange(0, 0.7, 0.1), density=True, color='blue', alpha=0.8, ec='white')\n",
    "ax.scatter(observed_distance, 0, color='red', s=40, zorder=10).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Distance'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('Prediction Under the Null Hypothesis');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fFDUOZ9tUgo",
   "metadata": {
    "id": "5fFDUOZ9tUgo"
   },
   "source": [
    " ## **Foundations Of DataScience**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59dc980-a589-47cd-84b4-cf2fd2514c0f",
   "metadata": {
    "id": "b59dc980-a589-47cd-84b4-cf2fd2514c0f"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dBxo5qqxtwZt",
   "metadata": {
    "id": "dBxo5qqxtwZt"
   },
   "source": [
    "**Lab 14 Estimating the unknown Parameter (Percentile Method, Bootstrap Method, Confidence Intervals)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c12e0e-cb86-4f46-a731-a7046ed42fd0",
   "metadata": {
    "executionInfo": {
     "elapsed": 581,
     "status": "ok",
     "timestamp": 1731836345064,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "e1c12e0e-cb86-4f46-a731-a7046ed42fd0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4zWjb6p8uWrf",
   "metadata": {
    "id": "4zWjb6p8uWrf"
   },
   "source": [
    "Imports necessary libraries like numpy, pandas, seaborn, and matplotlib.pyplot for numerical computations, data manipulation, visualization, and plotting, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab3e55-7814-4bcc-84cd-033a8b3a993a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731836345460,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "49ab3e55-7814-4bcc-84cd-033a8b3a993a",
    "outputId": "f05031fc-7a39-48fc-fa11-b2069d477bab"
   },
   "outputs": [],
   "source": [
    "sizes = np.array([12, 17, 6, 9, 7])\n",
    "np.sort(sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PuuloClqugfn",
   "metadata": {
    "id": "PuuloClqugfn"
   },
   "source": [
    " Creates a NumPy array named sizes with the given values and sorts it in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbcf15-f4a6-4701-a0ce-72991c115946",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731836345460,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "efbbcf15-f4a6-4701-a0ce-72991c115946",
    "outputId": "38f27ecf-ce10-4ee3-fb7a-26fe43c1a8f7"
   },
   "outputs": [],
   "source": [
    "np.percentile(sizes, 70, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LwHgaY5Auj-J",
   "metadata": {
    "id": "LwHgaY5Auj-J"
   },
   "source": [
    "Calculates the 70th percentile of the sizes array using the nearest-rank method for interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5063d16-a030-4c5e-9f8a-d985c5c6af3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731836345460,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "e5063d16-a030-4c5e-9f8a-d985c5c6af3a",
    "outputId": "fcffec7f-c7e5-473d-df37-5327aacf17b6"
   },
   "outputs": [],
   "source": [
    "scores_and_sections = pd.read_csv('scores_by_section.csv')\n",
    "scores_and_sections.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GJvf0I9EuoER",
   "metadata": {
    "id": "GJvf0I9EuoER"
   },
   "source": [
    "Reads data from a CSV file named 'scores_by_section.csv' into a Pandas DataFrame called scores_and_sections and displays the first 10 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a742f7-150c-4cf3-b9d0-e9d0e677d57c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 957,
     "status": "ok",
     "timestamp": 1731836346414,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "15a742f7-150c-4cf3-b9d0-e9d0e677d57c",
    "outputId": "4421a432-1057-423a-a322-bd0d0c5296f5"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(scores_and_sections['Midterm'], bins = np.arange(-0.5, 25.6, 1), density=True, alpha=0.8, ec='white')\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Midterm'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BcAEHAMru49M",
   "metadata": {
    "id": "BcAEHAMru49M"
   },
   "source": [
    " Creates a histogram of the 'Midterm' scores from the scores_and_sections DataFrame, setting bin edges and formatting axes labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08544092-96ff-4ebe-a677-887046485f91",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 458
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731836346414,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "08544092-96ff-4ebe-a677-887046485f91",
    "outputId": "ef62ca6b-5050-46ba-c3eb-3a7527ec1c9d"
   },
   "outputs": [],
   "source": [
    "scores = scores_and_sections.iloc[:,1]\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "L7Qf9PTnu8EX",
   "metadata": {
    "id": "L7Qf9PTnu8EX"
   },
   "source": [
    "Extracts the 'Midterm' scores from the DataFrame into a Pandas Series named scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aa5a73-64a9-4944-bf3c-db651b3d3072",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "d2aa5a73-64a9-4944-bf3c-db651b3d3072",
    "outputId": "73d7eb8f-dc7a-4427-f540-dc5ca9eac43c"
   },
   "outputs": [],
   "source": [
    "np.percentile(scores , 85, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "C9Kv-qsXu-dV",
   "metadata": {
    "id": "C9Kv-qsXu-dV"
   },
   "source": [
    " Computes the 85th percentile of the scores Series using the nearest-rank method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f33c87c-48ef-4c12-b759-c7ae92d13af7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "0f33c87c-48ef-4c12-b759-c7ae92d13af7",
    "outputId": "5b3a8f87-4361-4d28-d549-52de67933e72"
   },
   "outputs": [],
   "source": [
    "sorted_scores = np.sort(scores_and_sections.iloc[:,1])\n",
    "sorted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KXXrzknXvBKo",
   "metadata": {
    "id": "KXXrzknXvBKo"
   },
   "source": [
    " Sorts the 'Midterm' scores and stores them in a NumPy array named sorted_scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2c9bc1-3254-4bea-8fca-fc0ab7204f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "eb2c9bc1-3254-4bea-8fca-fc0ab7204f5b",
    "outputId": "ed22ae14-7fac-43ca-b57c-ff3274f2f1f4"
   },
   "outputs": [],
   "source": [
    "0.85 * 359"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wg5UWQQ7vD3K",
   "metadata": {
    "id": "Wg5UWQQ7vD3K"
   },
   "source": [
    " Calculates the index corresponding to the 85th percentile in the sorted scores array (which has 359 elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4357ad-c8f3-4fc6-9793-07074f319d44",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "9d4357ad-c8f3-4fc6-9793-07074f319d44",
    "outputId": "72ebd3f7-0d7f-4433-e8f7-3ecd0115a753"
   },
   "outputs": [],
   "source": [
    "sorted_scores.item(305)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2zEkunqBvGks",
   "metadata": {
    "id": "2zEkunqBvGks"
   },
   "source": [
    "Accesses the element at the calculated index (305) in the sorted_scores array, which represents the 85th percentile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137db207-85fc-413a-b39c-26cb9159c752",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "137db207-85fc-413a-b39c-26cb9159c752",
    "outputId": "ce2dee50-7872-46b7-c243-5403286328d8"
   },
   "outputs": [],
   "source": [
    "np.percentile(scores, 25, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312c9ba-0dd1-4117-87b0-9d2861c3af16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "2312c9ba-0dd1-4117-87b0-9d2861c3af16",
    "outputId": "178e056e-fc35-47f3-eb11-1a90a6fc46ee"
   },
   "outputs": [],
   "source": [
    "np.percentile(scores, 50, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebb72f3-33d5-4762-8795-7680a229a4a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731836346415,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "1ebb72f3-33d5-4762-8795-7680a229a4a7",
    "outputId": "3b61db33-b593-46f1-d818-06222ec0fd24"
   },
   "outputs": [],
   "source": [
    "np.percentile(scores, 75, interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Nrx9rRGnvNJ8",
   "metadata": {
    "id": "Nrx9rRGnvNJ8"
   },
   "source": [
    "Calculate and display the 25th, 50th (median), and 75th percentiles of the scores Series, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1267b68-1bad-4ef7-b497-d1b2ab5e08a8",
   "metadata": {
    "id": "b1267b68-1bad-4ef7-b497-d1b2ab5e08a8"
   },
   "source": [
    "#### 2. The Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fc8555-5202-411f-9245-7e6d860e17ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "executionInfo": {
     "elapsed": 452,
     "status": "ok",
     "timestamp": 1731836346861,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "d4fc8555-5202-411f-9245-7e6d860e17ed",
    "outputId": "d9b851bd-239c-4747-cec7-f82bc7f585a5"
   },
   "outputs": [],
   "source": [
    "sf2015 = pd.read_csv('san_francisco_2015.csv')\n",
    "sf2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dGebi31vQfc",
   "metadata": {
    "id": "6dGebi31vQfc"
   },
   "source": [
    "Reads data from a CSV file named 'san_francisco_2015.csv' into a Pandas DataFrame called sf2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c6d62-d5ed-43bf-a891-b85ae3b20017",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 533
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731836346862,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "d50c6d62-d5ed-43bf-a891-b85ae3b20017",
    "outputId": "4212cd3e-2eef-41bc-cf3c-d790182f6c33"
   },
   "outputs": [],
   "source": [
    "sf2015.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0_IA6LCpvUsE",
   "metadata": {
    "id": "0_IA6LCpvUsE"
   },
   "source": [
    "Displays the first 10 rows of the sf2015 DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b1dd9-211b-4337-9e6c-6d055e5144a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731836346862,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "e83b1dd9-211b-4337-9e6c-6d055e5144a3",
    "outputId": "93a337ed-f293-4225-cbe9-f4210c0f7e3f"
   },
   "outputs": [],
   "source": [
    "sf2015[sf2015['Job'] == 'Mayor']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DkcuEHWQvYkP",
   "metadata": {
    "id": "DkcuEHWQvYkP"
   },
   "source": [
    "Filters the sf2015 DataFrame to display rows where the 'Job' column is 'Mayor'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34512dd9-c367-4e8a-abee-3c0b5ab554c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731836346862,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "34512dd9-c367-4e8a-abee-3c0b5ab554c0",
    "outputId": "d7db2a4e-79f8-4523-9b8b-78787f28dd58"
   },
   "outputs": [],
   "source": [
    "sf2015.sort_values(by=['Total Compensation']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1gpm2U3vbh2",
   "metadata": {
    "id": "f1gpm2U3vbh2"
   },
   "source": [
    "Sorts the sf2015 DataFrame by 'Total Compensation' in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295d12e-c720-435c-b535-99465f67bcd4",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731836346862,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "4295d12e-c720-435c-b535-99465f67bcd4"
   },
   "outputs": [],
   "source": [
    "sf2015 = sf2015[sf2015['Salaries'] > 10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yW8Ag3rcveVO",
   "metadata": {
    "id": "yW8Ag3rcveVO"
   },
   "source": [
    " Filters the sf2015 DataFrame to keep only rows where 'Salaries' are greater than 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f368ff67-2359-4a62-ac4e-57ed948376f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731836346862,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "f368ff67-2359-4a62-ac4e-57ed948376f7",
    "outputId": "569988d2-5765-46ea-f26f-27d0218ba3e5"
   },
   "outputs": [],
   "source": [
    "len(sf2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M1Kmbpsjvh9l",
   "metadata": {
    "id": "M1Kmbpsjvh9l"
   },
   "source": [
    " Displays the number of rows in the filtered sf2015 DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fd5f43-d55f-4a91-82f4-acdf648c30e4",
   "metadata": {
    "id": "d9fd5f43-d55f-4a91-82f4-acdf648c30e4"
   },
   "source": [
    "#### Population and Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be62981d-0855-4e83-a0af-d3a8ddb2da55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "executionInfo": {
     "elapsed": 512,
     "status": "ok",
     "timestamp": 1731836347367,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "be62981d-0855-4e83-a0af-d3a8ddb2da55",
    "outputId": "a607b8dd-f6e7-4188-b9e2-1882b35c4773"
   },
   "outputs": [],
   "source": [
    "sf_bins = np.arange(0, 700000, 25000)\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(sf2015['Total Compensation'], bins = sf_bins, density=True, color='blue', alpha=0.8, ec='white')\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Total Compensation'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5FfMemvFvlBS",
   "metadata": {
    "id": "5FfMemvFvlBS"
   },
   "source": [
    " Creates a histogram of 'Total Compensation' from the sf2015 DataFrame, with specified bin edges and formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d9e633-3671-428e-a4f5-8f89fdb18437",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836347367,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "96d9e633-3671-428e-a4f5-8f89fdb18437",
    "outputId": "acc29ce9-192d-4df4-9b69-3e4865d01331"
   },
   "outputs": [],
   "source": [
    "sf2015.sort_values(by=['Total Compensation'], ascending=False).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jou659qFvnVB",
   "metadata": {
    "id": "Jou659qFvnVB"
   },
   "source": [
    " Sorts the sf2015 DataFrame by 'Total Compensation' in descending order and displays the top 2 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914e6257-5870-4be5-b188-820635912e2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836347367,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "914e6257-5870-4be5-b188-820635912e2a",
    "outputId": "c0430dcb-75d1-4760-e7da-301c49ec221d"
   },
   "outputs": [],
   "source": [
    "pop_median = np.percentile(sf2015['Total Compensation'], 50)\n",
    "pop_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9Lc7MMJKvqY4",
   "metadata": {
    "id": "9Lc7MMJKvqY4"
   },
   "source": [
    "Calculates the median 'Total Compensation' from the sf2015 DataFrame and assigns it to pop_median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fed6aa-3673-4610-9cfc-ea05600c0741",
   "metadata": {
    "id": "e7fed6aa-3673-4610-9cfc-ea05600c0741"
   },
   "source": [
    "#### A Random Sample and an Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6593ad-990c-420d-a048-05a8d818443e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "executionInfo": {
     "elapsed": 587,
     "status": "ok",
     "timestamp": 1731836347950,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "cf6593ad-990c-420d-a048-05a8d818443e",
    "outputId": "31318fa0-b5ea-48e0-bdac-954ee7d18f08"
   },
   "outputs": [],
   "source": [
    "our_sample = sf2015.sample(500, replace=False)\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(our_sample['Total Compensation'], bins = sf_bins, density=True, color='blue', alpha=0.8, ec='white')\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Total Compensation'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zq65Z3RHvtoI",
   "metadata": {
    "id": "zq65Z3RHvtoI"
   },
   "source": [
    "Takes a random sample of 500 rows from the sf2015 DataFrame without replacement and assigns it to our_sample. It then creates a histogram of 'Total Compensation' for this sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8dbd15-bb66-4cc9-92bd-b550c6b45585",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836347950,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "4f8dbd15-bb66-4cc9-92bd-b550c6b45585",
    "outputId": "0935329e-a8fa-4b73-8ef9-ee6596a90c02"
   },
   "outputs": [],
   "source": [
    "est_median = np.percentile(our_sample['Total Compensation'], 50)\n",
    "est_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wNHME52XvwQw",
   "metadata": {
    "id": "wNHME52XvwQw"
   },
   "source": [
    "Calculates the median 'Total Compensation' from the our_sample DataFrame and assigns it to est_median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba668538-cd55-44f8-b73c-409594e76d52",
   "metadata": {
    "id": "ba668538-cd55-44f8-b73c-409594e76d52"
   },
   "source": [
    "#### The Bootstrap: Resampling from the Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05b35d7-db9f-4550-95bb-b16d85a3c022",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 516
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731836347950,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "e05b35d7-db9f-4550-95bb-b16d85a3c022",
    "outputId": "c53e9037-6fc8-4306-90e1-d2e20e77c168"
   },
   "outputs": [],
   "source": [
    "resample_1 = our_sample.sample(len(our_sample), replace=True)\n",
    "resample_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1M0HUHSNv1C2",
   "metadata": {
    "id": "1M0HUHSNv1C2"
   },
   "source": [
    "Creates a bootstrap resample from our_sample with replacement and assigns it to resample_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e31a5-3e1d-4752-8682-bde5eb3e12e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 558
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731836348484,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "720e31a5-3e1d-4752-8682-bde5eb3e12e9",
    "outputId": "9d283cf8-5183-4667-952d-2c1688c75cb0"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resample_1['Total Compensation'], bins = sf_bins, density=True, color='blue', alpha=0.8, ec='white')\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Total Compensation'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nLkxrOVgv4IT",
   "metadata": {
    "id": "nLkxrOVgv4IT"
   },
   "source": [
    " Creates a histogram of 'Total Compensation' for the resample_1 DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4aecd8-eaa8-4dd6-b475-6987781198d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731836348484,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "7f4aecd8-eaa8-4dd6-b475-6987781198d2",
    "outputId": "49ce99b6-d060-4b68-c9f3-95d54fccd535"
   },
   "outputs": [],
   "source": [
    "resampled_median_1 = np.percentile(resample_1['Total Compensation'], 50, interpolation='nearest')\n",
    "resampled_median_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K2b_vPAZv6oA",
   "metadata": {
    "id": "K2b_vPAZv6oA"
   },
   "source": [
    " Calculates the median 'Total Compensation' from the resample_1 DataFrame and assigns it to resampled_median_1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7dbc1e-5554-4a5b-b91c-1ce1b0692ed2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1731836348484,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "1e7dbc1e-5554-4a5b-b91c-1ce1b0692ed2",
    "outputId": "2f8979ca-02ad-4062-db99-682857fc30aa"
   },
   "outputs": [],
   "source": [
    "resample_2 = our_sample.sample(len(our_sample), replace=True)\n",
    "resampled_median_2 = np.percentile(resample_2['Total Compensation'], 50, interpolation='nearest')\n",
    "resampled_median_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OVGPMYkEv9bf",
   "metadata": {
    "id": "OVGPMYkEv9bf"
   },
   "source": [
    " Creates another bootstrap resample (resample_2) and calculates its median (resampled_median_2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd04fd2-604e-447a-b65a-6f1aa21fd227",
   "metadata": {
    "id": "5bd04fd2-604e-447a-b65a-6f1aa21fd227"
   },
   "source": [
    "#### Bootstrap Empirical Distribution of the Sample Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1458f17-f97d-4b02-a3a1-ec5a3e99ec4f",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1731836348484,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "b1458f17-f97d-4b02-a3a1-ec5a3e99ec4f"
   },
   "outputs": [],
   "source": [
    "def bootstrap_median(original_sample, label, replications):\n",
    "    \"\"\"Returns an array of bootstrapped sample medians:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "    just_one_column = original_sample[label]\n",
    "    medians = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resampled_median = np.percentile(bootstrap_sample, 50)\n",
    "        medians = np.append(medians, resampled_median)\n",
    "\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WIBlA-YRwE7h",
   "metadata": {
    "id": "WIBlA-YRwE7h"
   },
   "source": [
    "Defines a function bootstrap_median that takes an original sample, a column label, and the number of replications as input. It generates bootstrap samples, calculates the median of each sample, and returns an array of these medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a6fd05-abdf-47a3-b629-2ba08a4e9477",
   "metadata": {
    "executionInfo": {
     "elapsed": 1965,
     "status": "ok",
     "timestamp": 1731836350446,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "70a6fd05-abdf-47a3-b629-2ba08a4e9477"
   },
   "outputs": [],
   "source": [
    "bstrap_medians = bootstrap_median(our_sample, 'Total Compensation', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1Domhk16wIjz",
   "metadata": {
    "id": "1Domhk16wIjz"
   },
   "source": [
    "Calls the bootstrap_median function with the our_sample DataFrame, 'Total Compensation' column, and 5000 replications to generate an array of bootstrapped medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ed76f-0008-4558-aef3-29a3f48aa2ac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1731836350446,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "d56ed76f-0008-4558-aef3-29a3f48aa2ac",
    "outputId": "48bb3053-1543-4316-816e-22e9d827847a"
   },
   "outputs": [],
   "source": [
    "resampled_medians = pd.DataFrame({'Bootstrap Sample Median':bstrap_medians})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_medians, density=True, color='blue', alpha=0.8, ec='white')\n",
    "ax.scatter(pop_median, 0, color='red', s=40, zorder=10).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Median'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bQIwcQ4nwL-6",
   "metadata": {
    "id": "bQIwcQ4nwL-6"
   },
   "source": [
    "Creates a histogram of the bootstrapped medians, highlighting the population median with a red dot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195ba33e-5733-477d-890b-bf37046f65fa",
   "metadata": {
    "id": "195ba33e-5733-477d-890b-bf37046f65fa"
   },
   "source": [
    "#### Do the Estimates Capture the Parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a15d2d-6c02-4aad-8095-3e946381df86",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731836350446,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "94a15d2d-6c02-4aad-8095-3e946381df86",
    "outputId": "da350321-14ff-4a16-d59a-42581bd85863"
   },
   "outputs": [],
   "source": [
    "left = np.percentile(bstrap_medians, 2.5, interpolation='nearest')\n",
    "left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525af1e-8195-4690-9a13-f27ad68a7c89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731836350446,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "f525af1e-8195-4690-9a13-f27ad68a7c89",
    "outputId": "7f946562-b36b-4472-f12e-4a4cfaf50652"
   },
   "outputs": [],
   "source": [
    "right = np.percentile(bstrap_medians, 97.5, interpolation='nearest')\n",
    "right"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e_3NbpL2wO8I",
   "metadata": {
    "id": "e_3NbpL2wO8I"
   },
   "source": [
    "Calculates the 2.5th and 97.5th percentiles of the bootstrapped medians to define the lower and upper bounds of a 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b74e7bb-ee1b-41df-a177-098f6e4013d9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1731836351055,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "0b74e7bb-ee1b-41df-a177-098f6e4013d9",
    "outputId": "9a9122b4-d9f7-42bf-fc2f-fc1fe5be486d"
   },
   "outputs": [],
   "source": [
    "resampled_medians = pd.DataFrame({'Bootstrap Sample Median':bstrap_medians})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_medians, density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot(np.array([left, right]), np.array([0,0]), color='yellow', lw=8, zorder=10)\n",
    "ax.scatter(pop_median, 0, color='red', s=40, zorder=15).set_clip_on(False)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Median'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uFAuKLvLwR6o",
   "metadata": {
    "id": "uFAuKLvLwR6o"
   },
   "source": [
    " Creates a histogram of the bootstrapped medians, highlighting the 95% confidence interval with a yellow line and the population median with a red dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96015928-b94d-4d55-bb39-afb4f8d88b61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836351055,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "96015928-b94d-4d55-bb39-afb4f8d88b61",
    "outputId": "00591e1c-9fe4-4c3b-e325-721bd4152674"
   },
   "outputs": [],
   "source": [
    "total_comps = sf2015[['Total Compensation']]\n",
    "total_comps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EuUMx4VWwU50",
   "metadata": {
    "id": "EuUMx4VWwU50"
   },
   "source": [
    " Selects the 'Total Compensation' column from the sf2015 DataFrame and assigns it to total_comps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f2be9c-6ed4-495c-bbda-eb203fca1245",
   "metadata": {
    "executionInfo": {
     "elapsed": 180254,
     "status": "ok",
     "timestamp": 1731836531304,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "01f2be9c-6ed4-495c-bbda-eb203fca1245"
   },
   "outputs": [],
   "source": [
    "# THE BIG SIMULATION: This one takes several minutes.\n",
    "\n",
    "# Generate 100 intervals, in the table intervals\n",
    "\n",
    "left_ends = np.array([])\n",
    "right_ends = np.array([])\n",
    "\n",
    "total_comps = sf2015[['Total Compensation']]\n",
    "\n",
    "for i in np.arange(100):\n",
    "    first_sample = total_comps.sample(500, replace=False)\n",
    "    medians = bootstrap_median(first_sample, 'Total Compensation', 5000)\n",
    "    left_ends = np.append(left_ends, np.percentile(medians, 2.5))\n",
    "    right_ends = np.append(right_ends, np.percentile(medians, 97.5))\n",
    "\n",
    "intervals = pd.DataFrame(\n",
    "    {'Left':left_ends,\n",
    "    'Right':right_ends}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JailAq5_wdoe",
   "metadata": {
    "id": "JailAq5_wdoe"
   },
   "source": [
    "Performs a simulation to generate 100 confidence intervals for the median 'Total Compensation'. It repeatedly samples from the data, calculates bootstrap medians, and stores the interval endpoints. The results are stored in a DataFrame called intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9622b0-e52b-4748-9d8a-ea9a3095b03b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1731836531304,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "3b9622b0-e52b-4748-9d8a-ea9a3095b03b",
    "outputId": "ac08b888-d7c9-4410-a968-a69c373847ff"
   },
   "outputs": [],
   "source": [
    "intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hcq4WUNawf8Z",
   "metadata": {
    "id": "hcq4WUNawf8Z"
   },
   "source": [
    "Prints the intervals DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b1fd6-c984-4bc1-b509-a5c0888db473",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1731836531304,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "2b7b1fd6-c984-4bc1-b509-a5c0888db473",
    "outputId": "a5ad412f-4e71-4f4b-f918-c242b0f5e731"
   },
   "outputs": [],
   "source": [
    "pop_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jk6HdkfiwiYK",
   "metadata": {
    "id": "Jk6HdkfiwiYK"
   },
   "source": [
    " Prints the population median (pop_median)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47b73d8-9f01-4aca-8e91-852e734127d7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731836531305,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "b47b73d8-9f01-4aca-8e91-852e734127d7",
    "outputId": "c125070b-18ae-4d0d-e720-91a5c865412e"
   },
   "outputs": [],
   "source": [
    "len(\n",
    "    intervals[\n",
    "        (intervals['Left'] < pop_median) &\n",
    "              (intervals['Right'] > pop_median)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xfTJV2O1wnTU",
   "metadata": {
    "id": "xfTJV2O1wnTU"
   },
   "source": [
    ": Calculates the number of intervals that contain the population median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e1d1e-b917-4866-8072-743eaedf0607",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1731836531936,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "984e1d1e-b917-4866-8072-743eaedf0607",
    "outputId": "1c6a4a57-983e-436b-9292-ebeee8b58d46"
   },
   "outputs": [],
   "source": [
    "replication_number = np.arange(1, 101)\n",
    "\n",
    "replication_number = replication_number.astype(str)\n",
    "\n",
    "intervals2 = pd.DataFrame(np.array([left_ends, right_ends]), columns=[replication_number])\n",
    "\n",
    "intervals2\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "for i in np.arange(100):\n",
    "    ends = intervals2.iloc[:,i]\n",
    "    plt.plot(ends, np.array([i+1, i+1]), color='gold')\n",
    "plt.plot(np.array([pop_median, pop_median]), np.array([0, 100]), color='red', lw=2)\n",
    "plt.xlabel('Median (dollars)')\n",
    "plt.ylabel('Replication')\n",
    "plt.title('Population Median and Intervals of Estimates');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wc5Q0JgIwqab",
   "metadata": {
    "id": "Wc5Q0JgIwqab"
   },
   "source": [
    "Visualizes the 100 confidence intervals as horizontal lines, with the population median as a vertical red line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd8a26-6d5a-4d65-b8b2-856d30788fab",
   "metadata": {
    "id": "c2cd8a26-6d5a-4d65-b8b2-856d30788fab"
   },
   "source": [
    "#### 3. Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c83fe7-0a9d-46df-a029-671fed0e6573",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1731836531937,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "23c83fe7-0a9d-46df-a029-671fed0e6573",
    "outputId": "89ac7fc0-e721-4bb0-eca0-cee6e5d61f39"
   },
   "outputs": [],
   "source": [
    "baby = pd.read_csv('baby.csv')\n",
    "baby.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KgBTvcP6wtm8",
   "metadata": {
    "id": "KgBTvcP6wtm8"
   },
   "source": [
    "Reads data from 'baby.csv' into a DataFrame called baby."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f2fdb-732d-421e-81df-e0c7c05e24ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731836531937,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "3b0f2fdb-732d-421e-81df-e0c7c05e24ab",
    "outputId": "b8622b7a-e367-4676-93a7-9a8fecc8777d"
   },
   "outputs": [],
   "source": [
    "ratios = baby[['Birth Weight', 'Gestational Days']]\n",
    "ratios['Ratio BW/GD'] = baby['Birth Weight']/baby['Gestational Days']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KO7i10ZKwwB9",
   "metadata": {
    "id": "KO7i10ZKwwB9"
   },
   "source": [
    " Creates a new DataFrame ratios with 'Birth Weight' and 'Gestational Days', and adds a new column 'Ratio BW/GD' calculated by dividing 'Birth Weight' by 'Gestational Days'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f3047-45ec-44e3-b58e-a91c6b032f15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731836531937,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "177f3047-45ec-44e3-b58e-a91c6b032f15",
    "outputId": "e7847ad5-41d4-490a-cceb-521a5435e784"
   },
   "outputs": [],
   "source": [
    "ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4-RZwiSPwyQ-",
   "metadata": {
    "id": "4-RZwiSPwyQ-"
   },
   "source": [
    "Displays the ratios DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15032439-fd49-4c20-adba-675f3fd873ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 528
    },
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1731836532424,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "15032439-fd49-4c20-adba-675f3fd873ba",
    "outputId": "e5c4eb78-43f9-4778-f095-3fd7e22b59f3"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(ratios['Ratio BW/GD'], density=True, color='blue', alpha=0.8, ec='white')\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Ratio BW/GD'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AfqK7iaAw05g",
   "metadata": {
    "id": "AfqK7iaAw05g"
   },
   "source": [
    " Creates a histogram of the 'Ratio BW/GD' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e599488b-4c84-40a9-aea1-cbb0aea563a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1731836532425,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "e599488b-4c84-40a9-aea1-cbb0aea563a7",
    "outputId": "9a12dfff-4e89-4beb-f237-eb989258e8ab"
   },
   "outputs": [],
   "source": [
    "ratios_1 = ratios.sort_values(by=['Ratio BW/GD'], ascending=False)\n",
    "ratios_1.iloc[[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PSK0alOHw3Eu",
   "metadata": {
    "id": "PSK0alOHw3Eu"
   },
   "source": [
    "Sorts the ratios DataFrame by 'Ratio BW/GD' in descending order and displays the first row (highest ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a9cb1-03ff-419b-9ebc-4caa5e1f7454",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731836532425,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "094a9cb1-03ff-419b-9ebc-4caa5e1f7454",
    "outputId": "c8239663-b3cc-4017-c428-b9cefa4b44ca"
   },
   "outputs": [],
   "source": [
    "np.median(ratios.iloc[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9lPHPF3w5NY",
   "metadata": {
    "id": "f9lPHPF3w5NY"
   },
   "source": [
    "Calculates and displays the median of the 'Ratio BW/GD' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8945149-2efc-4471-8be8-d670b889163a",
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731836532425,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "b8945149-2efc-4471-8be8-d670b889163a"
   },
   "outputs": [],
   "source": [
    "def bootstrap_median(original_sample, label, replications):\n",
    "\n",
    "    \"\"\"Returns an array of bootstrapped sample medians:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "    just_one_column = original_sample[[label]]\n",
    "    medians = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resampled_median = np.percentile(bootstrap_sample, 50)\n",
    "        medians = np.append(medians, resampled_median)\n",
    "\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "srx97R6Ew7ih",
   "metadata": {
    "id": "srx97R6Ew7ih"
   },
   "source": [
    "Redefines the bootstrap_median function. (This is redundant as it's already defined in Cell 37)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abaa4a4-d342-47d3-b0b1-ccccc4a06d24",
   "metadata": {
    "executionInfo": {
     "elapsed": 1897,
     "status": "ok",
     "timestamp": 1731836534315,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "1abaa4a4-d342-47d3-b0b1-ccccc4a06d24"
   },
   "outputs": [],
   "source": [
    "# Generate the medians from 5000 bootstrap samples\n",
    "bstrap_medians = bootstrap_median(ratios, 'Ratio BW/GD', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04rpzf09w9mB",
   "metadata": {
    "id": "04rpzf09w9mB"
   },
   "source": [
    "Generates bootstrapped medians for 'Ratio BW/GD' and stores them in bstrap_medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d549ce33-30aa-4e02-8e38-32a0e4171039",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731836534316,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "d549ce33-30aa-4e02-8e38-32a0e4171039",
    "outputId": "56509538-b23a-4a7b-ec3a-faa100caf063"
   },
   "outputs": [],
   "source": [
    "# Get the endpoints of the 95% confidence interval\n",
    "left = np.percentile(bstrap_medians, 2.5, interpolation='nearest')\n",
    "right = np.percentile(bstrap_medians, 97.5, interpolation='nearest')\n",
    "\n",
    "np.array([left, right])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "W8E-EUl1w_53",
   "metadata": {
    "id": "W8E-EUl1w_53"
   },
   "source": [
    "Calculates the 95% confidence interval for the median 'Ratio BW/GD' using the bootstrapped medians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edea3dc6-05d4-46af-8732-03bdd71e4d89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1731836534316,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "edea3dc6-05d4-46af-8732-03bdd71e4d89",
    "outputId": "66759f74-40d4-405a-fc5d-e3b93f10f4fa"
   },
   "outputs": [],
   "source": [
    "resampled_medians = pd.DataFrame({'Bootstrap Sample Median':bstrap_medians})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_medians, bins=15, density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot(np.array([left, right]), np.array([0,0]), color='yellow', lw=8, zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Median'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MIl9uj-WxCwB",
   "metadata": {
    "id": "MIl9uj-WxCwB"
   },
   "source": [
    "Creates a histogram of the bootstrapped medians, highlighting the 95% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2eae71-254d-4cc1-a5da-1937e84f109e",
   "metadata": {
    "id": "fd2eae71-254d-4cc1-a5da-1937e84f109e"
   },
   "source": [
    "#### Confidence Interval for a Population Mean: Bootstrap Percentile Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933c28e-e4e8-4734-bc92-8592c8232483",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1731836534769,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "f933c28e-e4e8-4734-bc92-8592c8232483",
    "outputId": "a3467d70-6fb6-45b8-e986-7256d271bfb0"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(baby['Maternal Age'], density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Maternal Age'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ANysVZqOxJI1",
   "metadata": {
    "id": "ANysVZqOxJI1"
   },
   "source": [
    " Creates a histogram of 'Maternal Age' from the baby DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e7bcc-f6c7-4f61-b4d3-def5bd000139",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1731836534770,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "614e7bcc-f6c7-4f61-b4d3-def5bd000139",
    "outputId": "e6efbf3c-ab62-4785-b273-1bc85b8a88fb"
   },
   "outputs": [],
   "source": [
    "np.mean(baby['Maternal Age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ETOYzaDaxLhp",
   "metadata": {
    "id": "ETOYzaDaxLhp"
   },
   "source": [
    "Calculates and displays the mean of 'Maternal Age'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3290d6cd-4636-41da-a7e4-8e7722cb2ce5",
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731836534771,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "3290d6cd-4636-41da-a7e4-8e7722cb2ce5"
   },
   "outputs": [],
   "source": [
    "def bootstrap_mean(original_sample, label, replications):\n",
    "\n",
    "    \"\"\"Returns an array of bootstrapped sample means:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "\n",
    "    just_one_column = original_sample[[label]]\n",
    "    means = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resampled_mean = np.mean(bootstrap_sample.iloc[:,0])\n",
    "        means = np.append(means, resampled_mean)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Lob0yut6xOMO",
   "metadata": {
    "id": "Lob0yut6xOMO"
   },
   "source": [
    "Defines a function bootstrap_mean to generate bootstrapped sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca16922-6b31-4e8a-afe1-5623273b2d8a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 2545,
     "status": "ok",
     "timestamp": 1731836537308,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "cca16922-6b31-4e8a-afe1-5623273b2d8a",
    "outputId": "932e0cc4-9d6f-4750-c124-1a226b53feea"
   },
   "outputs": [],
   "source": [
    "# Generate the means from 5000 bootstrap samples\n",
    "bstrap_means = bootstrap_mean(baby, 'Maternal Age', 5000)\n",
    "\n",
    "# Get the endpoints of the 95% confidence interval\n",
    "left = np.percentile(bstrap_means, 2.5, interpolation='nearest')\n",
    "right = np.percentile(bstrap_means, 97.5, interpolation='nearest')\n",
    "\n",
    "np.array([left, right])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pyz9tIYfxQw6",
   "metadata": {
    "id": "pyz9tIYfxQw6"
   },
   "source": [
    "Generates bootstrapped means for 'Maternal Age' and calculates the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320f9e0-4043-494f-ba50-0fc001a585c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731836537308,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "7320f9e0-4043-494f-ba50-0fc001a585c4",
    "outputId": "ec1954aa-a554-4639-d95a-24af57c05a77"
   },
   "outputs": [],
   "source": [
    "resampled_means = pd.DataFrame({'Bootstrap Sample Mean':bstrap_means})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_means, bins=15, density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot(np.array([left, right]), np.array([0,0]), color='yellow', lw=8, zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Median'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zrPElfMQxTGZ",
   "metadata": {
    "id": "zrPElfMQxTGZ"
   },
   "source": [
    "Creates a histogram of the bootstrapped means, highlighting the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad86da8-4b69-4c90-ab1c-b2c955377937",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 460,
     "status": "ok",
     "timestamp": 1731836537765,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "fad86da8-4b69-4c90-ab1c-b2c955377937",
    "outputId": "78f63723-00fe-4bdd-f22c-b44fbb99babe"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(baby['Maternal Age'], density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Maternal Age'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rglgwWrDxWuq",
   "metadata": {
    "id": "rglgwWrDxWuq"
   },
   "source": [
    "Creates another histogram of 'Maternal Age' (redundant, similar to Cell 69)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57eb07f-340e-422d-895e-0dfd955f32f2",
   "metadata": {
    "id": "a57eb07f-340e-422d-895e-0dfd955f32f2"
   },
   "source": [
    "#### An 80% Confidence Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b46d0-e1c2-43c2-9125-ae4830a786ef",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836537765,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "955b46d0-e1c2-43c2-9125-ae4830a786ef",
    "outputId": "f2655712-edfb-40f3-a9f4-8963dcaa01fe"
   },
   "outputs": [],
   "source": [
    "left_80 = np.percentile(bstrap_means, 10, interpolation='nearest')\n",
    "right_80 = np.percentile(bstrap_means, 90, interpolation='nearest')\n",
    "np.array([left_80, right_80])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rDBrCGNkxZW3",
   "metadata": {
    "id": "rDBrCGNkxZW3"
   },
   "source": [
    " Calculates the 80% confidence interval for the mean 'Maternal Age' using bootstrapped means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293541e-9fe9-41c8-879e-c043d8800184",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1731836538246,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c293541e-9fe9-41c8-879e-c043d8800184",
    "outputId": "42ef55b1-c86f-45b2-a313-27821a6f4ed0"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_means, bins=15, density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot(np.array([left_80, right_80]), np.array([0,0]), color='yellow', lw=8, zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Mean'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ijzi2AsXxb6y",
   "metadata": {
    "id": "Ijzi2AsXxb6y"
   },
   "source": [
    "Creates a histogram of the bootstrapped means, highlighting the 80% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a8ae63-4606-4e59-8596-4dfc5e53e70e",
   "metadata": {
    "id": "b7a8ae63-4606-4e59-8596-4dfc5e53e70e"
   },
   "source": [
    "#### Confidence Interval for a Population Proportion: Bootstrap Percentile Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afb287-e62e-4c67-bd20-4c73f97f7559",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731836538247,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "21afb287-e62e-4c67-bd20-4c73f97f7559",
    "outputId": "b0c25a45-8681-46ec-e72f-8ba19309dcc9"
   },
   "outputs": [],
   "source": [
    "len(baby[baby['Maternal Smoker'] == True]) / len(baby)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z1tFOqvDxj3v",
   "metadata": {
    "id": "z1tFOqvDxj3v"
   },
   "source": [
    "Calculates and prints the proportion of 'Maternal Smoker' being True in the baby DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ffdc5-0e96-4b05-a6c9-45e2a7c6ecf2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836538247,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "9e4ffdc5-0e96-4b05-a6c9-45e2a7c6ecf2",
    "outputId": "2d6f3a21-aed2-4b93-b003-8961aa3a6a3e"
   },
   "outputs": [],
   "source": [
    "smoking = baby['Maternal Smoker']\n",
    "np.count_nonzero(smoking)/len(smoking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bBYBmY6WxmoE",
   "metadata": {
    "id": "bBYBmY6WxmoE"
   },
   "source": [
    "Calculates and prints the proportion of 'Maternal Smoker' being True using np.count_nonzero. (Similar to Cell 79)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a1a53-777f-4cf1-997a-b16a012605c4",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1731836538247,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "f47a1a53-777f-4cf1-997a-b16a012605c4"
   },
   "outputs": [],
   "source": [
    "def bootstrap_proportion(original_sample, label, replications):\n",
    "\n",
    "    \"\"\"Returns an array of bootstrapped sample proportions:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the Boolean variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "\n",
    "    just_one_column = original_sample[[label]]\n",
    "    proportions = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resample_array = bootstrap_sample.iloc[:,0]\n",
    "        resampled_proportion = np.count_nonzero(resample_array)/len(resample_array)\n",
    "        proportions = np.append(proportions, resampled_proportion)\n",
    "\n",
    "    return proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LZiUzW0dxpBi",
   "metadata": {
    "id": "LZiUzW0dxpBi"
   },
   "source": [
    "Defines a function bootstrap_proportion to generate bootstrapped sample proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e57ae3-32d1-44a0-9f97-e438307035a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 1739,
     "status": "ok",
     "timestamp": 1731836539982,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "e7e57ae3-32d1-44a0-9f97-e438307035a1",
    "outputId": "438f47d5-ae95-4645-8726-da0916cb5a8e"
   },
   "outputs": [],
   "source": [
    "# Generate the proportions from 5000 bootstrap samples\n",
    "bstrap_props = bootstrap_proportion(baby, 'Maternal Smoker', 5000)\n",
    "\n",
    "# Get the endpoints of the 95% confidence interval\n",
    "left = np.percentile(bstrap_props, 2.5, interpolation='nearest')\n",
    "right = np.percentile(bstrap_props, 97.5, interpolation='nearest')\n",
    "\n",
    "np.array([left, right])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e-Uw8e6RxrSi",
   "metadata": {
    "id": "e-Uw8e6RxrSi"
   },
   "source": [
    "Generates bootstrapped proportions for 'Maternal Smoker' and calculates the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2ae312-77f8-43ce-966e-f218ac42dc5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1731836539982,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "5c2ae312-77f8-43ce-966e-f218ac42dc5b",
    "outputId": "a421827a-40ce-451d-9fe6-0c619d7663b5"
   },
   "outputs": [],
   "source": [
    "resampled_proportions = pd.DataFrame({'Bootstrap Sample Proportion':bstrap_props})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_proportions, bins=15, density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot(np.array([left, right]), np.array([0,0]), color='yellow', lw=8, zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Proportion'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ctv8EYkIxt-b",
   "metadata": {
    "id": "Ctv8EYkIxt-b"
   },
   "source": [
    "Creates a histogram of the bootstrapped proportions, highlighting the 95% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffca9c5-18b6-463c-b833-181b9bfaf036",
   "metadata": {
    "id": "3ffca9c5-18b6-463c-b833-181b9bfaf036"
   },
   "source": [
    "#### Care in Using the Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57701b0-c3ba-47a9-9f10-75f3f496d2de",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836539982,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "d57701b0-c3ba-47a9-9f10-75f3f496d2de"
   },
   "outputs": [],
   "source": [
    "def bootstrap_median(original_sample, label, replications):\n",
    "    \"\"\"Returns an array of bootstrapped sample medians:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "    just_one_column = original_sample[label]\n",
    "    medians = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resampled_median = np.percentile(bootstrap_sample, 50)\n",
    "        medians = np.append(medians, resampled_median)\n",
    "\n",
    "    return medians"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "utaMqB64xwlt",
   "metadata": {
    "id": "utaMqB64xwlt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd4c685-e1c8-424f-bfb6-d69754d50119",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836539983,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "9bd4c685-e1c8-424f-bfb6-d69754d50119"
   },
   "outputs": [],
   "source": [
    "def bootstrap_mean(original_sample, label, replications):\n",
    "\n",
    "    \"\"\"Returns an array of bootstrapped sample means:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "\n",
    "    just_one_column = original_sample[[label]]\n",
    "    means = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resampled_mean = np.mean(bootstrap_sample.iloc[:,0])\n",
    "        means = np.append(means, resampled_mean)\n",
    "\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec2400-14ae-4e31-8638-4a9b3c376361",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836539983,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "a5ec2400-14ae-4e31-8638-4a9b3c376361"
   },
   "outputs": [],
   "source": [
    "def bootstrap_proportion(original_sample, label, replications):\n",
    "\n",
    "    \"\"\"Returns an array of bootstrapped sample proportions:\n",
    "    original_sample: table containing the original sample\n",
    "    label: label of column containing the Boolean variable\n",
    "    replications: number of bootstrap samples\n",
    "    \"\"\"\n",
    "\n",
    "    just_one_column = original_sample[[label]]\n",
    "    proportions = np.array([])\n",
    "    for i in np.arange(replications):\n",
    "        bootstrap_sample = just_one_column.sample(len(just_one_column), replace=True)\n",
    "        resample_array = bootstrap_sample.iloc[:,0]\n",
    "        resampled_proportion = np.count_nonzero(resample_array)/len(resample_array)\n",
    "        proportions = np.append(proportions, resampled_proportion)\n",
    "\n",
    "    return proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2rXTZ6xFxxzZ",
   "metadata": {
    "id": "2rXTZ6xFxxzZ"
   },
   "source": [
    "Redefines the bootstrap_median, bootstrap_mean, and bootstrap_proportion functions (redundant, already defined earlier)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c56d1-67a3-4b74-88f8-ce9042590030",
   "metadata": {
    "id": "1d6c56d1-67a3-4b74-88f8-ce9042590030"
   },
   "source": [
    "#### 4. Using Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ad6fe2-3fca-4041-8fe4-a52f661d0cd9",
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1731836539983,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "c6ad6fe2-3fca-4041-8fe4-a52f661d0cd9"
   },
   "outputs": [],
   "source": [
    "baby = pd.read_csv('baby.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NRcFWpwVx0aC",
   "metadata": {
    "id": "NRcFWpwVx0aC"
   },
   "source": [
    "Reads data from 'baby.csv' into the baby DataFrame (redundant, already loaded in Cell 58)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27dfe4c-41a8-4b70-86db-44ad6836b8fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 609,
     "status": "ok",
     "timestamp": 1731836540586,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "a27dfe4c-41a8-4b70-86db-44ad6836b8fa",
    "outputId": "f1a54d6e-ae9f-4220-b3f4-21448dfb597a"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(baby['Maternal Age'], density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Maternal Age'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nGenghLex3SK",
   "metadata": {
    "id": "nGenghLex3SK"
   },
   "source": [
    " Creates a histogram of 'Maternal Age' (redundant, similar to Cell 69 and 74)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54eede7-6cc1-4303-a2d5-988af603dd59",
   "metadata": {
    "id": "b54eede7-6cc1-4303-a2d5-988af603dd59"
   },
   "source": [
    "#### Using a Confidence Interval to Test Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01207f18-3bcb-4077-981b-9d4c2766523f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1731836540586,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "01207f18-3bcb-4077-981b-9d4c2766523f",
    "outputId": "7ea1c566-c753-4c3d-b51e-eccc83550e1a"
   },
   "outputs": [],
   "source": [
    "hodgkins = pd.read_csv('hodgkins.csv')\n",
    "hodgkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hm4P1jrFx5rq",
   "metadata": {
    "id": "Hm4P1jrFx5rq"
   },
   "source": [
    "Reads data from 'hodgkins.csv' into a DataFrame called hodgkins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed32d3b-e704-42cc-9ec8-c35ec49d8dc7",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1731836540586,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "fed32d3b-e704-42cc-9ec8-c35ec49d8dc7"
   },
   "outputs": [],
   "source": [
    "hodgkins['drop'] = hodgkins['base'] - hodgkins['month15']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yTKrqz-2x74l",
   "metadata": {
    "id": "yTKrqz-2x74l"
   },
   "source": [
    "Creates a new column 'drop' in the hodgkins DataFrame, calculated as the difference between 'base' and 'month15'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20832be7-4f42-4eda-b161-b6215f67649b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 739
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1731836540586,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "20832be7-4f42-4eda-b161-b6215f67649b",
    "outputId": "93b3c52d-ab87-4df3-e7e3-0152b931da5a"
   },
   "outputs": [],
   "source": [
    "hodgkins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Onr-JBOVx-PJ",
   "metadata": {
    "id": "Onr-JBOVx-PJ"
   },
   "source": [
    "Displays the hodgkins DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8795d2c-6bf6-471f-ab3b-a6c54af6baa7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1731836540586,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "a8795d2c-6bf6-471f-ab3b-a6c54af6baa7",
    "outputId": "d6266c91-f6a8-4645-8fa6-ca655abb8413"
   },
   "outputs": [],
   "source": [
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(hodgkins['drop'], bins=np.arange(-20, 81, 20), density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'drop'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q3FOzD8qyA3F",
   "metadata": {
    "id": "Q3FOzD8qyA3F"
   },
   "source": [
    "Creates a histogram of the 'drop' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3083c8-577d-45da-ad16-732ad3a60d37",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1731836540586,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "1c3083c8-577d-45da-ad16-732ad3a60d37",
    "outputId": "f09edad5-32b2-425f-e6e1-827c19f2bc0d"
   },
   "outputs": [],
   "source": [
    "np.mean(hodgkins['drop'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r5AIc44eyC7O",
   "metadata": {
    "id": "r5AIc44eyC7O"
   },
   "source": [
    "Calculates and prints the mean of the 'drop' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98fa42-d0ab-4bef-adfa-95aae304a76d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "executionInfo": {
     "elapsed": 3315,
     "status": "ok",
     "timestamp": 1731836543890,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "9c98fa42-d0ab-4bef-adfa-95aae304a76d",
    "outputId": "7bef7525-1934-46c6-b616-969809ebe221"
   },
   "outputs": [],
   "source": [
    "bstrap_means = bootstrap_mean(hodgkins, 'drop', 10000)\n",
    "\n",
    "left = np.percentile(bstrap_means, 0.5, interpolation='nearest')\n",
    "right = np.percentile(bstrap_means, 99.5, interpolation='nearest')\n",
    "\n",
    "np.array([left, right])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HCBMLRtayFqP",
   "metadata": {
    "id": "HCBMLRtayFqP"
   },
   "source": [
    "Generates bootstrapped means for 'drop' and calculates the 99% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2342a-e679-4c48-aa42-1716baf5b6a1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1731836543890,
     "user": {
      "displayName": "Polimera Nithin",
      "userId": "16028368039724084933"
     },
     "user_tz": -330
    },
    "id": "54a2342a-e679-4c48-aa42-1716baf5b6a1",
    "outputId": "496dfc39-8526-4813-e835-951263bf754f"
   },
   "outputs": [],
   "source": [
    "resampled_means = pd.DataFrame({'Bootstrap Sample Mean': bstrap_means})\n",
    "unit = ''\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.hist(resampled_means, density=True, color='blue', alpha=0.8, ec='white', zorder=5)\n",
    "ax.plot(np.array([left, right]), np.array([0,0]), color='yellow', lw=8, zorder=10)\n",
    "y_vals = ax.get_yticks()\n",
    "y_label = 'Percent per ' + (unit if unit else 'unit')\n",
    "x_label = 'Bootstrap Sample Means'\n",
    "ax.set_yticklabels(['{:g}'.format(x * 100) for x in y_vals])\n",
    "plt.ylabel(y_label)\n",
    "plt.xlabel(x_label)\n",
    "plt.title('');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HGmXK5x-yIF5",
   "metadata": {
    "id": "HGmXK5x-yIF5"
   },
   "source": [
    "Creates a histogram of the bootstrapped means, highlighting the 99% confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RiTBfGSDdO2A",
   "metadata": {
    "id": "RiTBfGSDdO2A"
   },
   "source": [
    "# **Foundations of Data Science**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foqNl-hmdVg0",
   "metadata": {
    "id": "foqNl-hmdVg0"
   },
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RLmfVWo9dbrX",
   "metadata": {
    "id": "RLmfVWo9dbrX"
   },
   "source": [
    "**Lab 13 (Prediction and Classification)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rNdfedaXdJew",
   "metadata": {
    "id": "rNdfedaXdJew"
   },
   "source": [
    "The code demonstrates the implementation and evaluation of both simple and multiple linear regression models using Python's scikit-learn library. It generates sample datasets, trains the models, makes predictions, and assesses their performance using metrics like Mean Squared Error and R2 Score. Additionally, it visualizes the results to provide a graphical representation of the relationships between features and target variables.\n",
    "\n",
    "In essence, the code provides a comprehensive workflow for building and evaluating linear regression models for both single and multiple predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51862cca-1b1b-4e40-88e8-276a7666d15f",
   "metadata": {
    "id": "51862cca-1b1b-4e40-88e8-276a7666d15f",
    "outputId": "7e313207-65d9-49e8-df4e-5b2674b8c6ce"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Generate a sample dataset\n",
    "np.random.seed(0)\n",
    "X_single = np.random.rand(100, 1) * 10  # Single feature\n",
    "y_single = 3 * X_single.flatten() + np.random.randn(100) * 2  # y = 3x + noise\n",
    "\n",
    "X_multi = np.random.rand(100, 3) * 10  # Three features\n",
    "y_multi = 2 * X_multi[:, 0] + 3 * X_multi[:, 1] + 4 * X_multi[:, 2] + np.random.randn(100) * 2  # y = 2x1 + 3x2 + 4x3 + noise\n",
    "\n",
    "# Simple Linear Regression\n",
    "lin_reg_single = LinearRegression()\n",
    "lin_reg_single.fit(X_single, y_single)\n",
    "y_pred_single = lin_reg_single.predict(X_single)\n",
    "\n",
    "# Multiple Linear Regression\n",
    "lin_reg_multi = LinearRegression()\n",
    "lin_reg_multi.fit(X_multi, y_multi)\n",
    "y_pred_multi = lin_reg_multi.predict(X_multi)\n",
    "\n",
    "# Evaluation metrics\n",
    "print(\"Simple Linear Regression\")\n",
    "print(\"Coefficients:\", lin_reg_single.coef_)\n",
    "print(\"Intercept:\", lin_reg_single.intercept_)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_single, y_pred_single))\n",
    "print(\"R2 Score:\", r2_score(y_single, y_pred_single))\n",
    "\n",
    "print(\"\\nMultiple Linear Regression\")\n",
    "print(\"Coefficients:\", lin_reg_multi.coef_)\n",
    "print(\"Intercept:\", lin_reg_multi.intercept_)\n",
    "print(\"Mean Squared Error:\", mean_squared_error(y_multi, y_pred_multi))\n",
    "print(\"R2 Score:\", r2_score(y_multi, y_pred_multi))\n",
    "\n",
    "# Plotting Simple Linear Regression Results\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Simple Linear Regression\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_single, y_single, color=\"blue\", label=\"Actual Data\")\n",
    "plt.plot(X_single, y_pred_single, color=\"red\", linewidth=2, label=\"Regression Line\")\n",
    "plt.xlabel(\"Feature (X)\")\n",
    "plt.ylabel(\"Target (y)\")\n",
    "plt.title(\"Simple Linear Regression\")\n",
    "plt.legend()\n",
    "\n",
    "# Plotting Multiple Linear Regression Results\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_multi, y_pred_multi, color=\"purple\", alpha=0.6, edgecolors=\"k\")\n",
    "plt.plot([y_multi.min(), y_multi.max()], [y_multi.min(), y_multi.max()], 'r--', linewidth=2)\n",
    "plt.xlabel(\"Actual Target (y)\")\n",
    "plt.ylabel(\"Predicted Target (y_pred)\")\n",
    "plt.title(\"Multiple Linear Regression - Actual vs Predicted\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01c0a5-e2fd-44fc-83c7-8a9b98ff23d7",
   "metadata": {},
   "source": [
    "**Classfication**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98442b9d-646c-441d-a2be-5d139bf677b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600970b9-ebf3-4a5f-9a20-b07c5e777cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6836b53b-62bd-4f98-a19f-a9182fa16905",
   "metadata": {},
   "source": [
    "Reading the  data set of titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a565ec7-1bce-493e-aa69-34f8c40281bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e10df6-e707-4396-8456-23b5ecebcf38",
   "metadata": {},
   "source": [
    "producing the dataset information data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c6423b-d2be-4254-927f-d416daa00c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b201b61-c82e-4dbb-b1cf-ccbecc6708ac",
   "metadata": {},
   "source": [
    "checking the Null values of the data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42c41b-be73-4fed-a68c-81b3f4acdc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba33800-3726-44bc-9818-34d4544ec703",
   "metadata": {},
   "source": [
    "printing the top 5 data in dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1085c-ed93-4da2-8d50-277947d3b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Preprocess data\n",
    "# Select relevant features and target\n",
    "X = data[['Pclass', 'Sex', 'Age', 'Fare', 'SibSp', 'Parch']]\n",
    "y = data['Survived']\n",
    "\n",
    "# Handle missing values\n",
    "X['Age'].fillna(X['Age'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variable 'Sex'\n",
    "X = pd.get_dummies(X, columns=['Sex'], drop_first=True)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Plot ROC curves for each model\n",
    "plt.figure(figsize=(10, 8))\n",
    "for model_name, model in models.items():\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict probabilities\n",
    "    y_probs = model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Compute ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_probs)\n",
    "    roc_auc = roc_auc_score(y_test, y_probs)\n",
    "\n",
    "    # Plot ROC curve\n",
    "    plt.plot(fpr, tpr, label=f'{model_name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "\n",
    "    print(f\"Classification Report for {model_name}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "# Plot settings\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e1fe7-5820-46b0-93c9-6b1b3d7bfed8",
   "metadata": {},
   "source": [
    "This code preprocesses Titanic dataset features (`X`) and target (`y`), including handling missing values, encoding categorical variables, splitting data, and standardizing features. It trains multiple models (Naive Bayes, Decision Tree, Random Forest), evaluates them using ROC curves and classification reports, and visualizes their ROC curves with corresponding AUC scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Krishna GSVV  \n",
    "Roll no. AV.EN.U4CSE22016  \n",
    "Assignment - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to the Dataset\n",
    "\n",
    "The dataset provided is named `iphone.csv`. It likely contains data related to iPhones, potentially including features such as model specifications, prices, release dates, sales, or user ratings. Before diving into the tasks, we will first explore and preprocess this dataset to understand its structure and clean it as necessary. Following this, we will apply different visualization and analytical techniques to uncover patterns, relationships, and insights within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Understanding and Exploring the Dataset\n",
    "\n",
    "#### Explanation:\n",
    "In this task, the dataset is loaded using the `pandas` library, and basic exploration functions like `head()`, `info()`, and `describe()` are used to get an overview of the dataset's structure, data types, and statistical summary. These functions provide insights into the dataset's columns, missing data, and general distributions.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"cities_r2.csv\")\n",
    "\n",
    "# Explore the dataset\n",
    "display(df.head())\n",
    "print(df.info())\n",
    "display(df.describe())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Checking for Missing Data\n",
    "\n",
    "#### Explanation:\n",
    "We use the `isnull()` function to identify missing values in the dataset. This helps us decide on appropriate methods to handle missing data in the subsequent task.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to randomly remove data to simulate data inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Load the CSV file into a DataFrame\n",
    "# df = pd.read_csv('cities_r2.csv')\n",
    "\n",
    "# # Print the original number of non-NaN values\n",
    "# print(f\"Original number of non-NaN values: {df.notna().sum().sum()}\")\n",
    "\n",
    "# # Randomly select a few data points to set to NaN (e.g., 10 data points)\n",
    "# num_points_to_nan = 10\n",
    "# nan_indices = [(np.random.randint(0, df.shape[0]), np.random.randint(0, df.shape[1])) for _ in range(num_points_to_nan)]\n",
    "\n",
    "# # Set the selected data points to NaN\n",
    "# for row, col in nan_indices:\n",
    "#     df.iat[row, col] = np.nan\n",
    "\n",
    "# # Print the number of non-NaN values after setting some to NaN\n",
    "# print(f\"Number of non-NaN values after setting some to NaN: {df.notna().sum().sum()}\")\n",
    "\n",
    "# # Save the modified DataFrame back to a CSV file (optional)\n",
    "# df.to_csv('cities_r2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing data\n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "# Display missing data\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Handling Missing Data and Outliers\n",
    "\n",
    "#### Explanation:\n",
    "Missing data is handled by filling numerical columns with their mean values. To detect and remove outliers, we use the Z-score method, which identifies values that are more than three standard deviations from the mean. The dataset is then filtered to remove these outliers.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with mean for numerical columns\n",
    "df.fillna(df.select_dtypes(include=['float64', 'int64']).mean(), inplace=True)\n",
    "\n",
    "# Detect outliers using Z-score\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Calculate Z-scores and filter out data points with high Z-scores\n",
    "z_scores = zscore(df.select_dtypes(include=['float64', 'int64']))\n",
    "df_cleaned = df[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Converting Categorical Data to Numerical\n",
    "\n",
    "#### Explanation:\n",
    "Categorical columns are converted to numerical format using one-hot encoding. This process transforms categorical variables into a format suitable for machine learning algorithms by creating new binary columns for each category.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical columns using one-hot encoding\n",
    "df_encoded = pd.get_dummies(df_cleaned, drop_first=True)\n",
    "\n",
    "display(df_encoded.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Feature Scaling (if necessary)\n",
    "\n",
    "#### Explanation:\n",
    "Feature scaling is applied using `StandardScaler` to normalize numerical columns so that they have a mean of 0 and a standard deviation of 1. This ensures that all features are on a similar scale, which is important for many machine learning models.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply scaling to numerical columns\n",
    "scaled_data = scaler.fit_transform(df_encoded)\n",
    "\n",
    "# Convert scaled data back to DataFrame\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=df_encoded.columns)\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Visualizing Relationships Between Features\n",
    "\n",
    "#### Explanation:\n",
    "In this task, we will visualize the relationships between different features in the dataset using scatter plots, pair plots, and correlation heatmaps. These visualizations help in identifying patterns, trends, and correlations between features, providing insights into the data.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Print the columns of the DataFrame to verify their names\n",
    "print(\"Columns in DataFrame:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(df[['population_total', 'population_male', 'population_female', 'literates_total', 'literates_male', 'literates_female']].corr(), annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Heatmap of Selected Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot for 'population_total' and 'literates_total'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df, x='population_total', y='literates_total')\n",
    "plt.title('Scatter Plot between Total Population and Total Literates')\n",
    "plt.xlabel('Total Population')\n",
    "plt.ylabel('Total Literates')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pair Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plot for selected numerical features\n",
    "sns.pairplot(df[['population_total', 'population_male', 'population_female', 'literates_total', 'literates_male', 'literates_female']])\n",
    "plt.suptitle('Pair Plot of Selected Numerical Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7: Visualizing Distributions of Features\n",
    "\n",
    "#### Explanation:\n",
    "Histograms are used to visualize the distributions of individual numerical features. This allows us to observe whether the data is normally distributed, skewed, or contains outliers.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize data types\n",
    "for col in df.select_dtypes(include=['float64']).columns:\n",
    "    df[col] = df[col].astype('float32')\n",
    "\n",
    "# Sample a subset of the data (e.g., 10,000 rows)\n",
    "df_sampled = df.sample(n=10000, random_state=1) if len(df) > 10000 else df\n",
    "\n",
    "# Get the list of numerical columns\n",
    "numerical_cols = df_sampled.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Calculate the number of rows and columns needed for the subplots\n",
    "num_cols = len(numerical_cols)\n",
    "num_rows = int(np.ceil(num_cols / 3))  # Adjust the number of columns per row as needed\n",
    "\n",
    "# Create subplots dynamically\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=3, figsize=(20, num_rows * 5))  # Adjust the figure size as needed\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot histograms for numerical features\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    df_sampled[col].hist(ax=axes[i], bins=30, edgecolor='black')\n",
    "    axes[i].set_title(col)\n",
    "\n",
    "# Remove any unused subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust spacing between subplots\n",
    "plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1, hspace=0.4, wspace=0.4)\n",
    "\n",
    "# Add a title to the entire figure\n",
    "fig.suptitle('Histograms of Numerical Features', y=0.93, fontsize = 20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8: Detecting Outliers Using Visualization\n",
    "\n",
    "#### Explanation:\n",
    "Boxplots are used to visualize the presence of outliers in the dataset. The plots help in identifying extreme values that could affect the analysis.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation to the data\n",
    "df_log_transformed = df_scaled.apply(lambda x: np.log1p(x) if np.issubdtype(x.dtype, np.number) else x)\n",
    "\n",
    "# Plot boxplots for individual features after log transformation\n",
    "features_to_plot = ['population_total', 'population_male', 'population_female', 'literates_total', 'literates_male', 'literates_female']  # Adjust the list as needed\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for feature in features_to_plot:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.boxplot(data=df_log_transformed[feature])\n",
    "    plt.title(f'Boxplot of Log-Transformed {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9: Visualizing Trends or Time-Based Data\n",
    "\n",
    "#### Explanation:\n",
    "If the dataset contains time-series data, line plots are created to visualize trends over time. This helps in identifying patterns such as seasonality, growth, or decline in specific features over a period.\n",
    "\n",
    "#### Code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This database does not require time-based visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # If time-based data is available, plot a line graph\n",
    "# if 'date_column' in df.columns:  # Replace 'date_column' with the actual time column name\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(df['date_column'], df['target_column'])  # Replace 'target_column' with the feature of interest\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Target Feature')\n",
    "#     plt.title('Trend over Time')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10: Summary of Insights\n",
    "\n",
    "Through the preprocessing and visualization tasks, I learned the importance of understanding and cleaning the dataset before applying any analysis. Handling missing data ensures that no critical information is lost, while outlier detection helps in maintaining data integrity. The conversion of categorical data and feature scaling are crucial for making the dataset compatible with machine learning algorithms. Visualizing relationships and distributions provides a deeper understanding of how the features interact with each other. Finally, summarizing insights allows us to reflect on the key findings and patterns that can guide further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population Distribution Chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['population_total'], bins=30, kde=True, color='blue')\n",
    "plt.title('Population Distribution Across Cities', fontsize=14)\n",
    "plt.xlabel('Population Total', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Literacy Rate Comparison (Male vs Female by State)\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='state_name', y='effective_literacy_rate_total', palette=\"viridis\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Effective Literacy Rate by State', fontsize=14)\n",
    "plt.xlabel('State', fontsize=12)\n",
    "plt.ylabel('Effective Literacy Rate', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Heatmap of Numeric Features\n",
    "plt.figure(figsize=(14, 10))\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "corr_matrix = df[numeric_columns].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar=True)\n",
    "plt.title('Correlation Heatmap of Numeric Features', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38b07f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to include in the heatmap\n",
    "columns_to_include = [\n",
    "    \"population_total\",\n",
    "    \"population_male\",\n",
    "    \"population_female\",\n",
    "    \"0-6_population_total\",\n",
    "    \"0-6_population_male\",\n",
    "    \"0-6_population_female\",\n",
    "    \"literates_total\",\n",
    "    \"literates_male\",\n",
    "    \"literates_female\",\n",
    "    \"sex_ratio\",\n",
    "    \"child_sex_ratio\",\n",
    "    \"effective_literacy_rate_total\",\n",
    "    \"effective_literacy_rate_male\",\n",
    "    \"effective_literacy_rate_female\",\n",
    "    \"total_graduates\",\n",
    "    \"male_graduates\",\n",
    "    \"female_graduates\",\n",
    "]\n",
    "\n",
    "# Create a correlation matrix for the specified columns\n",
    "corr_matrix = df[columns_to_include].corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Correlation Heatmap of Selected Features\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
