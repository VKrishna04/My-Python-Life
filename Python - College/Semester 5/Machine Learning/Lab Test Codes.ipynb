{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Data array\n",
    "data_array = np.array([2, 4, 4, 5, 7, 9, 11, 11, 13, 14, 41])\n",
    "\n",
    "# MEAN\n",
    "mean = np.mean(data_array)\n",
    "\n",
    "# MEDIAN\n",
    "median = np.median(data_array)\n",
    "\n",
    "# MODE\n",
    "mode = stats.mode(data_array)\n",
    "\n",
    "# RANGE\n",
    "range_value = np.ptp(data_array)\n",
    "\n",
    "# VARIANCE\n",
    "variance = np.var(data_array, ddof=1)\n",
    "\n",
    "# STANDARD DEVIATION\n",
    "std = np.std(data_array, ddof=1)\n",
    "\n",
    "# Print results\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Median:\", median)\n",
    "print(\"Mode:\", mode)\n",
    "print(\"Range:\", range_value)\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Standard Deviation:\", std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lab 4  \n",
    "a. KNN(K- nearest neighbour) Classifier using the iris-flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "knn = KNeighborsClassifier(7)\n",
    "\n",
    "knn.fit(X, y)\n",
    "\n",
    "y_pred = knn.predict(X)\n",
    "\n",
    "print(\"Predictions:\", y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. K-Mean Clustering using the data given in class and the iris-flower dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "df[\"Target\"] = iris.target\n",
    "\n",
    "initial_centers = np.array(\n",
    "    [[5.0, 3.5, 1.5, 0.2], [6.0, 3.0, 4.5, 1.5], [7.0, 3.2, 5.5, 2.0]]\n",
    ")\n",
    "\n",
    "k = len(initial_centers)  # Number of clusters\n",
    "\n",
    "kmeans = KMeans(k, init=initial_centers, n_init=1, random_state=42)\n",
    "\n",
    "X = df[iris.feature_names].values\n",
    "\n",
    "kmeans.fit(X)\n",
    "\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "df[\"Cluster\"] = labels\n",
    "\n",
    "print(\"Cluster Centers:\\n\", kmeans.cluster_centers_)\n",
    "print(\"\\nUpdated Clusters:\\n\")\n",
    "display(\n",
    "    df[\n",
    "        [\n",
    "            \"sepal length (cm)\",\n",
    "            \"sepal width (cm)\",\n",
    "            \"petal length (cm)\",\n",
    "            \"petal width (cm)\",\n",
    "            \"Cluster\",\n",
    "        ]\n",
    "    ]\n",
    ")\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB 5 \n",
    "Demonstrate and compute Accuracy, Precision, Recall, F1 Score, Sensitivity, Specificity for the given confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data\n",
    "\n",
    "| Actual \\ Predicted | Apple | Orange | Pear | Total |\n",
    "|--------------------|-------|--------|------|-------|\n",
    "| Apple              | 50    | 5      | 50   | 105   |\n",
    "| Orange             | 10    | 50     | 20   | 80    |\n",
    "| Pear               | 5     | 5      | 0    | 10    |\n",
    "| Total              | 65    | 60     | 70   | 195   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "source": [
    "| Metric       | Value  |\n",
    "|--------------|--------|\n",
    "| True Positive (TP)  | 0      |\n",
    "| False Positive (FP) | 70     |\n",
    "| True Negative (TN)  | 115    |\n",
    "| False Negative (FN) | 10     |\n",
    "\n",
    "### Explanation:\n",
    "- **True Positive (TP)**: The number of positive samples correctly identified. In this case, it is 0.\n",
    "- **False Positive (FP)**: The number of negative samples incorrectly identified as positive. In this case, it is 70.\n",
    "- **True Negative (TN)**: The number of negative samples correctly identified. In this case, it is 115.\n",
    "- **False Negative (FN)**: The number of positive samples incorrectly identified as negative. In this case, it is 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "confusion_matrix = np.array([[50, 5, 50], [10, 50, 20], [5, 5, 0]])\n",
    "\n",
    "num_classes = confusion_matrix.shape[0]\n",
    "total = confusion_matrix.sum()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    TP = confusion_matrix[i, i]\n",
    "    FN = confusion_matrix[i, :].sum() - TP\n",
    "    FP = confusion_matrix[:, i].sum() - TP\n",
    "    TN = total - (TP + FP + FN)\n",
    "\n",
    "    accuracy = (TP + TN) / total\n",
    "    precision = TP / (TP + FP) if (TP + FP) else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) else 0\n",
    "    f1_score = (\n",
    "        2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "    )\n",
    "    specificity = TN / (TN + FP) if (TN + FP) else 0\n",
    "\n",
    "    print(f\"\\nClass {i} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1_score:.2f}, Specificity: {specificity:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB 7 \n",
    "Demonstrate and compute Decision tree (ID3) for the dataset given in class "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data\n",
    "\n",
    "| Day | Outlook   | Temperature | Humidity | Wind   | Play Tennis |\n",
    "|-----|-----------|-------------|----------|--------|-------------|\n",
    "| 1   | Sunny     | Hot         | High     | Weak   | No          |\n",
    "| 2   | Sunny     | Hot         | High     | Strong | No          |\n",
    "| 3   | Overcast  | Hot         | High     | Weak   | Yes         |\n",
    "| 4   | Rain      | Mild        | High     | Weak   | Yes         |\n",
    "| 5   | Rain      | Cool        | Normal   | Weak   | Yes         |\n",
    "| 6   | Rain      | Cool        | Normal   | Strong | No          |\n",
    "| 7   | Overcast  | Cool        | Normal   | Strong | Yes         |\n",
    "| 8   | Sunny     | Mild        | High     | Weak   | No          |\n",
    "| 9   | Sunny     | Cool        | Normal   | Weak   | Yes         |\n",
    "| 10  | Rain      | Mild        | Normal   | Weak   | Yes         |\n",
    "| 11  | Sunny     | Mild        | Normal   | Strong | Yes         |\n",
    "| 12  | Overcast  | Mild        | High     | Strong | Yes         |\n",
    "| 13  | Overcast  | Hot         | Normal   | Weak   | Yes         |\n",
    "| 14  | Rain      | Mild        | High     | Strong | No          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = {\n",
    "    \"Outlook\": [\n",
    "        \"Sunny\",\n",
    "        \"Sunny\",\n",
    "        \"Overcast\",\n",
    "        \"Rain\",\n",
    "        \"Rain\",\n",
    "        \"Rain\",\n",
    "        \"Overcast\",\n",
    "        \"Sunny\",\n",
    "        \"Sunny\",\n",
    "        \"Rain\",\n",
    "        \"Sunny\",\n",
    "        \"Overcast\",\n",
    "        \"Overcast\",\n",
    "        \"Rain\",\n",
    "    ],\n",
    "    \"Temperature\": [\n",
    "        \"Hot\",\n",
    "        \"Hot\",\n",
    "        \"Hot\",\n",
    "        \"Mild\",\n",
    "        \"Cool\",\n",
    "        \"Cool\",\n",
    "        \"Cool\",\n",
    "        \"Mild\",\n",
    "        \"Cool\",\n",
    "        \"Mild\",\n",
    "        \"Mild\",\n",
    "        \"Mild\",\n",
    "        \"Hot\",\n",
    "        \"Mild\",\n",
    "    ],\n",
    "    \"Humidity\": [\n",
    "        \"High\",\n",
    "        \"High\",\n",
    "        \"High\",\n",
    "        \"High\",\n",
    "        \"Normal\",\n",
    "        \"Normal\",\n",
    "        \"Normal\",\n",
    "        \"High\",\n",
    "        \"Normal\",\n",
    "        \"Normal\",\n",
    "        \"Normal\",\n",
    "        \"High\",\n",
    "        \"Normal\",\n",
    "        \"High\",\n",
    "    ],\n",
    "    \"Windy\": [\n",
    "        \"Weak\",\n",
    "        \"Strong\",\n",
    "        \"Weak\",\n",
    "        \"Weak\",\n",
    "        \"Weak\",\n",
    "        \"Strong\",\n",
    "        \"Strong\",\n",
    "        \"Weak\",\n",
    "        \"Weak\",\n",
    "        \"Weak\",\n",
    "        \"Strong\",\n",
    "        \"Strong\",\n",
    "        \"Weak\",\n",
    "        \"Strong\",\n",
    "    ],\n",
    "    \"PlayTennis\": [\n",
    "        \"No\",\n",
    "        \"No\",\n",
    "        \"Yes\",\n",
    "        \"Yes\",\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "        \"Yes\",\n",
    "        \"Yes\",\n",
    "        \"Yes\",\n",
    "        \"Yes\",\n",
    "        \"Yes\",\n",
    "        \"No\",\n",
    "    ],\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = pd.get_dummies(df.drop(\"PlayTennis\", axis=1))\n",
    "y = df[\"PlayTennis\"]\n",
    "\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "model.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(model, feature_names=X.columns, class_names=model.classes_, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 8  \n",
    "a. SVM linear example.  \n",
    "Sample Data  \n",
    "`+` ve Labelled - {(3 1) (3 -1) (6 1) (6 -1)}  \n",
    "`-` ve Labelled – {(1 0) (0 1) (0 -1) (-1 0)}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = np.array([[3, 1], [3, -1], [6, 1], [6, -1], [1, 0], [0, 1], [0, -1], [-1, 0]])\n",
    "y = np.array([1, 1, 1, 1, -1, -1, -1, -1])\n",
    "\n",
    "svm_linear = SVC(kernel=\"linear\")\n",
    "svm_linear.fit(X, y)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\", edgecolors=\"k\", s=100)\n",
    "\n",
    "w = svm_linear.coef_[0]\n",
    "b = svm_linear.intercept_[0]\n",
    "xx = np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1)\n",
    "yy = -(w[0] * xx + b) / w[1]\n",
    "plt.plot(xx, yy, \"k-\")\n",
    "\n",
    "plt.title(\"SVM with Linear Kernel\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.xlim(-2, 8)\n",
    "plt.ylim(-2, 2)\n",
    "plt.grid()\n",
    "\n",
    "plt.axhline(0, color=\"black\", lw=0.5)\n",
    "plt.axvline(0, color=\"black\", lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. SVM non-linear example.\n",
    "Sample Data  \n",
    "`+` ve Labelled - {(2 2) (2 -2) (-2 -2) (-2 2)}  \n",
    "`-` ve Labelled – {(1 1) (1 -1) (-1 -1) (-1 1)} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the data points and their labels\n",
    "X = np.array([[2, 2], [2, -2], [-2, -2], [-2, 2], [1, 1], [1, -1], [-1, -1], [-1, 1]])\n",
    "y = np.array(\n",
    "    [1, 1, 1, 1, -1, -1, -1, -1]\n",
    ")  # Positive labels are +1 and negative labels are -1\n",
    "\n",
    "# Create and fit the SVM model with an RBF kernel\n",
    "svm_non_linear = SVC(kernel=\"rbf\")\n",
    "svm_non_linear.fit(X, y)\n",
    "\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"coolwarm\", edgecolors=\"k\", s=100)\n",
    "\n",
    "# Create a grid to plot decision boundary\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X[:, 0].min() - 1, X[:, 0].max() + 1, 100),\n",
    "    np.linspace(X[:, 1].min() - 1, X[:, 1].max() + 1, 100),\n",
    ")\n",
    "Z = svm_non_linear.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contour(xx, yy, Z, levels=[0], linewidths=2, colors=\"k\")\n",
    "plt.title(\"SVM with Non-Linear Kernel (RBF)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.xlim(-3, 3)\n",
    "plt.ylim(-3, 3)\n",
    "plt.grid()\n",
    "plt.axhline(0, color=\"black\", lw=0.5)\n",
    "plt.axvline(0, color=\"black\", lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB 9  \n",
    "Demonstrate and compute Naive Bayes Classifier using the data given in class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data \n",
    "| Name of pattern | Habit   | Eats    | Footwear | Classification |\n",
    "|-----------------|---------|---------|----------|----------------|\n",
    "| T1              | Gabby   | Baked   | Clogs    | Student        |\n",
    "| T2              | Gabby   | Roasted | Sandals  | Professor      |\n",
    "| T3              | Gabby   | Baked   | Sandals  | Student        |\n",
    "| T4              | Quiet   | Fried   | Sandals  | Professor      |\n",
    "| T5              | Gabby   | Fried   | Clogs    | Student        |\n",
    "| T6              | Quiet   | Baked   | Sandals  | Student        |\n",
    "| T7              | Gabby   | Fried   | Sandals  | Professor      |\n",
    "| T8              | Quiet   | Fried   | Clogs    | Student        |\n",
    "| R1              | Quiet   | Baked   | Clogs    | R1             |\n",
    "| R2              | Quiet   | Roasted | Sandals  | R2             |\n",
    "| R3              | Gabby   | Roasted | Clogs    | R3             |\n",
    "| R4              | Quiet   | Roasted | Clogs    | R4             |\n",
    "\n",
    "Predicted classifications for unlabeled data:  \n",
    "R1: Student  \n",
    "R2: Professor  \n",
    "R3: Student  \n",
    "R4: Student  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted classifications for unlabeled data:\n",
      "R1: Student\n",
      "R2: Professor\n",
      "R3: Student\n",
      "R4: Student\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.SettingWithCopyWarning)\n",
    "\n",
    "nb_data = pd.DataFrame(\n",
    "    {\n",
    "        \"name of pattern\": [\n",
    "            \"T1\",\n",
    "            \"T2\",\n",
    "            \"T3\",\n",
    "            \"T4\",\n",
    "            \"T5\",\n",
    "            \"T6\",\n",
    "            \"T7\",\n",
    "            \"T8\",\n",
    "            \"R1\",\n",
    "            \"R2\",\n",
    "            \"R3\",\n",
    "            \"R4\",\n",
    "        ],\n",
    "        \"habit\": [\n",
    "            \"Gabby\",\n",
    "            \"Gabby\",\n",
    "            \"Gabby\",\n",
    "            \"Quiet\",\n",
    "            \"Gabby\",\n",
    "            \"Quiet\",\n",
    "            \"Gabby\",\n",
    "            \"Quiet\",\n",
    "            \"Quiet\",\n",
    "            \"Quiet\",\n",
    "            \"Gabby\",\n",
    "            \"Quiet\",\n",
    "        ],\n",
    "        \"eats\": [\n",
    "            \"Baked\",\n",
    "            \"Roasted\",\n",
    "            \"Baked\",\n",
    "            \"Fried\",\n",
    "            \"Fried\",\n",
    "            \"Baked\",\n",
    "            \"Fried\",\n",
    "            \"Fried\",\n",
    "            \"Baked\",\n",
    "            \"Roasted\",\n",
    "            \"Roasted\",\n",
    "            \"Roasted\",\n",
    "        ],\n",
    "        \"footwear\": [\n",
    "            \"Clogs\",\n",
    "            \"Sandals\",\n",
    "            \"Sandals\",\n",
    "            \"Sandals\",\n",
    "            \"Clogs\",\n",
    "            \"Sandals\",\n",
    "            \"Sandals\",\n",
    "            \"Clogs\",\n",
    "            \"Clogs\",\n",
    "            \"Sandals\",\n",
    "            \"Clogs\",\n",
    "            \"Clogs\",\n",
    "        ],\n",
    "        \"classification\": [\n",
    "            \"Student\",\n",
    "            \"Professor\",\n",
    "            \"Student\",\n",
    "            \"Professor\",\n",
    "            \"Student\",\n",
    "            \"Student\",\n",
    "            \"Professor\",\n",
    "            \"Student\",\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "            None,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "labeled_data = nb_data[nb_data[\"classification\"].notna()]\n",
    "unlabeled_data = nb_data[nb_data[\"classification\"].isna()]\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for column in nb_data.columns:\n",
    "    le = LabelEncoder()\n",
    "    nb_data[column] = le.fit_transform(nb_data[column].astype(str))\n",
    "    labeled_data[column] = le.transform(labeled_data[column].astype(str))\n",
    "    unlabeled_data[column] = le.transform(unlabeled_data[column].astype(str))\n",
    "    label_encoders[column] = le\n",
    "\n",
    "X = labeled_data[[\"name of pattern\", \"habit\", \"eats\", \"footwear\"]]\n",
    "y = labeled_data[\"classification\"]\n",
    "\n",
    "nb_classifier = CategoricalNB()\n",
    "nb_classifier.fit(X, y)\n",
    "\n",
    "X_unlabeled = unlabeled_data[[\"name of pattern\", \"habit\", \"eats\", \"footwear\"]]\n",
    "y_pred_unlabeled = nb_classifier.predict(X_unlabeled)\n",
    "\n",
    "decoded_predictions = label_encoders[\"classification\"].inverse_transform(\n",
    "    y_pred_unlabeled\n",
    ")\n",
    "print(\"\\nPredicted classifications for unlabeled data:\")\n",
    "for i, pred in enumerate(decoded_predictions, 1):\n",
    "    print(f\"R{i}: {pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB 10 \n",
    "Demonstrate and compute Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample Data \n",
    " \n",
    "| Sample No | X    | Y    |\n",
    "|-----------|------|------|\n",
    "| P1        | 0.40 | 0.53 |\n",
    "| P2        | 0.22 | 0.38 |\n",
    "| P3        | 0.35 | 0.32 |\n",
    "| P4        | 0.26 | 0.19 |\n",
    "| P5        | 0.08 | 0.41 |\n",
    "| P6        | 0.45 | 0.30 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"Sample No\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
    "    \"X\": [0.4, 0.22, 0.35, 0.26, 0.08, 0.45],\n",
    "    \"Y\": [0.53, 0.38, 0.32, 0.19, 0.41, 0.3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "X = df[[\"X\", \"Y\"]].values\n",
    "\n",
    "linkage_methods = [\"single\", \"complete\", \"average\"]\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, method in enumerate(linkage_methods, 1):\n",
    "    Z = linkage(X, method=method)\n",
    "\n",
    "    plt.subplot(1, 3, i)\n",
    "    dendrogram(Z, labels=df[\"Sample No\"].values)\n",
    "    plt.title(f\"Hierarchical Clustering ({method.capitalize()} Linkage)\")\n",
    "    plt.xlabel(\"Sample\")\n",
    "    plt.ylabel(\"Distance\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. Demonstrate and compute \n",
    " \n",
    "a. Divisive hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import pdist, squareform  # Import pdist and squareform\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "data = {\n",
    "    \"Sample No\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
    "    \"X\": [0.4, 0.22, 0.35, 0.26, 0.08, 0.45],\n",
    "    \"Y\": [0.53, 0.38, 0.32, 0.19, 0.41, 0.3],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "X = df[[\"X\", \"Y\"]].values\n",
    "\n",
    "\n",
    "def divisive_clustering(data, labels):\n",
    "\n",
    "    clusters = [[labels.copy()]]\n",
    "    current_cluster = labels.copy()\n",
    "\n",
    "    while len(current_cluster) > 1:\n",
    "        dist_matrix = squareform(pdist(data))\n",
    "        np.fill_diagonal(dist_matrix, np.inf)\n",
    "\n",
    "        max_dist_idx = np.unravel_index(np.argmax(dist_matrix), dist_matrix.shape)\n",
    "        cluster_a = [current_cluster[max_dist_idx[0]]]\n",
    "        cluster_b = [current_cluster[max_dist_idx[1]]]\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            if i != max_dist_idx[0] and i != max_dist_idx[1]:\n",
    "                if dist_matrix[max_dist_idx[0], i] < dist_matrix[max_dist_idx[1], i]:\n",
    "                    cluster_a.append(current_cluster[i])\n",
    "                else:\n",
    "                    cluster_b.append(current_cluster[i])\n",
    "\n",
    "        clusters.append([cluster_a, cluster_b])\n",
    "\n",
    "        if len(cluster_a) > len(cluster_b):\n",
    "            current_cluster = cluster_a\n",
    "        else:\n",
    "            current_cluster = cluster_b\n",
    "\n",
    "        data = np.array(\n",
    "            [data[current_cluster.index(sample)] for sample in current_cluster]\n",
    "        )\n",
    "\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = divisive_clustering(X, df[\"Sample No\"].tolist())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, cluster in enumerate(clusters):\n",
    "    y_position = len(clusters) - i\n",
    "    for j, sample in enumerate(cluster if isinstance(cluster, list) else [cluster]):\n",
    "        x_position = j * 2\n",
    "        plt.text(x_position, y_position, str(sample), ha=\"center\", va=\"center\")\n",
    "\n",
    "plt.title(\"Divisive Hierarchical Clustering\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.ylabel(\"Split Level\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Clustering evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "# Define the dataset\n",
    "data = {\n",
    "    \"Sample No\": [\"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\"],\n",
    "    \"X\": [0.4, 0.22, 0.35, 0.26, 0.08, 0.45],\n",
    "    \"Y\": [0.53, 0.38, 0.32, 0.19, 0.41, 0.3],\n",
    "}\n",
    "\n",
    "# Convert the data into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "X = df[[\"X\", \"Y\"]].values  # Use only the X and Y columns for clustering\n",
    "\n",
    "# Manually create a ground truth (you can replace this with real labels if available)\n",
    "df[\"True_Cluster\"] = [\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    1,\n",
    "    0,\n",
    "    1,\n",
    "]  # Example of arbitrary true labels (cluster 0 and 1)\n",
    "\n",
    "# Perform K-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)  # Adjust the number of clusters\n",
    "df[\"Cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "# Calculate Silhouette Score and Adjusted Rand Index\n",
    "silhouette_avg = silhouette_score(X, df[\"Cluster\"])\n",
    "rand_index = adjusted_rand_score(df[\"True_Cluster\"], df[\"Cluster\"])\n",
    "\n",
    "# Print results\n",
    "print(\"Clustering Evaluation Metrics:\")\n",
    "print(f\"Silhouette Score: {silhouette_avg:.2f}\")\n",
    "print(f\"Adjusted Rand Index: {rand_index:}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
